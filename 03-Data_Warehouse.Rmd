# The Data Warehouse and how to access it

The [first section](#section-the-data-warehouse) that follows provides lots of context about IDEA's data warehouse.

If, however, you are in a rush and want to go about accessing the data warehouse, then skip to section \@ref(accessing-the-data-warehouse-from-r) on accessing from R below. 

```{r load_dw, include=FALSE}
rna_dw_usage <- readxl::read_excel("DataWarehouse Usage.xlsx") %>% 
  janitor::clean_names() %>% 
  select(r_and_a_uses = r_a_uses_x,
         server_name, 
         database_name, 
         table_name, 
         column_name, 
         data_type, 
         constraint) %>% 
  mutate(
         across(where(is.character), as_factor),
         r_and_a_uses = !is.na(r_and_a_uses)) %>% 
  distinct()

n_servers <- rna_dw_usage %>% distinct(server_name) %>% nrow()
n_dbs <- rna_dw_usage %>% distinct(database_name) %>% nrow()
n_tables <- rna_dw_usage %>% 
  select(server_name, database_name, table_name) %>% 
  distinct() %>% 
  nrow()
```

## The Data Warehouse
The 'data warehouse' is actually a collection of disparate databases hosted by IDEA Public Schools.  Some databases are used to host the original source data, some are used as the data model for production applications, while others site between those two points.

While the IDEA has ~28 servers hosting SQL Server databases, R&A typically only accesses `r n_servers` servers hosting `r n_dbs` databases and `r prettyNum(n_tables, big.mark = ",")` distinct tables. It's a lot, for sure. 

### Core data warehouse server configuration

::: {.gotcha}
These facts below are scheduled to change in May-June of 2022.  The IT team is moving all servers from Rackspace to on-prem and as a result the Data warehousing team is upgrading servers and doing some maintenance on on the warehouse. 

Check back here for updates!
:::

The servers are not islands unto themselves, but rather form a small economy of data flows, where data moves from source servers, to production servers (i.e., the sweetspot for us) to reporting servers that host transformed data for our Logi-powered Locus dashboards.  

```{r server-graphs, echo=FALSE, fig.cap="Data in the warehouse is initially stored in 'src_*` databases in 'DS*' servers and flows to the right towads Logi hosted Locus dashboards."}
DiagrammeR::grViz("
  digraph data_wh {
    label='Basic Data Flows in Core Data Warehouse';
    labelloc = 't';
    compound=true;
  #graph statement
  graph [overlap = true, layout = dot, rankdir = LR]
  
    #node statement
    node [shape = cylinder, 
          style = filled, 
          fontname = Helvetica, 
          fillcolor= '#f9a054', 
          color = '#626363',
          fontcolor = white,
          fontsize=10]
    SRC1 [label=<SRC1<br/><font point-size='6'>RGVPDSD-DWSRC1</font>>]; 
    SRC2  [label=<SRC2<br/><font point-size='6'>RGVPDSD-DWSRC2	</font>>]; 
    SRC3 [label=<SRC3<br/><font point-size='6'>RGVPDSD-DWSRC3</font>>];
    SRC4 [label=<SRC3<br/><font point-size='6'>RGVPDSD-DWSRC4</font>>];
    SRC5 [label=<SRC3<br/><font point-size='6'>RGVPDSD-DWSRC5</font>>];
  
    node [fillcolor= '#1a4784']
    PROD1 [label=<PROD1<br/><font point-size='6'>RGVPDSD-DWPRD1</font>>]; 
    PROD2 [label=<PROD2<br/><font point-size='6'>RGVPDSD-DWPRD2</font>>]
    
    node [fillcolor= '#a4c364']
    RS2 [label=<RS2<br/><font point-size='6'>RGVPDSD-DWRPT1</font>>];
    RS1 [label=<RS1<br/><font point-size='6'>RGVPDSD-DWRPT1</font>>]
  
  
  node [shape = box, fontname = Helvetica, fillcolor= '#ffde75', fontcolor = black]
  LOGI [label='LOGI/PowerBI']
  
  node [shape = box, fontname = Helvetica, fillcolor= '#ee3a80', fontcolor = white]
  Analysis [label = 'R&A']

  # subgraph statements
  subgraph cluster_ds {rank = same; style = dotted; SRC1; SRC2; SRC3; SRC4; SRC5; label='1. Source Data'}
  subgraph cluster_prod {rank = same; style = dashed; PROD1; PROD2; label = '2. Production'}
  subgraph cluster_rs {rank = same; style = dotted; RS2; RS1; label='4. Reporting'}

  
  #edges statement
  edge [color = '#626363', arrowhead=vee]
  {SRC1 SRC3 SRC4 SRC5} -> PROD1 
  {SRC2} -> PROD2
   PROD1 -> {SRC1 SRC3 SRC4 SRC5} [label='Look-ups', color = gray, style=dashed, fontcolor=gray, fontsize=7]
   PROD1 -> RS1
   PROD2 -> RS2
  {PROD1 PROD2} 
   
  {RS2} -> LOGI [ltail=cluster_rs]
  
  {PROD1} -> LOGI [ltail=cluster_prod]
  {PROD1} -> Analysis [ltail=cluster_prod]
  
  
  
  }
")



```

Figure \@ref(fig:server-graphs) shows the flows of data in the warehouse, which essentially move from left to right.  The` DS-*` servers host databases holding source data.  That data is processed and saved in databases in the two production servers (`PROD1` and `PROD2`).  **These two production servers host most the data that R&A uses in analysis**, but know where the source data comes from in is often helpful.  The reporting servers---`RS1` and `RS2` serve transformed flat files that serve as the data layer for [Logi](https://www.logianalytics.com/) and PowerBI, which serve up [Locus dashboards on the hub](https://ideapublicschoolsorg.sharepoint.com/sites/dashboards).  

The following sections provide some details on the what databases might be found on each server.

#### SRC Servers
These servers are were source data from various applications is landed. 

* **`SRC1`** is hosted on  `RGVPDSD-DWSRC1` and serves as a source for `PROD1`.  Most the data hosted on `RGVPDSD-DWSRC1` mirrors the various SISes (i.e. Schools data from PowerSchool, Focus, and Skyward) for TX, LA, FL, and OH.

  * **Databases**:

    * SRC_Texas_Schools
    * SRC_Texas_Travis_Schools
    * SRC_Louisiana_Schools
    * SRC_Florida_Schools
    * SRC_Ohio_Schools
    * SRC_AD
    * Master_Schools
    * TravisSnapshotData
    
  * **Sources**:
    
    * PowerSchool
    * Skyward
    * Focus

  * **Targets**:
    
    * `PROD1`
    

* **`SRC2`** is hosted on  `RGVPDSD-DWSRC2`  and serves as a source for `PROD2` and exclusively source data from assessment platforms like Edcite, Illuminate DnA, AP, IB, ACT, and SAT. 

  * **Databases**:
    * lk_Schools          
    * SRC_Accountability  
    * SRC_ACT             
    * SRC_AP              
    * SRC_Dibles          
    * SRC_EA              
    * SRC_IA              
    * SRC_IANew           
    * SRC_IB              
    * SRC_Ohio_Assessments
    * SRC_StateAssessments
    * SRC_EXPLORER        
    * SRC_NWEA            
    * SRC_SAT             
    * SRC_PLAN   

    
  * **Sources**:
    
    * See the database names just above
    * `PROD1` for lookup data about students and schools

  * **Targets**:
    
    * `PROD2`
    
* **SRC3** is hosted on `RGVPDSD-DWSRC3`  and serves as a source for `PROD1`.  Databases focus on source data from variance external systems, including Naviance, Tyler Munis, Teachboost, Schoolmint, and a slew if individualized learning/blended learing platforms. 

  * **Databases**:
    * lk_Schools
    * SRC_Alumni
    * SRC_AssetPanda
    * SRC_CollegeSuccess
    * SRC_CornerStoneEvaluations
    * SRC_DMac
    * SRC_GetRatings
    * SRC_HealthOfficeAnywhere
    * SRC_HR
    * SRC_Naviance
    * SRC_OpsCampusRanking
    * SRC_PanoramaSurveys
    * SRC_Recruitment
    * SRC_SchoolMint
    * SRC_StaffRetention
    * SRC_STMATH
    * SRC_Stream
    * SRC_Teachboost
    * SRC_TSI
    * SRC_TylerMunis
    * SRC_Wrike
    * SRC_Zendesk
    * SRC_ZendeskDev
    * TCPAppDev
    * SRC_JobVite
    * SRC_TTM
    * SRC_FitnessGram
    * SRC_NationalClearingHouse
    
      
      
  * **Sources**:
    
    * See the database names just above
    * `PROD1` for lookup data about students and schools

  * **Targets**:
    
    * `PROD1`
      
* **SRC4** is hosted on `RGVPDSD-DWSRC4`  and serves as a source for `PROD1`.  Databases focus on source data from various individualized learning/blended learnng platforms. 

  * **Databases**:
    * lk_Schools         
    * SRC_AR             
    * SRC_BlendedLearning
    * SRC_IHT    
    
      
  * **Sources**:
    
    * See the database names just above
    * `PROD1` for lookup data about students and schools

  * **Targets**:
    
    * `PROD1`    


* **SRC5** is hosted on `RGVPDSD-DWSRC5`  and serves as a source for `PROD1`.  Databases focus on source data Microsoft Teams

  * **Databases**:
    * TeamsAttendance   
    
      
  * **Sources**:
    
    * See the database names just above
    * `PROD1` for lookup data about students and schools

  * **Targets**:
    
    * `PROD1`    

#### PROD Servers

* **PROD1** is hosted on `RGVPDSD-DWPRD1` and contains a variety of data bases sourced from all `SRC` servers except for `SRC2`. The key students, schools, and regions data is found here and is 

  * **Databases**:
    * ADA               
    * BlendedLearning   
    * dwSnapshots       
    * Enrollment        
    * IT                
    * Persistence       
    * PROD1             
    * ProductDevelopment
    * CollegeSuccess    
    * Matriculation     
    * SSISTemp          
    * Staffing          
    * DashboardSettings 
    
  * **Sources**:
    
    * `SRC1`
    * `SRC3`
    * `SRC4`
    * `SRC5`
  
 * **Targets**:
 
  * `RS1`
  * `ST-HIS`

  
* **PROD2** hosts all assessement data for all state  This is the source server for `RS2` and includes assessments (e.g., IAs, bi-weekly and unit assessments, AP, IB) data and accountability tables. 

  * **Databases**:
    * Assessments  
    * lk_Schools   
    * PROD2        
    * SSISTemp  
    

    * Schools : this actually contains inventories at the school level, like lists of employees, equipment and asset inventories, students schedules, correspondences between teachers and students. 
    
#### RS and Hisotrical data Servers

R&A tends not to use these tables very often. `RS1`and  `RS2` git  have flat tables that utilized by by Logi for Locus Dashboards that are developed by Software Development. `ST-HIS` ostensibly has snapshots of data from the `PROD` servers, but that is just an unverified hunch 



* **RS1** 
  
  * **Databases**: unknown
  * **Sources**:
    
    * `PROD2`
    * something called `ST2`?
  
  * **Targets**
    * Logi
    
* **RS2**
  
  * **Databases**: unknown
  * **Sources**:
    
    * `PROD1`
    * something called `ST1`?
  
  * **Targets**
    * Logi
  


### Server, Table, and Field Lookup

The easiest way to explore databases and tables available in the data warehouse is to use the [`ideadata`](https://idea-analytics.github.io/ideadata/) packages's `view_warehouse_metadata()` function, which will launch a fiterable table in the RStudio IDEA.  

```{r display-dw-tables, eval=FALSE, echo=TRUE, warning=FALSE, fig.cap="Data warehouse details"}
library(ideadata)

view_warehouse_metadata()
```

![Example from running `view_warehouse_metadata()`](img/view_ware_house_meta_data.png "Example from running `view_warehouse_metadata()")

More details on accessing the data warehouse from R are in the following section.

## Accessing the data warehouse from R

The most straightforward way to access the data warehouse is to use our own, bespoke r package: `ideadata`, which is [maintained on github](https://github.com/idea-analytics/ideadata) and has [its own documentation site](https://idea-analytics.github.io/ideadata/).
 
### Installation


Since `ideadata` is an internal IDEA package, there is only a development version, which is installed from [GitHub](https://github.com/) with:

``` {r install, eval=FALSE}
#install.packages("remotes")
remotes::install_github("idea-analytics/ideadata")

#renv::install("idea-analytics/ideadata@main") also works
```
### Example

Here's how you connect to the `Schools` table in the warehouse.

```{r example, eval=FALSE}
library(dplyr)
library(ideadata)

schools <- get_schools()

glimpse(schools)
```


The `schools` object above is `tbl` object.  That means it works with `dplyr` verbs and functions, but  what  happens in the background is that `dplyr` and `dbplyr` generate SQL that is sent to the database you are connected to and  all that computation (e.g., filtering, selecting, joining, calculations, aggregation) are completed on the remote SQL Server instance and **not** on your computer.  

Nevertheless, you will eventually want to pull that data down onto your machine when you want to use R or Python do what they can do (like modeling or graphics) that the database can't do. 

Pulling that data down is easy with [dplyr::collect()]

```{r collect, eval=FALSE}
library(dplyr)

schools_df <- schools %>% 
  collect() %>% 
  janitor::clean_names()
```

(Here `janitor::clean_names()` snake_cases all the column names). 

#### What if I am pulling down lots of data (say, millions of rows)?
In this instance the database connection may fail.  It's not ideal, but it happens.  One way to deal with this is to pull down the data piecemeal.  The `collector()` function in `ideadata` makes this task trivial. It takes column names as arguments (unquote) from the table you want to pull down and those columns are used to break up the data into smaller sets of data that are pulled down from the database onto your computer and then recombined into a single table. 

```{r collector, eval=FALSE}

schools_df <- schools %>% 
  collector(SchoolState, CountyName) %>% 
  janitor::clean_names()

```

::: {.gotcha}
The `ideadata` package is clever in that it updates its knowledge of the data warehouse every time you load the package with `library(ideadata)`.  However to do that you need to have access to the the warehouse, and that requires that you are on the VPN/behind the firewall. Do makes sure that is true before invoking the package!
:::


### Finding things in the data warehouse

The `ideadata` package has a function that will open up a sortable, filterable, and searchable table in the RStudio idea: [`view_warehouse_meta_data()`](https://idea-analytics.github.io/ideadata/reference/view_warehouse_metadata.html)


### Where to learn more

`ideadata` [has it's own documentation here](https://idea-analytics.github.io/ideadata/).  If you can't find an answer there, then reach out to Chris Haid (he's responsible for this craziness).  

::: {.tip}
[Go to this article](https://idea-analytics.github.io/ideadata/articles/setting-up-your-credentials.html) to set up your credentials in R so that the warehouse can authenticate and authorize you as verified user
:::


::: {.tip}
Another important aspect of the warehouse is that the sources system for most student data is our SIS: PowerSchool.  The [PowerSchool Tables Data Dictionary](http://www.albertapsug.ca/uploads/1/5/1/2/15120130/ps10x_data_dictionary_tbl.pdf) is a helpful resource in understanding fields and relationships between tables. 
:::

