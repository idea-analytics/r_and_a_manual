[{"path":"index.html","id":"about","chapter":"1 A little about this manual","heading":"1 A little about this manual","text":" IDEA R&Manual IDEA Public Schools’ Research & Analytics (R&) Team’s ever evolving encyclopedia resources best practices. purpose make R&team member’s (really interested reader’s) job easier sharing jobs.manual particularly aimed technical audience (e.g., statisticians, data analysts, data engineers, data scientists) contributions technical authors. Indeed, expectation technical members R&team contribute manual regularly (.e., weekly daily festive (information) harvesting celebration Doctoberfest).","code":""},{"path":"index.html","id":"what-goes-in-this-manual","chapter":"1 A little about this manual","heading":"1.1 What goes in this manual?","text":"Anything everything learn course work IDEA. particular help information, learning, insights, topics especially useful colleagues (future self) include:Locations important tables data warehouseInformation use data warehouse (e.g., identify students CSI)Links examples useful R packagesTips tricks R, SQL, Python discover course workTemplates: output templates, input templates, ProjectTemplates, . . . templates.","code":""},{"path":"index.html","id":"how-do-you-contribute-to-this-book","chapter":"1 A little about this manual","heading":"1.2 How do you contribute to this book?","text":"manual written Markdown managed Git/GitHub.unfamiliar Git/GitHub ’ll want read use git Projects chapterThe general process follows:Clone repo: haven’t already, pull book ’s GitHub repo. command line run git clone https://github.com/idea-analytics/r_and_a_manual.git., pull latest version master branch git checkout master git pullIn File Explorer/Finder find r_and_a_manual folder double click r_and_a_manual.Rproj, open book’s project RStudioCheck branch git checkout -b -manual-update.Make updates. can run R bookdown::serve_book recompile book save.Commit frequently.Push changes branch GitHub.Initiate pull request merge changes. minor, can whole process . major–especially changing book’s structure–another team member review pull request merging.Complete merge.Rinse repeat!Remember Rmd file contains one one chapter, chapter defined first-level heading #. Use second (##) third (###) level headings sections chapter.","code":""},{"path":"index.html","id":"adding-tips-and-other-callouts","chapter":"1 A little about this manual","heading":"1.2.1 Adding “Tips” and other callouts","text":"see blue box just section? ’s tips box, others can add.super simple using special block tag (:::) RMarkdown creates CSS-styled <div> block resulting HTML manual’s RMD files rendered.’s example. Writing RMD:Results :tip box!use quick callouts important pieces hard-earned wisdom.four callout boxes can use, different icon:RStudio tip boxThis different tip box use sage advice regarding RStudio products like RStudio Connect, RStudio IDE, even RStudio supported packages.gotcha calloutWarn reader things look box.design calloutThis great looking spot provide extra advice look--feel design conventions.hat calloutYou get hat!can use extra special tips seem like magic. something like .","code":"::: {.tip}\nThis is a tip box!\n  \nYou should use this for quick callouts that are important pieces of hard-earned wisdom\n:::::: {.rstudio-tip}\nThis is an **RStudio** tip box\n\nThis is a different tip box to use for any sage advice regarding RStudio products like RStudio Connect, the RStudio IDE, or even RStudio supported packages.\n:::::: {.gotcha}\nThis is a **gotcha** callout\n\nWarn your reader of things to look out for with this box.\n:::::: {.design}\nThis is a **design** callout\n\nThis is great looking spot to provide extra advice on look-and-feel and design conventions.\n:::::: {hat}\nThis is a **hat** callout\n\nYou get a hat!  \n\nYou can use this for extra special tips that seem like magic. Or something like that.\n:::"},{"path":"who.html","id":"who","chapter":"2 Contributors","heading":"2 Contributors","text":"","code":""},{"path":"who.html","id":"about-research-and-analytics","chapter":"2 Contributors","heading":"2.1 About Research and Analytics","text":"IDEA’s Research Analytics Team (R&) provides leaders levels IDEA insights, findings, tools required make best short- long-term decisions behalf students families. R&finds opportunities improvement investments, locates exemplars best-practices, embeds analyses insights tools reports.Succinctly, R&team separates communicates signal noise following impacts organization:Actionable decision support: Leaders informed quickly possible making decisions can draw clear, correct inferences; know data utilized best extent possible well informed make decisions.Actionable decision support: Leaders informed quickly possible making decisions can draw clear, correct inferences; know data utilized best extent possible well informed make decisions.Strategic support: Long-term investments high ROI pursued; strategies ineffective adjusted replaced activities move us closer goal college .Strategic support: Long-term investments high ROI pursued; strategies ineffective adjusted replaced activities move us closer goal college .Tactical guidance: Nimbly surmise working pilots across region(s) communicate findings clearly; ensure decisions pushed one school year next.Tactical guidance: Nimbly surmise working pilots across region(s) communicate findings clearly; ensure decisions pushed one school year next.Short cycle improvements: Analyze understand short--medium term impacts program choices business partners provide actionable recommendations cycle continuous improvement.Short cycle improvements: Analyze understand short--medium term impacts program choices business partners provide actionable recommendations cycle continuous improvement.Educate partners: Assist team family understanding possible data, analyses can performed, nuggets wisdom can mined, face limitation need bring substantive expertise outside R&.Educate partners: Assist team family understanding possible data, analyses can performed, nuggets wisdom can mined, face limitation need bring substantive expertise outside R&.","code":""},{"path":"who.html","id":"who-we-are","chapter":"2 Contributors","heading":"2.2 Who we are","text":"","code":""},{"path":"who.html","id":"edison-coronado","chapter":"2 Contributors","heading":"2.2.1 Edison Coronado","text":"Edison Data Science Analytics Engineer supports IDEA making sure organization team access highest quality information insights streamlined, efficient, accurate. works teams members across IDEA help drive better decisions navigate goal. Edison also works different teams identifying opportunities improve process use collect, share, disseminate information.previous position Software Development Team Senior Developer working data integration software development. One software’s led Edison Teacher Career Pathway (TCP) developed designed system absorb numerous data points transformed TCP Level teacher across IDEA.background stems Computer Science holds BBA Computer Information Systems MS Business Analytics. Ask Power BI, Excel, R, DAX, Power Query, statistical methods/models.","code":""},{"path":"who.html","id":"chris-haid","chapter":"2 Contributors","heading":"2.2.2 Chris Haid","text":"Chris Haid Sr. VP Data Analytics IDEA Public Schools, leads research, evaluation, data analysis across 180+ schools Texas, Louisiana, Florida, Ohio.Previously KIPP Chicago’s Chief Staff, leading progress monitoring, strategic planning, data analysis, technology planning. also supported external affairs, growth strategy, communications, development. roles held KIPP Chicago included Chief Information Officer Director Research Analytics.Chris held academic positions Yale University, New York University, University Chicago. taught graduate undergraduate courses social scientific theory, statistical analysis, game theory, international development, globalization. Chris attended College William Mary earned BA Economics University Chicago earning MPP MA Political Science.","code":""},{"path":"who.html","id":"mishan-jensen-phd","chapter":"2 Contributors","heading":"2.2.3 Mishan Jensen, PhD","text":"Dr. Mishan Jensen Director Analytics IDEA’s Research Analytics Team 4 years experience program evaluation large urban school district 4 years experience Statistician Texas Department Public Safety & IDEA. holds Master’s Doctoral degrees University Texas Austin educational psychology, specialization Quantitative Methods. Previous work included evaluating multilingual education, teacher appraisal programs, integration arts classroom. time UT, Mishan assisted development College Education’s first fully web-based Introduction Statistics course, well provided assistant teaching support graduate level statistics courses offered. Recent work IDEA included Student Persistence, Enrollment, Teacher Career Pathways, Teacher Incentive Allotment, Advanced Placement, focusing impact analyses predictive modeling.","code":""},{"path":"who.html","id":"steven-macapagal","chapter":"2 Contributors","heading":"2.2.4 Steven Macapagal","text":"Steven Macapagal (Mac) Analytics Manager IDEA Public Schools Research, Analytics, Product team previously Sr. Data Scientist. Prior joining team, taught middle school high school math, including AP IB courses, grade team leader IDEA Bluff Springs College Preparatory IDEA Frontier College Preparatory. started Teach America - Rio Grande Valley corps member IDEA Frontier saw 100 percent seniors matriculate college. Mac earned BA Economics Mathematics University Texas Austin MS Statistics Texas &M University. current work involves academic operational data science projects leading Data Fellows, professional development program data science analysis.","code":""},{"path":"who.html","id":"aline-orr-phd","chapter":"2 Contributors","heading":"2.2.5 Aline Orr, PhD","text":"Dr. Aline Orr 20 years combined experience research program evaluation. holds Master’s degree educational psychology quantitative methods University Texas Austin PhD Neuroscience University Pittsburgh, focused brain pathways underlying emotional responses. recent past, Aline led evaluation educational programs serving elementary secondary students large urban public school district. conducting educational research large assessment textbook publishing house. Aline joined IDEA’s Research Analytics team evaluator 2021 currently Director Research. position, partners Advancement Growth teams well Operations team implement research insights drive change improvements.","code":""},{"path":"who.html","id":"ilissa-madrigal","chapter":"2 Contributors","heading":"2.2.6 Ilissa Madrigal","text":"Ilissa Madrigal Sr. Evaluator R&team, often assisting qualitative methods frequently partnering HA AST teams.Recent work includes providing thematic analyses GPTW open-ended questions, conducting focus groups Core Values, designing training evaluation surveys, providing evaluation support Teacher & School Leader Incentive Program grant.working IDEA, Ilissa taught high school chemistry RGV earning master’s Industrial-Organizational Psychology University Tulsa. holds BS Psychology BA Biology University Texas Austin.","code":""},{"path":"who.html","id":"marlena-coco-phd","chapter":"2 Contributors","heading":"2.2.7 Marlena Coco, PhD","text":"Dr. Marlena Coco Evaluator R&Team 15 years experience education higher education. earned PhD Higher Education Leadership Research Methodology Florida Atlantic University, MA College Student Development St. Edward’s University, BS Psychology UT-Austin. teaches undergraduate graduate courses, chairs doctoral students dissertation research, reviews articles journal publication, provides education consulting services, conducts strengths-based leadership development. previous roles, led research, evaluation, data support college career readiness large, urban school district, implemented district wide surveys, analyzed post secondary retention academic support data multiple universities. evaluates Charter School Program grants.","code":""},{"path":"who.html","id":"lindsey-smith-phd","chapter":"2 Contributors","heading":"2.2.8 Lindsey Smith, PhD","text":"Dr. Lindsey Smith data scientist IDEA Public Schools contributes mission goals IDEA providing analyses reporting. Prior coming IDEA, associate professor instruction University Texas Austin Department Statistics Data Science. Lindsey holds BS Biochemistry, MS Statistics, PhD Educational Psychology focus Quantitative Methods University Texas Austin.","code":""},{"path":"who.html","id":"karina-pacheco","chapter":"2 Contributors","heading":"2.2.9 Karina Pacheco","text":"","code":""},{"path":"who.html","id":"connor-caldwell","chapter":"2 Contributors","heading":"2.2.10 Connor Caldwell","text":"Connor Caldwell statistician R&Team supports Human Assets division. holds BA Statistics Cognitive Science Rice University MS Information Science Texas &M International University.","code":""},{"path":"who.html","id":"jose-f.-rodriguez","chapter":"2 Contributors","heading":"2.2.11 Jose F. Rodriguez","text":"Jose Rodriguez Human Assets Data Analyst IDEA background statistics. supports IDEA’s goals transforming information insights drive staff performance management reward programs.","code":""},{"path":"who.html","id":"colleen-skinner","chapter":"2 Contributors","heading":"2.2.12 Colleen Skinner","text":"Colleen Skinner Human Assets Data Analyst R&Team IDEA. earned BA Statistics Data Science Rice University.","code":""},{"path":"who.html","id":"hilary-doe","chapter":"2 Contributors","heading":"2.2.13 Hilary Doe","text":"Hilary Doe Data Analyst supporting IDEA’s Growth team. joining IDEA August 2025, Hilary worked Senior Data Analyst Prenatal--3 Policy Impact Center Vanderbilt University (formerly Child Family Research Partnership UT Austin). role managed, merged, cleaned, analyzed large datasets primarily program evaluation research programs serving young children families. Hilary received PhD Applied Developmental Psychology University Pittsburgh 2017 BA Psychology Messiah College.","code":""},{"path":"who.html","id":"what-weve-contributed","chapter":"2 Contributors","heading":"2.3 What we’ve contributed","text":"team among ’s annual goals following:R&Team member create 6 entries R&Manual July 1, 2022 June 30, 2023; entries can include documentation methods, data access, data definitions, projects, insights.Shiny app embedded allows us track contributions year.includes simple interactive ggplot graph (made interactive excellent {ggiraph} package) well table info merged pull request.Note clicking hyperlinked pull request number take diff page Github merged pull request.","code":""},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"the-data-warehouse-and-how-to-access-it","chapter":"3 The Data Warehouse and How to Access It","heading":"3 The Data Warehouse and How to Access It","text":"first section follows provides lots context IDEA’s data warehouse., however, rush want go accessing data warehouse, skip section 3.2 accessing R .","code":""},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"the-data-warehouse","chapter":"3 The Data Warehouse and How to Access It","heading":"3.1 The Data Warehouse","text":"‘data warehouse’ actually collection disparate databases hosted IDEA Public Schools. databases used host original source data, used data model production applications, others site two points.IDEA ~28 servers hosting SQL Server databases, R&typically accesses 13 servers hosting 126 databases 313 distinct tables. ’s lot, sure.","code":""},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"core-data-warehouse-server-configuration","chapter":"3 The Data Warehouse and How to Access It","heading":"3.1.1 Core data warehouse server configuration","text":"facts scheduled change May-June 2022. team moving servers Rackspace -prem result Data warehousing team upgrading servers maintenance warehouse.Check back updates!servers islands unto , rather form small economy data flows, data moves source servers, production servers (.e., sweetspot us) reporting servers host transformed data Logi-powered Locus dashboards.\nFigure 3.1: Data warehouse initially stored ‘src_` databases ’DS’ servers flows right towads Logi hosted Locus dashboards.\nFigure 3.1 shows flows data warehouse, essentially move left right. TheDS-* servers host databases holding source data. data processed saved databases two production servers (PROD1 PROD2). two production servers host data R&uses analysis, know source data comes often helpful. reporting servers—RS1 RS2 serve transformed flat files serve data layer Logi PowerBI, serve Locus dashboards hub.following sections provide details databases might found server.","code":""},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"src-servers","chapter":"3 The Data Warehouse and How to Access It","heading":"3.1.1.1 SRC Servers","text":"servers source data various applications landed.SRC1 hosted RGVPDSD-DWSRC1 serves source PROD1. data hosted RGVPDSD-DWSRC1 mirrors various SISes (.e., Schools data PowerSchool, Focus, Skyward) TX (Travis), LA, FL, OH.\nDatabases:\nlk_Schools\nMaster_Schools\nNewSchoolsSetup\nSchools_YearlySnapShot\nSRC_AD\nSRC_Florida_Schools\nSRC_Florida_Schools_Focus\nSRC_Louisiana_Schools\nSRC_Ohio_Schools\nSRC_Texas_Schools\nSRC_Texas_Travis_Schools\nSSISTemp\nTravisSnapshotData\n\nSRC1 hosted RGVPDSD-DWSRC1 serves source PROD1. data hosted RGVPDSD-DWSRC1 mirrors various SISes (.e., Schools data PowerSchool, Focus, Skyward) TX (Travis), LA, FL, OH.Databases:\nlk_Schools\nMaster_Schools\nNewSchoolsSetup\nSchools_YearlySnapShot\nSRC_AD\nSRC_Florida_Schools\nSRC_Florida_Schools_Focus\nSRC_Louisiana_Schools\nSRC_Ohio_Schools\nSRC_Texas_Schools\nSRC_Texas_Travis_Schools\nSSISTemp\nTravisSnapshotData\nDatabases:lk_SchoolsMaster_SchoolsNewSchoolsSetupSchools_YearlySnapShotSRC_ADSRC_Florida_SchoolsSRC_Florida_Schools_FocusSRC_Louisiana_SchoolsSRC_Ohio_SchoolsSRC_Texas_SchoolsSRC_Texas_Travis_SchoolsSSISTempTravisSnapshotDataSRC2 hosted RGVPDSD-DWSRC2 serves source PROD2 exclusively source data assessment platforms like Edcite, Illuminate DnA, AP, IB, ACT, SAT.\nDatabases:\nlk_Schools\nSRC_Accountability\nSRC_ACT\nSRC_AP\nSRC_Dibles\nSRC_EA\nSRC_Edcite\nSRC_Edulastic\nSRC_EXPLORER\nSRC_IB\nSRC_Illuminate_LA\nSRC_NWEA\nSRC_PLAN\nSRC_SAT\nSRC_SchoolCity\nSRC_StateAssessments\nSRC_TSIAccuplacer\n\nSources:\nSee database names just \nPROD1 lookup data students schools\n\nTargets:\nPROD2\n\nSRC2 hosted RGVPDSD-DWSRC2 serves source PROD2 exclusively source data assessment platforms like Edcite, Illuminate DnA, AP, IB, ACT, SAT.Databases:\nlk_Schools\nSRC_Accountability\nSRC_ACT\nSRC_AP\nSRC_Dibles\nSRC_EA\nSRC_Edcite\nSRC_Edulastic\nSRC_EXPLORER\nSRC_IB\nSRC_Illuminate_LA\nSRC_NWEA\nSRC_PLAN\nSRC_SAT\nSRC_SchoolCity\nSRC_StateAssessments\nSRC_TSIAccuplacer\nDatabases:lk_SchoolsSRC_AccountabilitySRC_ACTSRC_APSRC_DiblesSRC_EASRC_EdciteSRC_EdulasticSRC_EXPLORERSRC_IBSRC_Illuminate_LASRC_NWEASRC_PLANSRC_SATSRC_SchoolCitySRC_StateAssessmentsSRC_TSIAccuplacerSources:\nSee database names just \nPROD1 lookup data students schools\nSources:See database names just abovePROD1 lookup data students schoolsTargets:\nPROD2\nTargets:PROD2SRC3 hosted RGVPDSD-DWSRC3 serves source PROD1. Databases focus source data variance external systems, including Naviance, Tyler Munis, Teachboost, Schoolmint, slew individualized learning/blended learning platforms.\nDatabases:\nlk_Schools\nSRC_Alumni\nSRC_AssetPanda\nSRC_CollegeSuccess\nSRC_CornerStoneEvaluations\nSRC_DMac\nSRC_FitnessGram\nSRC_GetRatings\nSRC_GoodsideHealth\nSRC_HealthOfficeAnywhere\nSRC_HR\nSRC_JobVite\nSRC_NationalClearingHouse\nSRC_Naviance\nSRC_OpsCampusRanking\nSRC_PanoramaSurveys\nSRC_Recruitment\nSRC_SchoolMint\nSRC_StaffRetention\nSRC_STMATH\nSRC_Stream\nSRC_Teachboost\nSRC_TSI\nSRC_TTM\nSRC_TylerMunis\nSRC_Wrike\nSRC_Zendesk\nSRC_ZendeskDev\nTCPAppDev\n\nSources:\nSee database names just \nPROD1 lookup data students schools\n\nTargets:\nPROD1\n\nSRC3 hosted RGVPDSD-DWSRC3 serves source PROD1. Databases focus source data variance external systems, including Naviance, Tyler Munis, Teachboost, Schoolmint, slew individualized learning/blended learning platforms.Databases:\nlk_Schools\nSRC_Alumni\nSRC_AssetPanda\nSRC_CollegeSuccess\nSRC_CornerStoneEvaluations\nSRC_DMac\nSRC_FitnessGram\nSRC_GetRatings\nSRC_GoodsideHealth\nSRC_HealthOfficeAnywhere\nSRC_HR\nSRC_JobVite\nSRC_NationalClearingHouse\nSRC_Naviance\nSRC_OpsCampusRanking\nSRC_PanoramaSurveys\nSRC_Recruitment\nSRC_SchoolMint\nSRC_StaffRetention\nSRC_STMATH\nSRC_Stream\nSRC_Teachboost\nSRC_TSI\nSRC_TTM\nSRC_TylerMunis\nSRC_Wrike\nSRC_Zendesk\nSRC_ZendeskDev\nTCPAppDev\nDatabases:lk_SchoolsSRC_AlumniSRC_AssetPandaSRC_CollegeSuccessSRC_CornerStoneEvaluationsSRC_DMacSRC_FitnessGramSRC_GetRatingsSRC_GoodsideHealthSRC_HealthOfficeAnywhereSRC_HRSRC_JobViteSRC_NationalClearingHouseSRC_NavianceSRC_OpsCampusRankingSRC_PanoramaSurveysSRC_RecruitmentSRC_SchoolMintSRC_StaffRetentionSRC_STMATHSRC_StreamSRC_TeachboostSRC_TSISRC_TTMSRC_TylerMunisSRC_WrikeSRC_ZendeskSRC_ZendeskDevTCPAppDevSources:\nSee database names just \nPROD1 lookup data students schools\nSources:See database names just abovePROD1 lookup data students schoolsTargets:\nPROD1\nTargets:PROD1SRC4 hosted RGVPDSD-DWSRC4 serves source PROD1. Databases focus source data various individualized learning/blended learning platforms.\nDatabases:\nlk_Schools\nSRC_AR\nSRC_BlendedLearning\nSRC_IHT\nSRC_IReady\n\nSources:\nSee database names just \nPROD1 lookup data students schools\n\nTargets:\nPROD1\n\nSRC4 hosted RGVPDSD-DWSRC4 serves source PROD1. Databases focus source data various individualized learning/blended learning platforms.Databases:\nlk_Schools\nSRC_AR\nSRC_BlendedLearning\nSRC_IHT\nSRC_IReady\nDatabases:lk_SchoolsSRC_ARSRC_BlendedLearningSRC_IHTSRC_IReadySources:\nSee database names just \nPROD1 lookup data students schools\nSources:See database names just abovePROD1 lookup data students schoolsTargets:\nPROD1\nTargets:PROD1SRC5 hosted RGVPDSD-DWSRC5 serves source PROD1. Databases focus source data Microsoft Teams.\nDatabases:\nTeamsAttendance\n\nSources:\nSee database names just \nPROD1 lookup data students schools\n\nTargets:\nPROD1\n\nSRC5 hosted RGVPDSD-DWSRC5 serves source PROD1. Databases focus source data Microsoft Teams.Databases:\nTeamsAttendance\nDatabases:TeamsAttendanceSources:\nSee database names just \nPROD1 lookup data students schools\nSources:See database names just abovePROD1 lookup data students schoolsTargets:\nPROD1\nTargets:PROD1","code":""},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"prod-servers","chapter":"3 The Data Warehouse and How to Access It","heading":"3.1.1.2 PROD Servers","text":"PROD1 hosted RGVPDSD-DWPRD1 contains variety databases sourced SRC servers except SRC2. key students, schools, regions data found \nDatabases:\nADA\nBlendedLearning\nCollegeSuccess\nDashboardSettings\ndwSnapshots\nEnrollment\nGoodSideHealth\nHealthOfficeAnywhere\nIndividualized Learning\n\nMatriculation\nPersistence\nPROD1\nPROD1New\nProductDevelopment\nSSISDeprecation\nSSISTemp\nStaffing\nStudentPersistence\n\nSources:\nRGVPDSD-DWSRC1\nRGVPDSD-DWSRC2\nRGVPDSD-DWSRC3\nRGVPDSD-DWSRC4\nRGVPDSD-DWSRC5\nRGVPDSD-SQLCSI\nRGVPDSD-SQLDI\nRGVPDSD-TCPSQL\n\nPROD1 hosted RGVPDSD-DWPRD1 contains variety databases sourced SRC servers except SRC2. key students, schools, regions data found isDatabases:\nADA\nBlendedLearning\nCollegeSuccess\nDashboardSettings\ndwSnapshots\nEnrollment\nGoodSideHealth\nHealthOfficeAnywhere\nIndividualized Learning\n\nMatriculation\nPersistence\nPROD1\nPROD1New\nProductDevelopment\nSSISDeprecation\nSSISTemp\nStaffing\nStudentPersistence\nDatabases:ADABlendedLearningCollegeSuccessDashboardSettingsdwSnapshotsEnrollmentGoodSideHealthHealthOfficeAnywhereIndividualized LearningITMatriculationPersistencePROD1PROD1NewProductDevelopmentSSISDeprecationSSISTempStaffingStudentPersistenceSources:\nRGVPDSD-DWSRC1\nRGVPDSD-DWSRC2\nRGVPDSD-DWSRC3\nRGVPDSD-DWSRC4\nRGVPDSD-DWSRC5\nRGVPDSD-SQLCSI\nRGVPDSD-SQLDI\nRGVPDSD-TCPSQL\nSources:RGVPDSD-DWSRC1RGVPDSD-DWSRC2RGVPDSD-DWSRC3RGVPDSD-DWSRC4RGVPDSD-DWSRC5RGVPDSD-SQLCSIRGVPDSD-SQLDIRGVPDSD-TCPSQLPROD2 hosts assessment data states. source server RS2 includes assessments (e.g., IAs, bi-weekly unit assessments, AP, IB) data accountability tables.\nDatabases:\nAssessments\nlk_Schools\nPROD2\nSSISDeprecation\nSSISTemp\nSchools: actually contains inventories school level, like lists employees, equipment asset inventories, students schedules, correspondences teachers students.\n\nPROD2 hosts assessment data states. source server RS2 includes assessments (e.g., IAs, bi-weekly unit assessments, AP, IB) data accountability tables.Databases:\nAssessments\nlk_Schools\nPROD2\nSSISDeprecation\nSSISTemp\nSchools: actually contains inventories school level, like lists employees, equipment asset inventories, students schedules, correspondences teachers students.\nAssessmentsAssessmentslk_Schoolslk_SchoolsPROD2PROD2SSISDeprecationSSISDeprecationSSISTempSSISTempSchools: actually contains inventories school level, like lists employees, equipment asset inventories, students schedules, correspondences teachers students.Schools: actually contains inventories school level, like lists employees, equipment asset inventories, students schedules, correspondences teachers students.","code":""},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"server-table-and-field-lookup","chapter":"3 The Data Warehouse and How to Access It","heading":"3.1.2 Server, Table, and Field Lookup","text":"easiest way explore databases tables available data warehouse use ideadata packages’ view_warehouse_metadata() function, launch filterable table RStudio IDEA.details accessing data warehouse R following section.","code":"\nlibrary(ideadata)\n\nview_warehouse_metadata()"},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"accessing-the-data-warehouse-from-r","chapter":"3 The Data Warehouse and How to Access It","heading":"3.2 Accessing the data warehouse from R","text":"straightforward way access data warehouse use , bespoke r package: ideadata, maintained github documentation site.","code":""},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"installation","chapter":"3 The Data Warehouse and How to Access It","heading":"3.2.1 Installation","text":"Since ideadata internal IDEA package, development version, installed GitHub :","code":"\n#install.packages(\"remotes\")\nremotes::install_github(\"idea-analytics/ideadata\")\n\n#renv::install(\"idea-analytics/ideadata@main\") also works"},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"example","chapter":"3 The Data Warehouse and How to Access It","heading":"3.2.2 Example","text":"’s connect Schools table warehouse.schools object tbl object. means works dplyr verbs functions, happens background dplyr dbplyr generate SQL sent database connected computation (e.g., filtering, selecting, joining, calculations, aggregation) completed remote SQL Server instance computer.Nevertheless, eventually want pull data onto machine want use R Python can (like modeling graphics) database can’t .Pulling data easy [dplyr::collect()](janitor::clean_names() snake_cases column names).","code":"\nlibrary(dplyr)\nlibrary(ideadata)\n\nschools <- get_schools()\n\nglimpse(schools)\nlibrary(dplyr)\n\nschools_df <- schools %>% \n  collect() %>% \n  janitor::clean_names()"},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"what-if-i-am-pulling-down-lots-of-data-say-millions-of-rows","chapter":"3 The Data Warehouse and How to Access It","heading":"3.2.2.1 What if I am pulling down lots of data (say, millions of rows)?","text":"instance database connection may fail. ’s ideal, happens. One way deal pull data piecemeal. collector() function ideadata makes task trivial. takes column names arguments (unquote) table want pull columns used break data smaller sets data pulled database onto computer recombined single table.ideadata package clever updates knowledge data warehouse every time load package library(ideadata). However need access warehouse, requires VPN/behind firewall. make sure true invoking package!","code":"\n\nschools_df <- schools %>% \n  collector(SchoolState, CountyName) %>% \n  janitor::clean_names()"},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"finding-things-in-the-data-warehouse","chapter":"3 The Data Warehouse and How to Access It","heading":"3.2.3 Finding things in the data warehouse","text":"ideadata package function open sortable, filterable, searchable table RStudio idea: view_warehouse_meta_data()","code":""},{"path":"the-data-warehouse-and-how-to-access-it.html","id":"where-to-learn-more","chapter":"3 The Data Warehouse and How to Access It","heading":"3.2.4 Where to learn more","text":"ideadata ’s documentation . can’t find answer , reach Chris Haid (’s responsible craziness).Go article set credentials R warehouse can authenticate authorize verified userAnother important aspect warehouse sources system student data SIS: PowerSchool. PowerSchool Tables Data Dictionary helpful resource understanding fields relationships tables.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"key-tables-measures-and-metrics","chapter":"4 Key Tables, Measures, and Metrics","heading":"4 Key Tables, Measures, and Metrics","text":"Within chapter find tables metrics IDEA Public\nSchools stakeholders interested .Note individual table may contain information \ninterest. additional information extracted \ndifferent table joined. Information regarding various types\njoins can found .","code":""},{"path":"key-tables-measures-and-metrics.html","id":"the-students-table","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.1 The Students Table","text":"Students table probably important table . \ncontains historical student personal data since IDEA’s inception.use table know subpopulation student belongs .\nAlso, can link table student data using \n[StudentNumber] field.Table: [RGVPDSD-DWPRD1].[PROD1].[Schools].[Students]Main fields: [AcademicYear] [StudentNumber] | [SchoolNumber] |\n[GradeLevelID] | [EnrollmentStatus] | [Gender] | [SPED] | [ELLCode]\n| [PrimaryDisabilityCode ] | [SecondaryDisabilityCode ] |\n[TertiaryDisabilityCode ] | [EconomicDisadvantageCode] |\n[FederalHispanicFlag] | [FederaRaceI] | [FederaRaceA] | [FederaRaceB]\n| [FederaRaceP] | [FederaRaceW] |[EntryDate] | [ExitDate] |\n[RowIsCurrent]?:[EnrollmentStatus]:\nEnrollmentStatus = 0, student /active student\ncorresponding academic year,\nEnrollmentStatus = 2, student left district \ncompleting academic year,\nEnrollmentStatus = 3, student graduated IDEA’s high\nschool.\n[EnrollmentStatus]:EnrollmentStatus = 0, student /active student\ncorresponding academic year,EnrollmentStatus = 2, student left district \ncompleting academic year,EnrollmentStatus = 3, student graduated IDEA’s high\nschool.[ELLCode]: English Learner (EL) .K.. Limited English\nProficiency (LEP)\nELLCode = 0, student identified EL\nstudent,\nELLCode = 1, student identified EL student,\nELLCode (0,1), student currently identified\nEL identified one,\nELLCode = “F”, student identified EL\nstudent First Year Monitoring status,\nELLCode = “S”, student identified EL\nstudent Second Year Monitoring status,\nELLCode = 3, student identified EL\nstudent Third Year Monitoring status,\nELLCode = 4, student identified EL\nstudent Fourth Year Monitoring status,\nELLCode = 5, student identified EL\nstudent one point 4 years ago.\n[ELLCode]: English Learner (EL) .K.. Limited English\nProficiency (LEP)ELLCode = 0, student identified EL\nstudent,ELLCode = 1, student identified EL student,ELLCode (0,1), student currently identified\nEL identified one,ELLCode = “F”, student identified EL\nstudent First Year Monitoring status,ELLCode = “S”, student identified EL\nstudent Second Year Monitoring status,ELLCode = 3, student identified EL\nstudent Third Year Monitoring status,ELLCode = 4, student identified EL\nstudent Fourth Year Monitoring status,ELLCode = 5, student identified EL\nstudent one point 4 years ago.EL Reclassification EL passed Texas English\nLanguage Proficiency Assessment System (TELPAS) reclassified\nNon-EL monitored 4 years. reclassification, \nstudent’s ELLCode change 0, move \ncodes 4 years monitoring status change \nELLCode 5EL Reclassification EL passed Texas English\nLanguage Proficiency Assessment System (TELPAS) reclassified\nNon-EL monitored 4 years. reclassification, \nstudent’s ELLCode change 0, move \ncodes 4 years monitoring status change \nELLCode 5[SPED]: SPED students composed RISE Life Skills\nstudents, including Critical Student Intervention (CSI)\nstudents.\nSPED = 0, student identified SPED student,\notherwise SPED = 1.\n[SPED]: SPED students composed RISE Life Skills\nstudents, including Critical Student Intervention (CSI)\nstudents.SPED = 0, student identified SPED student,\notherwise SPED = 1.[InstructionalSettingCode]: Students classified \nSPED may receive additional services. services can found \nInstructionalSettingDescription column, linked \nspecific PEIMS\ncode:\nInstructionalSettingCode\nDescription\n0\nadditional SPED services\n1\nHomebound\n8\nVocational Adjustment Class/Program\n40\nMainstream\n41\nResource Room/Services < 21%\n42\nResource Room/Services 21 - <50%\n43\nResource Room/Services 50-60%\n44\nResource Room/Services > 60%\n96\nHome Campus - Separate Campus\n[InstructionalSettingCode] = 43 44, student \ntypically RISE.\n[InstructionalSettingCode] = 8 96, student \ntypically Thrive.\nNote 2022-2023, Thrive students recoded reflect\nhome campuses, necessarily campus \nprovides services.\n[InstructionalSettingCode]: Students classified \nSPED may receive additional services. services can found \nInstructionalSettingDescription column, linked \nspecific PEIMS\ncode:[InstructionalSettingCode] = 43 44, student \ntypically RISE.[InstructionalSettingCode] = 8 96, student \ntypically Thrive.Note 2022-2023, Thrive students recoded reflect\nhome campuses, necessarily campus \nprovides services.[DisabilityCode]\nDisabilityCode\nDescription\n0\ndisability\n1\nOrthopedic impairment\n2\nhealth impairment\n3\nAuditory impairment\n4\nVisual impairment\n5\nDeaf-Blind\n6\nIntellectual disability\n7\nEmotional disturbance\n8\nLearning disability\n9\nSpeech impairment\n10\nAutism\n13\nTraumatic brain injury\n14\nNoncategorical early childhood\n[DisabilityCode][EconomicDisadvantageCode]: .K.ECD\nEconomicDisadvantageCode = 0, student \nidentified economically disadvantaged, otherwise student\nidentified economically disadvantaged,\nEconomicDisadvantageCode = 1, student identified\neconomically disadvantaged eligible free meals,\nEconomicDisadvantageCode = 2, student also identified\neconomically disadvantaged eligible \nreduced-price meals,\nEconomicDisadvantageCode = 99, means student \nidentified economically disadvantaged another\neconomic disadvantage.\nEconomicDisadvantageCode = 0, student \nidentified economically disadvantaged, otherwise student\nidentified economically disadvantaged,EconomicDisadvantageCode = 1, student identified\neconomically disadvantaged eligible free meals,EconomicDisadvantageCode = 2, student also identified\neconomically disadvantaged eligible \nreduced-price meals,EconomicDisadvantageCode = 99, means student \nidentified economically disadvantaged another\neconomic disadvantage.ECDFlag consolidates codes 0/1 indicator\nECDFlag = TRUE (1), student identified \neconomically disadvantaged,\nECDFlag = FALSE (0), student identified \neconomically disadvantaged.\nECDFlag = TRUE (1), student identified \neconomically disadvantaged,ECDFlag = FALSE (0), student identified \neconomically disadvantaged.Race / Ethnicity: like TX\nstudent identifies Hispanic Latino, student \nclassified Hispanic/Latino,\nstudent identify Hispanic Latino \nselected one race, student classified race,\nstudent identify Hispanic Latino \nselected one race, student classified two \nraces.\nstudent identifies Hispanic Latino, student \nclassified Hispanic/Latino,student identify Hispanic Latino \nselected one race, student classified race,student identify Hispanic Latino \nselected one race, student classified two \nraces.[RowIsCurrent]: Indicates current row student,\nused current school year","code":"SELECT DISTINCT \n [StudentNumber], \n [PrimaryDisabilityCode] AS [DisabilityCode], \n [PrimaryDisabilityDescription] AS [DisabilityDescription]\n\n FROM (\n\nSELECT DISTINCT [StudentNumber],[PrimaryDisabilityCode], [PrimaryDisabilityDescription]\n\n FROM [PROD1].[Schools].[Students]\n WHERE AcademicYear='2018-2019'\n\n UNION ALL\n\nSELECT DISTINCT  [StudentNumber], [SecondaryDisabilityCode], [SecondaryDisabilityDescription]\n\n FROM [PROD1].[Schools].[Students]\n WHERE AcademicYear='2018-2019'\n\n UNION ALL\n\nSELECT DISTINCT  [StudentNumber], [TertiaryDisabilityCode], [TertiaryDisabilityDescription]\n\n FROM [PROD1].[Schools].[Students]\n WHERE AcademicYear='2018-2019') A WHERE [PrimaryDisabilityDescription] <> '' ORDER BY StudentNumber"},{"path":"key-tables-measures-and-metrics.html","id":"common-queries","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.1.1 Common queries","text":"frequently need disaggregate data year, region, school, \n, retaining basic information student. Students\ntable directly contain school region names, need\njoin Schools table Regions table.Two common queries involving students include:producing roster students fit certain\ncharacteristics andcounting number students fit certain characteristics.Suppose tracking number seniors track go college.\nfollowing two queries pull roster currently enrolled\nseniors:SQL example:R example:However, count number seniors school region, group\nstudents characteristics, use aggregate\nfunction count number per group.SQL example:R example:IDEA continues expand, important reexamine tables\nincorporate differences demographics coding, nomenclature, etc.,\naccount states regional authorizers using different\nconventions.","code":"SELECT [AcademicYear]\n      ,C.[RegionDescription]  \n      ,B.[SchoolName]\n      ,[GradeLevelID]\n      ,[StudentNumber]\n    ,[StudentFullName]\n    ,[FirstName]\n    ,[MiddleInitial]\n    ,[LastName]\n\n--join Schools and Regions tables\n  FROM [RGVPDSD-DWPRD1].[PROD1].[Schools].[Students] AS A\n    LEFT JOIN [RGVPDSD-DWPRD1].[PROD1].[Schools].[Schools] AS B\n      ON A.[SchoolNumber] = B.[SchoolNumber]\n    INNER JOIN [RGVPDSD-DWPRD1].[PROD1].[Schools].[Regions] AS C\n      ON B.[RegionID] = C.[RegionID]\n\n--filter for currently enrolled seniors in 2021-2022\n  WHERE [AcademicYear] = '2021-2022'\n    AND [GradeLevelID] = '12'\n    AND [ExitDate] > '2022-05-01'\n    AND [RowIsCurrent] = '1'\n\n--optional, filter RISE (43, 44) and Thrive students (8, 96)\n--  AND [InstructionalSettingCode] NOT IN ('43', '44', '8', '96')\n    \nget_students() %>%\n\n# filter for currently enrolled seniors in 2021-2022\n  filter(AcademicYear == \"2021-2022\",\n         GradeLevelID == \"12\",\n         ExitDate > \"2022-05-01\",\n         RowIsCurrent == 1) %>%\n  \n# optional, filter RISE (43, 44) and Thrive students (8, 96)\n# filter(!(InstructionalSettingCode %in% c(\"43\", \"44\", \"8\", \"96\"))) %>%\n  \n# join Schools and Regions tables\n  inner_join(get_schools(),\n             by = c(\"SchoolNumber\" = \"SchoolNumber\")) %>%\n  inner_join(get_regions(),\n             by = c(\"RegionID\" = \"RegionID\")) %>%\n  \n  select(AcademicYear,\n         RegionDescription,\n         SchoolName,\n         GradeLevelID,\n         StudentNumber,\n         StudentFullName,\n         FirstName,\n         MiddleInitial,\n         LastName)SELECT [AcademicYear]\n    ,CASE\n         WHEN C.[RegionDescription] IN ('Austin', 'West San Antonio', 'East San Antonio') THEN 'Central Texas'\n           WHEN C.[RegionDescription] IN ('Lower Valley', 'Mid Valley', 'Upper Valley') THEN 'Rio Grande Valley'\n           ELSE C.[RegionDescription]\n       END AS [Area]\n      ,C.[RegionDescription]\n      ,B.[SchoolName]\n      ,[GradeLevelID]\n      \n--count number of student IDs to get total per group\n      ,COUNT([StudentNumber]) AS [EnrolledSeniors]\n      \n  FROM [RGVPDSD-DWPRD1].[PROD1].[Schools].[Students] AS A\n    LEFT JOIN [RGVPDSD-DWPRD1].[PROD1].[Schools].[Schools] AS B  \n        ON A.[SchoolNumber] = B.[SchoolNumber]  \n    INNER JOIN [RGVPDSD-DWPRD1].[PROD1].[Schools].[Regions] AS C \n        ON B.[RegionAltID] = C.[RegionID]  \n        \n  WHERE [AcademicYear] = '2022-2023' \n      AND [ExitDate] > '2022-08-17'\n      AND [RowIsCurrent] = '1'\n      AND [GradeLevelID] = '12'\n--  AND [InstructionalSettingCode] NOT IN ('43', '44', '8', '96')\n\n--grouping variables to determine aggregates    \n  GROUP BY [AcademicYear]\n      ,[Area]\n          ,C.[RegionDescription]\n          ,B.[SchoolName]\n          ,[GradeLevelID]\n  ORDER BY [Area]\n          ,[RegionDescription]\n      ,[SchoolName]\nget_students() %>%\n  \n  filter(AcademicYear == \"2022-2023\",\n         GradeLevelID == \"12\",\n         ExitDate > lubridate::today(),\n         RowIsCurrent == 1) %>%\n  # filter(!(InstructionalSettingCode %in% c(\"43\", \"44\", \"8\", \"96\"))) %>%\n  \n  inner_join(get_schools(),\n             by = c(\"SchoolNumber\" = \"SchoolNumber\")) %>%\n  inner_join(get_regions(),\n             by = c(\"RegionAltID\" = \"RegionID\")) %>%\n\n  # grouping variables to determine aggregates  \n  group_by(RegionDescription,\n           SchoolName,\n           GradeLevelID) %>%\n  \n  # count number of students to get total per group\n  summarize(EnrolledSeniors = n()) %>%\n  \n  mutate(Area = case_when(\n    RegionDescription %in% c(\"Lower Valley\", \"Mid Valley\", \"Upper Valley\") ~ \"Rio Grande Valley\",\n    RegionDescription %in% c(\"Austin\", \"West San Antonio\", \"East San Antonio\") ~ \"Central Texas\",\n    TRUE ~ RegionDescription\n  )) %>%\n  arrange(Area,\n          RegionDescription,\n          SchoolName)"},{"path":"key-tables-measures-and-metrics.html","id":"schools-and-regions","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.2 Schools and regions","text":"","code":""},{"path":"key-tables-measures-and-metrics.html","id":"schools-table","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.2.1 Schools table","text":"Schools table provides essential information school,\nincluding contact information, full short names, regions,\ncan connected tables via SchoolNumber.Database: [RGVPDSD-DWPRD1].[PROD1].[Schools].[Schools]Main metrics: School names, PowerSchool numbers, state IDs, regionsImportant columns:[SchoolNumber]: official PowerSchool school ID; frequently\nused link tables[SchoolName]: full name school (e.g., IDEA Frontier\nCollege Preparatory)[SchoolShortName]: campus name (e.g., Frontier)[StateSchoolNumber]: number used campus’ respective state\nreporting (note: column may correct values \nschools)[SchoolAbbreviation]: abbreviation school name (commonly\nused)[SchoolLowestGrade]: lowest grade level, PK = -1, K = 0[SchoolHighestGrade]: highest grade level[SchoolStreet], [SchoolCity], [SchoolState], [SchoolZipCode],\n[SchoolPhone], [SchoolFax], [PrincipalName], [PrincipalPhone],\n[PrincipalEmail], [CountyNumber], [CountyName]: contact\ninformation[RegionID]: official IDEA region describing location \nschool; links Regions table[VPofSchools]: regional Vice President (VP) oversees \nschool; links Employees table using EmployeeKey[ExecutiveDirector]: Executive Director (ED) Regional\nSuperintendent oversees region; links Employees table\nusing EmployeeKey[RegionDirectorOfOperations]: Regional Director Operations\n(RDO) oversees region; links Employees table using\nEmployeeKey[CollegeSuccessDirector]: Director College Counseling (DCC)\nschool; links Employees table using EmployeeKey[Area]: describes school division RGV,\nTexas, IPS & SA, .e. superintendent oversees school[RegionAltID]: describes Subregion, applicable (default\nRegion); mostly used RGV schools divide Lower, Mid\nUpper Valley, San Antonio schools East West; links\nRegions table[IsDeprecated]: 0/1 indicator open vs. closed schools old\nvs. new school numbers. Oscar Dunn coded 1, since closed \nend 2021-2022. two Tampa schools (Hope Victory) \n4 rows, 2 school number used 2021-2022 2 \nnew school numbers used 2022-2023 school year. Note: \nneeding data Hope Victory 2021-2022, need\nuse old school numbers IsDeprecated == 1. want\ndata current year, need filter IsDeprecated\n== 0.Context:[SchoolName] column PowerSchool name school, \nnecessarily official name. Many high school names PowerSchool\nshortened “College Prep” instead “College Preparatory”.\nschools may officially named “IDEA Academy/College\nPreparatory [ShortName]”.Note Middle School High School administered \nsingle College Preparatory; however, receive separate\nPowerSchool instances.historical reasons, IDEA Academy Donna labeled “IDEA\nAcademy Primary”, IDEA Middle School Donna labeled “IDEA\nAcademy”, IDEA College Preparatory Donna labeled “IDEA\nCollege Preparatory”. (suggested rename \nmodern names).IDEA San Juan Academy physically different\nlocation\nIDEA San Juan College Prep, rather \ncampus. Systems individuals traditionally shared\ncampuses, APO, distinct school.\n[SchoolShortName] also different - “San Juan AC” “San\nJuan CP”, respectively. (suggested rename \n“San Juan” pulling data.)IDEA Allan renamed IDEA Montopolis, older records may\nstill reflect name.IDEA Travis Academy -district partnership Midland ISD.\nRecords school may necessarily accurate \ninterpretable since values may reflect coding choices Midland\nISD.IDEA Amber Creek renamed IDEA Ambrose Freda Robinson (short\nname IDEA Robinson) 2022-2023 school year.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"regions-table","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.2.2 Regions table","text":"Regions table provides keys RegionDescription, can \nconnected tables via RegionID.Database: [RGVPDSD-DWPRD1].[PROD1].[Schools].[Regions]Main metrics: region numbers, region names, state, parent region (\napplicable)Important columns:[RegionID]: region number, used link back [Schools]\ntable[RegionDescription]: full name region subregion[State]: full name state[ParentRegion]: link region number contains \nsubregion; 0 usually combined regionsContext:IDEA originally started single school Donna, TX 2000, \nmade first expansions Quest Frontier 2006. notion\nregional structure outside Rio Grande Valley (RGV) \nstart IDEA expanded 2012, Allan (now Montopolis)\nopened Austin, Carver, San Antonio.IDEA open outside Texas Southern Louisiana\n(SOLA) region opened first schools, Bridge Innovation, \n\nInformally, RGV “super region” can divided Lower, Mid,\nUpper Valley, subregions parent\nregion (RGV). point, IDEA formally divided RGV schools \nLower Upper Valley regions, separate Executive\nDirector, Lower/Upper distinction longer officially\nused. RGV may also considered Area, governed Area\nSuperintendent rather Executive Director.Occasionally, Central Texas “super region” used include\nWest San Antonio, East San Antonio Austin regions, \nincluded Regions table.Area portfolio superintendent, includes\nmultiple regions. three Areas “RGV”, “Texas”, “IPS \nSA”, included [Schools] table (see entry).Different teams across IDEA may may split portfolios using\nLower/Upper Lower/Mid/Upper subregions East/West San\nAntonio. assigning regions RGV San Antonio schools, check\npartnering team see categorize RGV San Antonio\nschools.team use subregions, link Regions \nSchools table using [Regions].[RegionID] = [Schools].[RegionID]. \nteam uses Lower/Mid/Upper subregions, link using\n[Regions].[RegionID] = [Schools].[RegionAltID]. team uses \nLower/Upper subregions, need ask team divide\nportfolio schools.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"school-launch-year","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.2.3 School Launch Year","text":"IDEA opened new schools four states last 20+ years. IDEA\nAcademy IDEA College Preparatory Donna first two schools\nopen 2000-2001 [see also regions context]\n(https://idea-analytics.github.io/r_and_a_manual/key-tables-measures--metrics.html#regions-table).Need know year school opened? See LaunchSchoolYear\ncolumn Schools table, Dashboard database. fall 2023, \ntable includes 164 schools LaunchSchoolYear ranging \n2000-2001 2021-2022-2023.Table: [RGVPDRA-DASQL].[Dashboard].[dbo].[Schools]Important columns:[Name]: full name school, e.g., IDEA Achieve Academy[DisplayName]: campus name, like SchoolShortName, e.g., Achieve[RegionID]: IDEA region number describing location \nschool; links Regions table[CampusTypeID]: uses values 1 2 indicate campus \nAcademy College Prep, respectively[CountyDistrictCampusNumber]: number combining County,\nDistrict, Campus numbers, like SchoolNumber[LaunchSchoolYear]: school year school first opened;\nranges 2000-2001 2022-2023","code":""},{"path":"key-tables-measures-and-metrics.html","id":"school-scaling-status","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.2.4 School Scaling Status","text":"IDEA schools typically open grade levels present. \nyear operation includes addition grade levels \nfully scaled. Details find scaling status \nschool along sample R code pull information found :Table: [RGVPDSD-DWPRD2].[lk_Schools].[dbo].[SchoolsExtensions]Important columns:[SchoolName]: full name school (e.g., IDEA Donna Academy)[SchoolShortName]: campus name (e.g., Donna)[SchoolDesignation]: Academy, College Prep[StateSchoolNumber]: state school number[RegionID]: IDEA region number, links Regions table[RegionDescription]: region description (e.g., Rio Grande\nValley)[SchoolState]: school’s state (e.g., TX)[SchoolTypeOperation]: site status (e.g., full scale)[SchoolYearOperation]: year school launched (e.g., 2004)","code":"\n# load packages\nlibrary(tidyverse)\nlibrary(ideadata)\n\n# pull school name, campus name, region, and operation\noperation <- ideadata::get_table(.table_name = \"SchoolsExtensions\",\n                                 .schema = \"dbo\",\n                                 .database_name = \"lk_Schools\",\n                                 .server_name = \"RGVPDSD-DWPRD2\") %>% \n  dplyr::select(SchoolName,\n                SchoolShortName,\n                RegionDescription,\n                SchoolTypeOperation) %>% \n  collect()"},{"path":"key-tables-measures-and-metrics.html","id":"school-information-combined","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.2.5 School Information (combined)","text":"Beginning {ideadata} version 4.1.0, get_schools_extensions\nfunction available. function executes query pull school\ninformation including, among others, school name, region, launch\nyear, scaling status. following R code can used bring \nresults local R memory:","code":"\n# load packages\nlibrary(tidyverse)\nlibrary(ideadata)\n\n# pull school information\nschools <- ideadata::get_schools_extensions() %>% \n  collect()"},{"path":"key-tables-measures-and-metrics.html","id":"student-attendance","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.3 Student Attendance","text":"Daily attendance taken PowerSchool see students \npresently school . default, student assumed present\nmarked absent () teacher, tardy present\n(TP) school’s front office. Schools typically take \npreliminary attendance snapshot within first available period (.e.\neither homeroom 1st period) determine families need \ncalled. , school designates Official Attendance-Taking\nTime Period (OATT/OATP), roughly 10-minute window \nteachers class time submit day’s official\nattendance roster. OATP snapshot sent state \nAverage Daily Attendance (ADA) counts recorded \nwarehouse.Database: [RGVPDSD-DWPRD1].[PROD1].[Attendance].[Students] *\nCurrent Year + 3 Past Years table currently data \ncurrent year (2023-2024), last three years data (2022-2023,\n2021-2022, & 2020-2021). current year complete next\nyear begins, 2020-2021 data drop table new\nacademic year added.Attendance Data Prior 2019-2020: Database:\n[RGVPDSD-DWPRD1].[PROD1].[Attendance].[StudentsHistorical] * Academic\nYears: 2021-2022 - 2015-2016 official historical table.\ncolumns [Attendance].[Students] table. told\nacademic year ends data roll table.Main metrics: Full-day vs. half-day attendance; number absences;\nnew IDEA studentsImportant columns:[AcademicYear]: yyyy-yyyy[SchoolName]: IDEA [Campus] [SchoolType][schoolnumber]: Note column name stored \nlowercase.[SchoolShortName]: Campus name [SchoolType]: Academy College Prep[RegionDescription][GradeLevelID]: Uses values -1 0 PK K,\nrespectively.[GradeLevel]: Uses labels PK K.[AttStudentKey]: Identifying key student day.[WeekNumber]: Gives week school year.[DateNumber]: Gives day number school year (1, 2, 3,\n…, 180). Note schools different start dates \nDateNumber begins counting school’s FDOS year.[AttDate]: Gives actual date record.[Membership]: Indicates 1.00 full-day student (nearly\neveryone) 0.50 half-day student (Pre-K ).[Absences]: Indicates 1.00 full-day absence, 0.50 \nhalf-day absence.[VAbsences]: Unsure different [Absences].[SchoolYear]: Indicates 1 new--IDEA student, 2+ \nreturning student.[SchoolTypeOperation]: USE. information \nfound inaccurate. work creating table \ncorrected information school academic year, now,\n“Launching”, “Scaling”, “Fully Scaled” operation data stored\nExcel file Enrollment GitHub repo.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"common-queries-1","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.3.1 Common queries","text":"pull student daily attendance current school year \nspecific school certain date, can use functions pull\ndata:Average daily attendance (ADA) computed ratio present\nstudents enrolled students, can found using:needing attendance data enrollment purposes years\nprior 2015-2016, need use different table.Database [RGVPDSD-DWPRD1].[PROD1].[ADA].[StudentDailyMembership]\ntable contain daily attendance 2002-2003 2020-2021\nAcademic Years. However, data 2016-2017 2018-2019\nappears incorrect. use table daily attendance prior\n2015-2016 School Year. far fewer columns table, \nones needed calculating ADA /enrollment years prior \n2015-2016 .Important columns:[AcademicYear]: yyyy-yyyy[SchoolNumber]: Local school number[SchoolName]: Long school name[StudentNumber]: Local student ID number[GradeLevelID]: Numeric grade level, Pre-K == -1 K ==\n0[Membership]: Indicates 1.00 full-day student (nearly\neveryone) 0.50 half-day student (Pre-K )[AttDate]: Gives actual date record","code":"\ncurrent_school_year <- \"2021-2022\"\nour_school <- \"IDEA Walzem Academy\"\ndate <- \"2022-04-01\"\n\n# gets individual attendance records by student\n\nget_student_daily_attendance() %>%  # this is a built-in function for {ideadata}\n  filter(AcademicYear == current_school_year,\n         SchoolName == our_school,\n         AttDate == date) get_student_daily_attendance() %>%\n  rename(SchoolNumber = schoolnumber,\n         Region = RegionDescription) %>%\n  \n# pick a specific school and academic year \n  filter(AcademicYear == current_school_year,\n         SchoolName == our_school) %>%\n\n# groups by school for a particular day  \n  group_by(AcademicYear,\n           Region,\n           SchoolNumber,\n           SchoolName,\n           SchoolShortName,\n           SchoolType,\n           AttDate,\n           DateNumber) %>%\n  distinct() %>%\n  summarise(n_enrolled = sum(Membership),\n            n_absent = sum(Absences)) %>%\n\n# computes ADA as 1 - absence ratio\n  mutate(ada_percent = 1 - (n_absent/n_enrolled)) %>% "},{"path":"key-tables-measures-and-metrics.html","id":"other-uses","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.3.2 Other uses","text":"Attendance can also used obtain daily total enrollment \nmultiple levels, including grade level school.side enrollment student persistence. see \nenrollment used student persistence, jump student\npersistence\nsection.","code":"\nget_student_daily_attendance() %>%\n  rename(SchoolNumber = schoolnumber,\n         Region = RegionDescription) %>%\n  \n# pick a specific school and academic year \n  filter(AcademicYear == current_school_year,\n         SchoolName == our_school) %>%\n  \n# groups by grade level at a school per day  \n  group_by(SchoolNumber,\n           SchoolName,\n           SchoolShortName,\n           SchoolType,\n           GradeLevelID,\n           AttDate,\n           DateNumber) %>%                     \n  distinct() %>%\n  \n# counts total number of students enrolled  \n  summarise(n_enrolled = sum(Membership))"},{"path":"key-tables-measures-and-metrics.html","id":"student-persistence","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.4 Student Persistence","text":"Student Persistence one important measures Chiefs,\nVPs, School Leaders always monitoring understand efforts\nproviding high quality services students families. \norder student actualize benefits IDEA, student must\npersist high school. say student persisted student\nenrolled active entire academic school year, returned\nfollowing school year, enrolled active First Day\nPersistence (FDOP). words, student enrolled \nattended school FDOP two consecutive years. exception \nNew Students enroll FDOP, attend entire\nyear, return following year, enrolled active FDOP.\nnew students enrolled attending two consecutive\nFDOPs enrolled first FDOP still \nconsidered persisting.Although appears definition FDOP may changed time\n(previously listed manual Monday first week \nschool), according 22-23 Persistence Dictionary, FDOP \ndefined 11:59 PM 10th day school current academic year.\npracticality, unless automatic data pull 11:59 PM, \nFDOP use 11th day school.Unless holiday falls within first two weeks school, 11th\nday class 14 calendar days First Day School\n(FDOS).quick easy reference, either pull calendar check\ndate two weeks FDOS, take FDOS add 14!Example: first day school Johns IDEA school August 12,\n2024. John enrolled active August 26, 2024, FDOP \nschool (11th day class). John remained enrolled actively\nattending entire 2024-2025 academic year enrolled active\nFDOP following academic year (FDOP 2025-2026), \npersisted. , however, John enrolled active\n(attending) FDOP didn’t actually return \nSeptember, John count student persisted.Julia, enrolled began attending IDEA October, moving \nnew city. remained enrolled actively attending entire\n2024-2025 academic year enrolled active FDOP \nfollowing academic year (FDOP 2025-2026). persisted, even though\nenrolled FDOP 2024-2025.Finally, Jose active FDOP 2024-2025, left midyear attend\nanother school, returned IDEA still within 2024-2025\nacademic year, still active FDOP 2025, also \nconsidered persisting.way get accurate Persistence data using official\npersistence tables. many additional rules regarding \ncounted persistence. example, graduating seniors count\ntowards persistence. reasons exclusion include \nlimited : student migrant status, death, incarceration,\nexpected never enrolled, etc. Although relatively rare numbers,\ntypes exclusions impact calculations attempting\ncalculate persistence without official persistence tables.easy get confused looking current academic year’s\npersistence data dashboards. current tables dashboards \ntracking persistence FDOP last year FDOP year.\nInstead tracking persistence FDOP year current\ndate. can think Year--Date (YTD) persistence. Current\npersistence appear much higher historical persistence, \nYTD persistence slowly drops course academic year, \ndistinct drops certain times year.See screenshot chart Persistence Dashboard\ndemonstrating trend. 75.17% 2024-2025 indicate \nfinal persistence rate 2024-2025 academic year.Database: [RGVPDSD-DWPRD1].[StudentPersistence]Main metrics: District, Regional, School, Sub-population, Grade\nLevelGeneral Formula: 1 – (Leavers/Students) 1 -\n(FDOPLEAVERS/FDOPENROLLED + FDOPNEWENTRY)Tables:[Fact].[PersistenceCode]: table used calculate \npersistence rate current academic year. data updated\nevery three hours, weekdays. LeaverWeek column shows week \nstudent left district (beginning week containing FDOP,\nsecond week academic year). end \ncurrent school year persistence year ended (\nsummer months), week student leaves district captured\nULeaverWeek column. PersistenceWeek column shows \ncurrent week persistence school region \nstudent attends (week different across schools \nregions due differing start dates FDOPs).[Fact].[PersistenceCode]: table used calculate \npersistence rate current academic year. data updated\nevery three hours, weekdays. LeaverWeek column shows week \nstudent left district (beginning week containing FDOP,\nsecond week academic year). end \ncurrent school year persistence year ended (\nsummer months), week student leaves district captured\nULeaverWeek column. PersistenceWeek column shows \ncurrent week persistence school region \nstudent attends (week different across schools \nregions due differing start dates FDOPs).[Fact].[PersistenceCodeHistorical]: table contains \nfinal persistence data previous persistence years starting \n2018-2019 2022-2023. table updated \nprevious years’ data year closed next\npersistence year started.[Fact].[PersistenceCodeHistorical]: table contains \nfinal persistence data previous persistence years starting \n2018-2019 2022-2023. table updated \nprevious years’ data year closed next\npersistence year started.Context:Counts?calculate persistence, need filter students \nexcluded denominator, filter(FDOPCOUNTP == 1). limits\ndenominator students counted. \nfilter used looking current historical data.Leaver?leavers coded FDOPLEAVER = 1, FDOPLEAVER = 0 \ncurrent student.Useful Fields:\nAcademicYear: academic year\nRegionDescription: region student \nSchoolShortName: school student attends\nSchoolType: Academy College Prep\nStudentnumber: local student number\nGradeLevelID: student’s grade level (integer ranging -1\n= Pre-K 12)\nNewStudent: indicates student new (1) returning\n\n\nPersistenceWeek: current week persistence based \nstudent’s region school (ranges 1-52)\nLeaverWeek: persistence week student left \ndistrict\nULeaverWeek: persistence week student left \ndistrict last day school\nPersistenceCode: reason student left district\nPersistenceCategory: category reason falls \nstudent left district\nPersistenceComment: additional comments SIS clerk\nstudent left district\nEnrollmentStatus: contains enrollment status, \naccurate Use\nEntryDate: date student entered school \nparticular academic year date student started school\nnew campus\nExitDate: last day academic year (last day \nschool) day student left district (summer leavers\nsometimes snapped back last day school, beware)\nRecapture: 0/1 indicator students left \nreturned district. 1 = recaptured, 0 = recaptured.\nTrusted\nSummerLeaver: 0/1 indicator students leave \nsummer\nStudentGender: “M”/“F” gender indicator\nRace: race indicator combined ethnicity; ex.\n“WHITE-HISPANIC”\nIsHispanic: indicates whether student identifies \nHispanic; values = “HISPANIC” “NON-HISPANIC”\nMigrant: 0/1 indicator student’s migrant status\nLEP: 0/1 indicator student’s English Learner status.\nInaccurate Don’t Use\nSped: 0/1 indicator student’s SPED status\nEconDisad: 0/1 indicator student’s economic disadvantaged\nstatus. Inaccurate Don’t Use\nIsCSI: 0/1 indicator students identified CSI\nContinuousEnrollment: 0/1 indicates whether student \ncontinuously enrolled\nEntity: Indicates either TX IPS\nState: Indicates state student attends school\nAcademicYear: academic yearRegionDescription: region student inSchoolShortName: school student attendsSchoolType: Academy College PrepStudentnumber: local student numberGradeLevelID: student’s grade level (integer ranging -1\n= Pre-K 12)NewStudent: indicates student new (1) returning\n\nPersistenceWeek: current week persistence based \nstudent’s region school (ranges 1-52)LeaverWeek: persistence week student left \ndistrictULeaverWeek: persistence week student left \ndistrict last day schoolPersistenceCode: reason student left districtPersistenceCategory: category reason falls \nstudent left districtPersistenceComment: additional comments SIS clerk\nstudent left districtEnrollmentStatus: contains enrollment status, \naccurate UseEntryDate: date student entered school \nparticular academic year date student started school\nnew campusExitDate: last day academic year (last day \nschool) day student left district (summer leavers\nsometimes snapped back last day school, beware)Recapture: 0/1 indicator students left \nreturned district. 1 = recaptured, 0 = recaptured.\nTrustedSummerLeaver: 0/1 indicator students leave \nsummerStudentGender: “M”/“F” gender indicatorRace: race indicator combined ethnicity; ex.\n“WHITE-HISPANIC”IsHispanic: indicates whether student identifies \nHispanic; values = “HISPANIC” “NON-HISPANIC”Migrant: 0/1 indicator student’s migrant statusLEP: 0/1 indicator student’s English Learner status.\nInaccurate Don’t UseSped: 0/1 indicator student’s SPED statusEconDisad: 0/1 indicator student’s economic disadvantaged\nstatus. Inaccurate Don’t UseIsCSI: 0/1 indicator students identified CSIContinuousEnrollment: 0/1 indicates whether student \ncontinuously enrolledEntity: Indicates either TX IPSState: Indicates state student attends schoolExample pull calculate Student Persistence","code":"\n#Getting a connection to the Persistence table\npersistence_conn <- get_table(.table_name = \"PersistenceCode\", .database_name = \"StudentPersistence\",\n                                  .schema = \"Fact\", .server_name = \"RGVPDSD-DWPRD1\")\n\n#Pull the columns  that you need\npersistence_24_25 <- persistence_conn %>%\n  filter(AcademicYear == \"2024-2025\") %>%\n  select(AcademicYear,\n         RegionDescription,\n         SchoolShortName,\n         Studentnumber,\n         FDOPENROLLED,\n         FDOPNEWENTRY,\n         FDOPLEAVER,\n         FDOPCOUNTP\n         ) %>%\n  #Creating a \"leavers\" column\n  mutate(leavers = if_else(FDOPLEAVER == 1, 1, 0)\n         ) %>%\n  distinct() %>%\n  #Collect the data to pull it onto your machine\n  collect()\n\n#Calculate Student Persistence by Campus Using the 2 different formulas above\nPersistence_Rate_24_25 <- persistence_24_25 %>%\n  filter(FDOPCOUNTP == 1) %>%\n  group_by(SchoolShortName) %>%\n  summarize(n_leavers = sum(leavers),\n            n_students = n_distinct(Studentnumber),\n            n_FDOP = sum(FDOPENROLLED),\n            n_NEWENTRY = sum(FDOPNEWENTRY),\n            persistence_rate_1 = (1-(n_leavers)/(n_students))*100,\n            persistence_rate_2 = (1-(n_leavers)/(n_FDOP + n_NEWENTRY))) %>%\n  distinct()"},{"path":"key-tables-measures-and-metrics.html","id":"student-persistence-using-attendance-tables-a.k.a.-cohort-persistence","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.4.1 Student Persistence using Attendance Tables (A.K.A. Cohort Persistence)","text":"Occasionally student persistence requested school years \ncaptured Persistence Tables, .e., persistence data prior \n2018-2019, cohorts students time. occurs, \nAttendance tables can used “snapshot” whether student \nattending particular date beginning school year \nquestion still attending particular date beginning \nfollowing school year. way calculating persistence \ndrawbacks, mainly precise persistence calculated\npersistence table, results differ slightly depending \n“snapshot” date selected.Database: [RGVPDSD-DWPRD1].[PROD1]Tables:[Attendance].[Students]: table contains daily attendance\ndata 2017-2018 school year present. see students \nattending specific date use AcademicYear column select\nspecific school year AttDate select date (\nYYYY-MM-DD format). sure filter collecting data due\nlarge size table (contains row every school day\nevery student attended years contained table).[Attendance].[Students]: table contains daily attendance\ndata 2017-2018 school year present. see students \nattending specific date use AcademicYear column select\nspecific school year AttDate select date (\nYYYY-MM-DD format). sure filter collecting data due\nlarge size table (contains row every school day\nevery student attended years contained table).[ADA].[StudentDailyMembership] table contains daily\nattendance data 2016-2017 prior. Contains \ncolumns Attendance.Students table, AttDate,\nAcademicYear, SchoolNumber. see students attending\nspecific day use process described .[ADA].[StudentDailyMembership] table contains daily\nattendance data 2016-2017 prior. Contains \ncolumns Attendance.Students table, AttDate,\nAcademicYear, SchoolNumber. see students attending\nspecific day use process described .Useful Fields:\nAcademicYear: academic year (tables)\nSchoolName: long school name (tables)\nschoolnumber: school number (StudentDailyMembership\n(2016-2017 & prior) table SchoolNumber)\nSchoolShortName: school’s short name (ex. Donna; \nAttendance.Students table - 2017-2018 present)\nSchoolType: indicates Academy College Prep (\nAttendance.Students table - 2017-2018 present)\nRegionDescription: region (Attendance.Students\ntable - 2017-2018 present)\nGradeLevelID: student’s grade level (tables)\nWeekNumber: number week academic year (\ntables) Use Cautiously weeks numbered\nproperly 2019-2020 contains Attendance.Students table\nAttDate: date attendance record (format\n“YYYY-MM-DD”) (tables)\nMembership: indicates full-time = 1.0 half-time = .5\n(half-day pre-k students)\nSchoolTypeOperation: indicates school “FULL\nSCALE”, “SCALING”, “LAUNCHING” (\nAttendance.Students table - 2017-2018 present) applies \nAcademies College Preps individually\nUseful Fields:AcademicYear: academic year (tables)SchoolName: long school name (tables)schoolnumber: school number (StudentDailyMembership\n(2016-2017 & prior) table SchoolNumber)SchoolShortName: school’s short name (ex. Donna; \nAttendance.Students table - 2017-2018 present)SchoolType: indicates Academy College Prep (\nAttendance.Students table - 2017-2018 present)RegionDescription: region (Attendance.Students\ntable - 2017-2018 present)GradeLevelID: student’s grade level (tables)WeekNumber: number week academic year (\ntables) Use Cautiously weeks numbered\nproperly 2019-2020 contains Attendance.Students tableAttDate: date attendance record (format\n“YYYY-MM-DD”) (tables)Membership: indicates full-time = 1.0 half-time = .5\n(half-day pre-k students)SchoolTypeOperation: indicates school “FULL\nSCALE”, “SCALING”, “LAUNCHING” (\nAttendance.Students table - 2017-2018 present) applies \nAcademies College Preps individually","code":""},{"path":"key-tables-measures-and-metrics.html","id":"college-application-matriculation-metrics","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.5 College Application & Matriculation Metrics","text":"close opportunity gap, IDEA Public Schools committed \nvision College Children. College Success Team (CST) leads\ninitiative monitoring identifying best College/University\nsenior student, possible data dashboards use\nNaviance information.Database: [RGVPDSD-DWPRD1].[PROD1].[Colleges]Main metrics: Percent least 1 application, Percent least 1\nsubmission, Percent least 1 acceptanceMost important columns: [Stage] | [ResultCode]Tables:[Colleges]: find colleges/universities. \nmakes table important [CEEB] field ID \ncan help us connect distinct college related data sources like\nNaviance National Student Clearinghouse data![Colleges]: find colleges/universities. \nmakes table important [CEEB] field ID \ncan help us connect distinct college related data sources like\nNaviance National Student Clearinghouse data![CollegeTuition]: Besides -state tuition \n--state tuition data, can also find two unique codes\n([OPEID] [ACTCode]), aid us college data across\ndifferent data sources.[CollegeTuition]: Besides -state tuition \n--state tuition data, can also find two unique codes\n([OPEID] [ACTCode]), aid us college data across\ndifferent data sources.[EDocs]: Details application submitted e-documents.[EDocs]: Details application submitted e-documents.[StudentCollegeApplication]: main table. use \ncalculate metrics College Application &\nMatriculation dashboard . can find data 2018 \ncurrent academic year.[StudentCollegeApplication]: main table. use \ncalculate metrics College Application &\nMatriculation dashboard . can find data 2018 \ncurrent academic year.[StudentCollegeApplicationsSummary]:[StudentCollegeApplicationsSummary]:[StudentScholarships]:[StudentScholarships]:Context:Counts?Counts?4year 2year?4year 2year?","code":""},{"path":"key-tables-measures-and-metrics.html","id":"lottery-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.6 Lottery Data","text":"IDEA uses Stream \ncapture information enrollment applications, lottery, contracts,\nenrollment goals. three main tables: Daily, Historical,\nSnapshot.Daily table provides daily application data Stream\ntable current academic year.Historical table provides information Daily\nprevious academic years.Snapshot table provides submitted, accepted,\ncapacity, ratios school grade level day.Tables:[RGVPDRA-DASQL].[StreamLotteryEnrollment].[dbo].[StreamLotteryDaily][RGVPDRA-DASQL].[StreamLotteryEnrollment].[dbo].[StreamLotteryHistorical][RGVPDRA-DASQL].[StreamLotteryEnrollment].[dbo].[StreamLotterySnapshot]Main metrics: Number contracts available / offered, number \ncontracts submitted / accepted, ratios submitted / accepted contracts\ncapacityImportant columns Daily Historical tables:[AcademicYear]: yyyy-yyyy[Campus]: equivalent school short name[School]: labeled Academy College Prep[Grade]: labeled PK, K, 1, 2, …[ApplicantTarget]: number student applications targeted,\nusually 2:1 ratio applications capacity[CapacityContract]: number seats available grade\nlevel[OfferAccepted]: number offers accepted (may higher \ncapacity)[NonEnrollment]:[DuplicateTransfer]:[TransferStudent]:[ReturningStudent]:[NewStudent]:[UnacceptedApplicant]:[Submitted]:[RatioAcceptance]: calculated [OfferAccepted] \\(\\div\\)\n[CapacityContract][RatioSubmission]: calculated [Submitted] \\(\\div\\)\n[CapacityContract][Active]: 1 = grade level non-zero enrollment \nacademic year (.e. students grade level, \nschool may may accepting applications); 0 = grade level\nenrolled academic year (.e. \nstudents grade level, school accepting\napplications grade level)[DateStamp] (Daily): data pulled \nStreamImportant columns Snapshot table:[Date]: yyyy-mm-dd[Campus]: equivalent school short name[School]: labeled Academy College Prep[Grade]: labeled Pre-K, Kindergarten, 1st, 2nd, …[Submitted]:[AcceptedOffers]:[CapacityContract]: number seats available grade\nlevel[RatioAcceptance]: calculated [OfferAccepted] \\(\\div\\)\n[CapacityContract][RatioSubmission]: calculated [Submitted] \\(\\div\\)\n[CapacityContract]","code":""},{"path":"key-tables-measures-and-metrics.html","id":"csi","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.7 Critical Student Intervention (CSI)","text":"Critical Student Intervention (CSI) program introduced \n2014 aims provide additional Reading Math instructional time\nstudents grades 3-8 (Hub\nsite).\nStudents selected participate CSI program based \nRenaissance STAR (RenStar) state assessment scores. Students \ngap 2.0 years either Math /Reading measured \nrespective RenStar grade equivalency (GE) selected CSI\nprogram. However, based documentation, students failed \nReading /Math state assessment can also selected CSI\nprogram. students brought late-June \nfirst day school, decoding placement test used (addition \nstate assessment score) since RenStar available time\n(rollover system).Within CSI program, two intervention subjects (Math \nReading), program various strands. example, students \nCSI Reading grouped strands Decoding, Reading Mastery,\nCorrective Reading. Based CSI documentation, programs \nDISE Español English identified neither Math Reading;\nhowever, data, labeled Reading students \nDISE tend move Decoding (another Reading intervention)\n60 lessons.documented guidance CSI entry, limited\ninformation CSI exit process. instance, currently \nflag data warehouse indicate whether student \nexited CSI programming. exit date included warehouse table;\nhowever, found accurate (e.g., students \nexit date continued, without break, program). According \nCSI documents, students required enrolled CSI courses \nentirety school year, students exit program \nend school year RenStar GE score less two years\ngrade level. However, data reflect \nrequirements. instance, students across grade levels 3-7 exiting\nCSI despite end year RenStar GEs two grade\nlevels .Software Development Team created tables students \nenrolled CSI programs can identified. tables described\n.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"csi-tables","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.7.1 CSI Tables","text":"","code":""},{"path":"key-tables-measures-and-metrics.html","id":"csilessoninputcoredetails","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.7.1.1 CSILessonInputCoreDetails","text":"[RGVPDSD-DWRPT2].[Assessments].[dbo].[CSILessonInputCoreDetails]table used populate CSI Locus\ndashboard.\nrecommended cross-reference data dashboard \nraw data table inconsistencies student counts \nobserved.IDEA data used pull data table R, \nfollowing code can utilized access data:noted students multiple grade levels recorded\nwithin school year. , recommended join \ntable Students table\n([RGVPDSD-DWPRD1].[PROD1].[Schools].[Students]) \n--date grade level.","code":"username <- [enter user name]\npassword <- [enter password]\n\nserver <- \"RGVPDSD-DWRPT2.ips.org\"\n\nconnection_string <- glue::glue(\n\n  \"Driver = {{ODBC Driver 17 for SQL Server}};\",\n  \"Server = {server};\",\n  \"UID = {username};\",\n  \"PWD = {password};\",\n  \"database = Assessments\"\n  \n  )\n\nconn <- NA\n\nconn <- DBI::dbConnect(odbc::odbc()\n                       ,timeout = 10\n                       ,.connection_string = connection_string)\n\n# pull all information from SY 24-25 (school term = 3400)\ncsi_sy2425_raw <-\n  DBI::dbGetQuery(conn\n                  ,paste(\"SELECT *\n                         FROM [RGVPDSD-DWRPT2].[Assessments].[dbo].[CSILessonInputCoreDetails]\n                         WHERE [TermID] = '3400'\")\n                         )"},{"path":"key-tables-measures-and-metrics.html","id":"studentcsi","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.7.1.2 StudentCSI","text":"[RGVPDSD-DWPRD1].[PROD1].[Schools].[StudentCSI]table identifies students /enrolled Math Reading\nCSI intervention programs. Since need data adjustments \none year another, [ProgramID] number might change. However, \nproblem [InterventionType] field can\ncorrectly associate intervention program either Math Reading.SQL Code Example:","code":"SELECT DISTINCT AcademicYear, [Subject], ProgramID\nFROM (SELECT [AcademicYear]\n      ,[ProgramID]\n      ,CASE\n      WHEN [InterventionType] LIKE '%math%' THEN 'Math'\n      WHEN [InterventionType] LIKE '%reading%' THEN 'Reading' ELSE NULL END AS [Subject]\n  FROM [RGVPDSD-DWPRD1].[PROD1].[Schools].[StudentCSI]\n  WHERE [AcademicYear] = '2018-2019'\n  AND (InterventionType LIKE '%math%' OR InterventionType LIKE '%reading%')) AS A\n  GROUP BY AcademicYear, [Subject], ProgramID"},{"path":"key-tables-measures-and-metrics.html","id":"studentcsidetails","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.7.1.3 StudentCSIDetails","text":"[RGVPDSD-DWPRD1].[PROD1].[Schools].[StudentCSIDetails]temporary table used pull data.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"assessment-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8 Assessment Data","text":"","code":""},{"path":"key-tables-measures-and-metrics.html","id":"state-of-texas-assessments-of-academic-readiness-staar","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.1 State of Texas Assessments of Academic Readiness (STAAR)","text":"STAAR assessments Texas’ standardized tests administered every\nyear, except 2019-2020 due COVID-19. Grades 3-8 take Reading\nMath assessments every year Writing, Science, Social\nStudies assessed specific grades. 2021-2022, TEA removed \nwriting assessment incorporated writing assessments.\nTesting schedule follows:Grade 3: Reading MathGrade 4: Reading MathGrade 5: Reading, Math, ScienceGrade 6: Reading MathGrade 7: Reading MathGrade 8: Reading, Math, Science, Social StudiesAssessments provided English Spanish 5th\ngrade, test English. Students High School\n(middle school students) complete End--Course (EOC)\nassessments fulfill graduation requirements. order graduate \nTexas, student must taken passed five EOC assessments:\nAlgebra (taken 8th grade IDEA), Biology, English , English II,\nUnited States History. Students significant cognitive\ndisabilities take STAAR Alternate 2 (STAAR Alt 2) rather \nSTAAR. alternate test administered teacher \nusually excluded analyses academic achievement.STAAR assessments, excluding STAAR Alt 2, three performance\nstandards: Approaches, Meets, Masters. assessments \nrolled , passing standard going moved Meets\nstandard years half students meeting\nApproaches standard. yet happened passing\nstandard remains Approaches performance level. three\nperformance levels mutually exclusive, meaning students\nachieve Masters standard included Meets count \nApproaches count, students achieving Meets standard \nincluded Approaches count. STAAR Alt 2 two performance\nlevels: Developing, Satisfactory, Accomplished. passing standard\nSTAAR Alt 2 Satisfactory performance standard. \nperformance levels (Satisfactory Accomplished) \nmutually exclusive categories, students achieve Accomplished\nstandard included counts Satisfactory.Database: [RGVPDRA-DASQL].[Dashboard]Tables:[dbo].[STAAR]: table contains STAAR STAAR\nAlt 2, 3-8 EOC assessment data. Data table multiple\nrows student, test administration \nthree administrations one year. example, \nfifth grade student take reading, math, science one\nyear, ’s three rows test. , student\ndoesn’t pass reading math March (first administration)\ntake May (second administration \nretake). didn’t pass May, take third\ntime June. 5th 8th grade students get three\nopportunities take Reading Math one academic year, \ndue Student Success Initiative (SSI) requirements every\n5th 8th grade student pass STAAR Reading Math promoted\nnext grade. Although exceptions rule (.e.,\nrequirement waived 2020-2021), one expect \none administration students. description \ncolumns example R get student’s best score \nde-duplicate get one row per student.[dbo].[STAAR]: table contains STAAR STAAR\nAlt 2, 3-8 EOC assessment data. Data table multiple\nrows student, test administration \nthree administrations one year. example, \nfifth grade student take reading, math, science one\nyear, ’s three rows test. , student\ndoesn’t pass reading math March (first administration)\ntake May (second administration \nretake). didn’t pass May, take third\ntime June. 5th 8th grade students get three\nopportunities take Reading Math one academic year, \ndue Student Success Initiative (SSI) requirements every\n5th 8th grade student pass STAAR Reading Math promoted\nnext grade. Although exceptions rule (.e.,\nrequirement waived 2020-2021), one expect \none administration students. description \ncolumns example R get student’s best score \nde-duplicate get one row per student.Useful Fields:\nAdminDate: indicates two digit month two digit year\nadministration grades 3-8, character values.\nEx. Spring 2021 administration dates 3-8 “0421” \n“0521”; EOC exams AdminDate Spring 2021 “1521”.\nGradeLevel: character values, two digit grade. Ex. “06”\nCountyDistrictCampusNumber: indicates School Number\nLastName: Student’s Last Name\nFirstName: Student’s First Name\nStudentID: Student’s testing ID number IDEA\nStudent Number\nRaceReportingCategory: Student’s reported race, Ex. “H” =\nHispanic\nEcoDisadvantage: Student’s economic disadvantaged status, 0,\n1, 2, 9.\nLEP: Student’s Limited English Proficiency status Codes: C =\nCurrent LEP, F = 1st year monitoring, S = 2nd year \nmonitoring, T = 3rd year monitoring, R = 4th year \nmonitoring, E = former LEP 4 years since\nreclassification, 0 = Non-LEP\nSpEd: 0/1 indicator receiving special education services\nAtRisk: 0/1 indicator -risk status\nLocalStudentID: Student’s 108 number\nSubjectCode: tested subject, .e., Reading, Math, Science,\nAlgebra , etc.\nTestDate: equivalent AdminDate 3-8\nScoreCode: indicates whether test scored student\nabsent. ALWAYS filter ScoreCode == “S” get \nscored tests\nTestVersion: “S” = STAAR “T” = STAAR Alt 2\nScaleScore: provides scaled score assessment\ncan used find best score/recent\nadministration\nLevelII: 0/1 indicator Approaches performance\nstandard Note filtered STAAR Alt 2 indicates\nwhether student achieved Satisfactory performance\nlevel\nLevelIIFinal: 0/1 indicator Meets performance\nstandard Note filtered STAAR Alt 2 indicates\nwhether student achieved Satisfactory performance\nlevel\nLevelIII: 0/1 indicator Masters performance standard\nNote filtered STAAR Alt 2 indicates whether \nstudent achieved Accomplished performance level\nSchoolYear: character value indicating academic year,\nEx. “2020-2021”\nBestRecord: logical column supposed indicate \nrecord best student test \nWORK\nUseful Fields:AdminDate: indicates two digit month two digit year\nadministration grades 3-8, character values.\nEx. Spring 2021 administration dates 3-8 “0421” \n“0521”; EOC exams AdminDate Spring 2021 “1521”.GradeLevel: character values, two digit grade. Ex. “06”CountyDistrictCampusNumber: indicates School NumberLastName: Student’s Last NameFirstName: Student’s First NameStudentID: Student’s testing ID number IDEA\nStudent NumberRaceReportingCategory: Student’s reported race, Ex. “H” =\nHispanicEcoDisadvantage: Student’s economic disadvantaged status, 0,\n1, 2, 9.LEP: Student’s Limited English Proficiency status Codes: C =\nCurrent LEP, F = 1st year monitoring, S = 2nd year \nmonitoring, T = 3rd year monitoring, R = 4th year \nmonitoring, E = former LEP 4 years since\nreclassification, 0 = Non-LEPSpEd: 0/1 indicator receiving special education servicesAtRisk: 0/1 indicator -risk statusLocalStudentID: Student’s 108 numberSubjectCode: tested subject, .e., Reading, Math, Science,\nAlgebra , etc.TestDate: equivalent AdminDate 3-8ScoreCode: indicates whether test scored student\nabsent. ALWAYS filter ScoreCode == “S” get \nscored testsTestVersion: “S” = STAAR “T” = STAAR Alt 2ScaleScore: provides scaled score assessment\ncan used find best score/recent\nadministrationLevelII: 0/1 indicator Approaches performance\nstandard Note filtered STAAR Alt 2 indicates\nwhether student achieved Satisfactory performance\nlevelLevelIIFinal: 0/1 indicator Meets performance\nstandard Note filtered STAAR Alt 2 indicates\nwhether student achieved Satisfactory performance\nlevelLevelIII: 0/1 indicator Masters performance standard\nNote filtered STAAR Alt 2 indicates whether \nstudent achieved Accomplished performance levelSchoolYear: character value indicating academic year,\nEx. “2020-2021”BestRecord: logical column supposed indicate \nrecord best student test \nWORKR example:R example:","code":"\n\nSTAAR <- get_table(.table_name = \"STAAR\", .database_name = \"Dashboard\", \n                   .schema = \"dbo\", .server_name = \"RGVPDRA-DASQL\") %>%\n  filter(TestVersion == \"S\", ScoreCode == \"S\", SubjectCode == \"Math\",\n         AdminDate %in% c(\"0421\", \"0521\")) %>%\n  select(StudentID,\n         LocalStudentID,\n         GradeLevel,\n         SubjectCode,\n         AdminDate,\n         ScoreCode,\n         ScaleScore,\n         Approaches = LevelII,\n         Meets = LevelIIFinal,\n         Masters = LevelIII) %>%\n  mutate(StudentID = as.numeric(StudentID),\n         LocalStudentID = as.numeric(LocalStudentID),\n         StudentNumber = if_else(LocalStudentID %in% c(0, NA), StudentID, LocalStudentID),\n         StudentNumber = as.numeric(StudentNumber)) %>%\n  filter(StudentNumber != 0) %>%\n  select(-StudentID, -LocalStudentID, -ScoreCode) %>%\n  group_by(StudentNumber) %>%\n  distinct() %>%\n  collect()\n\n# To get a count of distinct student numbers to see how much duplication exists\nCount_stus <- STAAR %>%\n  distinct(StudentNumber)\n\n# Getting max score to de-duplicate\nstaar_math <- STAAR %>%\n  group_by(StudentNumber) %>%\n  mutate(Best_score = max(ScaleScore),\n         BestScoreFlag = if_else(Best_score == ScaleScore, 1, 0)) %>%\n  filter(BestScoreFlag == 1) %>%\n  select(-BestScoreFlag, -Best_score, -AdminDate, -ScaleScore, -GradeLevel) %>%\n  distinct()\n\n# Calculating the % Approaches and the % Masters\npct_apprhs_mstrs <- staar_math %>%\n  select(Approaches, Masters) %>%\n  summarize(n_students = n(),\n         n_apprchs = sum(Approaches),\n         n_mstrs = sum(Masters)) %>%\n  mutate(pct_app = n_apprchs/n_students,\n         pct_mst = n_mstrs/n_students)"},{"path":"key-tables-measures-and-metrics.html","id":"district-assessments","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.2 District assessments","text":"IDEA produces -house assessments major content area except\nnational state EOY assessments. Typically, courses require \nteachers students administer summative assessments \nbenchmarks, formative assessments left teacher \ncreate.Summative assessments evaluate student learned time \nusually high-stakes types assignments. Examples \ncommon summative assessments administer include:Unit examsEnd--module assessmentsMid-unit exams (also mid-unit quizzes)Mid-module assessmentsSemester examsFinal examsProjects, papers, performances, portfoliosQuarterly interim assessments (former)Bi-weekly assessments (former)Formative assessments used reveal student progress \nlearning cycle usually low-stakes. small sample \nformative assessments use :Daily exit ticketsWeekly quizzesProgress checksPeer feedbackand …section, consider district assessments \ncentralized, meaning schools must administer scan \nresults Illuminate\n(Texas |\nLouisiana),\nmain assessment platform.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"current-assessment-platforms","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.2.1 Current assessment platforms","text":"IABWA tables (Interim Assessments Biweekly\nAssessments) contain student-level item-level performance\nrecords assessment administered Edcite, Illuminate,\nEdulastic, SchoolCity, SchoolNet. Although phased IAs \nBWAs favor UEs (unit exams) EOMs (end module assessments),\ntable nevertheless contains types assessments scanned \nsince 2014-2015.common way entering data Illuminate \nscantron-like answer form, Illuminate automatically generates \nassessment created. teacher option generating\nanswer forms either individual student ID prepopulated (\ncommon) generic ID key must bubbled (less common).\nStudents (teachers, response open-ended) bubble \nresponses, upload answer form via webcam scanner, data\ncollected.Starting 2022-2023, STAAR exam administered online ,\ncausing IDEA Texas assessments switch using Edcite\nexclusively.internal assessment data stored two different levels:student-level, andstudent-level, anditem-level student,item-level student,stored different IABWA table.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"naming-conventions","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.2.1.1 Naming conventions","text":"assessments standard naming convention:STATEABBR_SUBJECTCODE_COURSE_SEMESTER_ASSESSMENTFor example, 6th grade ELA semester exam Fall 2024 may \nname TX_ELA_6thReading_F24_SE, first AP Spanish Language unit\nexam may name TX_SPA_APSpanishLanguage_F24_UE1.Note prior 2021, many assessments omitted state\nabbreviation, need identify historical exam names, start\nsubject code instead.list common codes used included :Note assessment, except semester final exams, \ntypically numbered (see examples). can use regular expressions \nparse codes select exams needed. Note different\nstates may use different names equivalent exams. Similarly,\nmultiple-part exams may deviate convention indicate \npart assessment.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"iabwa-table","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.2.1.2 IABWA table","text":"table aggregates item-level data student reports \nstudent’s performance single assessment.Table: [RGVPDSD-DWPRD2].[PROD2].[Assessments].[IABWA]Main metrics: Student-level data describing assessment taken,\noverall score, performance band, mastery levelAssessment columns:[IABWAID]: number uniquely links student \nassessment.[ExternalTestID]: number uniquely identifies assessment.[SubjectID]: number describes subject math, ELA,\netc.[Subject]: SubjectID, words.[AssessmentDate]: Date assessment.[AssessmentName]: Name assessment (see naming\nconventions, ).[AssessmentReporingName]: One two columns choose type \nassessment.[AssessmentType]: One two columns choose type \nassessment.[RawScore]: Raw number points earned assessment.[PercentCorrect]: Percent earned assessment.[PointsPossible]: Total raw points available assessment.[PerfomanceBand]: Description student’s performance\n(typically “Critical”, “Meet”, “Approaches”, “Meets”,\n“Masters”)[PerfomanceBandNumber]: Numeric code PerformanceBand\n(typically 1-5).[PBStartRange]: Lower bound performance band, \npercent.[PBEndRange]: Upper bound performance band, percent.[Description]: Description performance band interval, \nwords.[Mastery]: 1 = demonstrated mastery (passed, approaches+, etc.);\n0 = [src]: Source asssessment data (Illuminate, \nlegacy systems)[Scope]: Similar AssessmentType, detailed.[State]: Two-letter state code (TX, LA, FL, OH) \nassessment administered.useful fields:[AcademicYear]: Use filter table appropriate\nschool year.[StudentNumber]: Use link students table.[TcpCourseCode]: code uniquely links assessment \nTCP course code.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"iabwa-items","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.2.1.3 IABWA Items","text":"table displays item-level data student \nassessment. information can useful looking items \nspecific TEKS, taught/-taught objectives, multiple-choice vs.\nopen-ended responses, etc.Table: [RGVPDSD-DWPRD2].[PROD2].[Assessments].[IABWAItems]Main metrics: Item-level data describing assessment taken, \nquestion part, student’s response, correct answer,\ncorrectness, standard, question type, weight, pointsAssessment columns:[IABWAItemID]: number uniquely links assessment item\npart student.[IABWAID]: number uniquely links student \nassessment.[ExternalTestID]: number uniquely identifies assessment.[AssessmentDate]: Date assessment.[SubjectID]: number describes subject math, ELA,\netc.[Subject]: SubjectID, words.[AssessmentReporingName]: One two columns choose type \nassessment.[AssessmentType]: One two columns choose type \nassessment.[QuestionNumber]: Describes question part (1a, 1b, 2,\netc.)[ItemStudentResponse]: response(s) scanned student\nteacher[ItemCorrectResponse]: response(s) needed full credit \nitem.[standard]: Describes objective number, TEKS, etc.[StandardsDescription]: Description objective words.[Supporting]: 1 = supporting objective; 0 = [Readiness]: 1 = readiness objective; 0 = [isCorrect]: 1 = student earned credit question number; 0 =\n[Points]: Total points available item.[ReportingGroups]: Describes reporting group objectives.[IsRubric]: ?[State]: Two-letter state code (TX, LA, FL, OH) \nassessment administered.[QuestionTypeName]: Describes type question (Multiple\nChoice, etc.)[QuestionType]: QuestionTypeName abbr.[ExtraCredit]: 1 = extra credit question; 0 = [IsAdvanced]: 1 = advanced question; 0 = [Weight]:[Maximum]: Maximum points available item.[ItemWeight]: Weight item question.[Taught]: empty[MultiRubric]: ?[Taughtabbr]: NT = objective taught; T = objective taught[PossibleScore]: Maximum (weighted?) points available item.[RawScore]: Raw points student earned item.[PointsCorrect]: Weighted points student earned \nitem.[PossibleScoreTaught]: Conditional taught objective: 0 = \ntaught; PossibleScore = taught[RawScoreTaught]: Conditional taught objective: 0 = \ntaught; RawScore = taught[PointsCorrectTaught]: Conditional taught objective: 0 = \ntaught; PointsCorrect = taughtOther useful fields:[AcademicYear]: Use filter table appropriate\nschool year.[StudentNumber]: Use link students table.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"other-sources","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.2.2 Other sources","text":"IDEA grows nationally, certain regions assessment-specific\nplatforms directly flow data warehouse. \nexample, Louisiana schools historically used\nANet house \nLEAP-aligned assessments.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"common-queries-2","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.2.3 Common queries","text":"Querying assessment data, particularly item data, can computationally\ncostly. best practices ’re looking specific exam\ndata:Use IABWA table first filter desired\n[SchoolTermID], [Subject], [State] [AssessmentType] (\nknown) identify exam names need. , use \ncorresponding [ExternalTestID] column filter exams\nefficiently.need items specific exam, use [ExternalTestID]\nIABWAItems table. Filter [SchoolTermID],\n[State], [ExternalTestID], [QuestionNumber], [AssessmentType]\n(known) get item-level data students.Let’s say want scores open-ended questions AP\nEnglish Literature Unit Exam 1 assessment 2024-2025. one way\napproach problem:Use IABWA table identify [ExternalTestID] \nassessment.Use [ExternalTestID] filter IABWA table .Use [ExternalTestID] [QuestionNumber] filter \nIABWAItems table.find names exams administered within school year, use\nfollowing query:learn relevant [ExternalTestID] 2601.query student-assessment-level-data, use following query:learn Question 13 particularly difficult, like \ninvestigate item. IABWAItems table extremely large, \nquery assessment item interested .query student-assessment-item-level-data, use following\nquery:may want join data Students, Schools, Regions\ntables get item-level summaries every organizational level.","code":"SELECT  DISTINCT [AcademicYear]\n                ,[State]\n                ,[SubjectID]\n                ,[Subject]\n                ,[AssessmentType]\n                ,[ExternalTestID]\n                ,[AssessmentName]\n                ,[AssessmentGradeLevels]\n                ,[StudentNumber]\n  FROM [RGVPDSD-DWPRD2].[PROD2].[Assessments].[IABWA]\n  \n  /* use as many filters as needed, but at minimum, start with the school year */\n  WHERE [SchoolTermID] = 3400 /* 3400 is 2024-2025, 3300 is 2023-2024, etc. */\n    AND [State] = 'TX'\n    AND [Subject] = 'English Language Arts'SELECT *\n  FROM [RGVPDSD-DWPRD2].[PROD2].[Assessments].[IABWA]\n  \n  /* add filter for [ExternalTestID] */\n  WHERE [SchoolTermID] = 3400 /* 3400 is 2024-2025, 3300 is 2023-2024, etc. */\n    AND [State] = 'TX'\n    AND [Subject] = 'English Language Arts'\n    AND [ExternalTestID] = 2601SELECT B.[AssessmentName]\n      ,A.* /* pulls all columns from table A */\n      \n  /* use a subquery on IABWAItems to pull only the [QuestionNumber]s you need */\n  FROM (\n    SELECT *\n      FROM [RGVPDSD-DWPRD2].[PROD2].[Assessments].[IABWAItems]\n      WHERE [SchoolTermID] = 3400\n        AND [State] = 'TX'\n        AND [ExternalTestID] = 2601\n        AND [QuestionNumber] = 13\n    ) AS A \n    \n  /* the IABWAItems table does not have the name of the assessment, so \n     join to the IABWA table to get the assessment name                */\n  LEFT JOIN (\n    SELECT DISTINCT [ExternalTestID],\n                    [AssessmentName]\n      FROM [RGVPDSD-DWPRD2].[PROD2].[Assessments].[IABWA]\n      WHERE [SchoolTermID] = 3400\n        AND [State] = 'TX'\n        AND [ExternalTestID] = 2601\n    ) AS B\n  ON A.[ExternalTestID] = B.[ExternalTestID]"},{"path":"key-tables-measures-and-metrics.html","id":"dibels","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.3 DIBELS","text":"Dynamic Indicators Basic Early Literacy Skills, \nDIBELS series short literacy\ntests early grade levels (K-2) originally developed \nUniversity Oregon Center Teaching Learning (CTL). use \ntests inform us reading outcomes youngest scholars BOY,\nMOY, EOY.Data can viewed Amplify\nusually pulled stored warehouse.Table: [RGVPDRA-DASQL].[Dashboard].[dbo].[DIBELS_MCLASS]Main metrics: Counts students meeting standard, \nstandard overall individual tests; Scores \nindividual testsMost important columns: [Assessment Measure-Composite Score-Levels]\n| [Assessment Measure-Composite Score-Score] | [Assessment\nMeasure-FSF-Levels] | [Assessment Measure-FSF-Score] | [Assessment\nMeasure-LNF-Levels] | [Assessment Measure-LNF-Score] | [Assessment\nMeasure-PSF-Levels] | [Assessment Measure-PSF-Score] | [Assessment\nMeasure-NWF (CLS)-Levels] | [Assessment Measure-NWF (CLS)-Score] |\n[Assessment Measure-NWF (WWR)-Levels] | [Assessment Measure-NWF\n(WWR)-Score] | [Assessment Measure-DORF (Fluency)-Levels] |\n[Assessment Measure-DORF (Fluency)-Score] | [Assessment Measure-DORF\n(Accuracy)-Levels] | [Assessment Measure-DORF (Accuracy)-Score] |\n[Assessment Measure-DORF (Retell)-Levels] | [Assessment Measure-DORF\n(Retell)-Score] | [Assessment Measure-DORF (Retell Quality)-Levels] |\n[Assessment Measure-DORF (Retell Quality)-Score] | [Assessment\nMeasure-DORF (Errors)-Score] | [Assessment Measure-Daze-Levels] |\n[Assessment Measure-Daze-Score] | [Assessment Measure-Daze\n(Correct)-Score] | [Assessment Measure-Daze (Incorrect)-Score]useful fields:[School Year], [School Name], [Assessment Grade]: use filter\ntable appropriate students[Benchmark Period]: labeled BOY, MOY, EOY[Student ID (District ID)]: use match students back \nStudents table.Note data IDEA Travis 2021-22 BOY Student\nIDs. must match students (potentially others) \n[Student Last Name] [Student First Name]. match \nreturned, check misspellings names hyphenated/dual\nlast names. DIBELS data often omits hyphen second last name\nentirely.Context:assessed?students K, 1, 2 assessed using DIBELS.tests/columns actually used?\n[Assessment Measure-Composite Score-Levels]: composite\nlevel assigned students, regardless complete\nsections. Levels include “Well Benchmark”, “\nBenchmark”, “Benchmark”, “Benchmark”.\n[Assessment Measure-Composite Score-Score]: composite\nscore assigned students, regardless complete\nsections. interval composite scores [200, 467+).\n[Assessment Measure-LNF-Levels]: LNF, Letter Naming\nFluency test, administered K-1 students . Levels\ninclude “Well Benchmark”, “Benchmark”, “\nBenchmark”.\n[Assessment Measure-LNF-Score]: numerical measure\nLNF interval [0, 59+).\n[Assessment Measure-PSF-Levels]: PSF, Phonemic\nSegmentation Fluency test, administered K-1 students\n. Levels include “Well Benchmark”, “Benchmark”,\n“Benchmark”, “Benchmark”.\n[Assessment Measure-PSF-Score]: numerical measure\nPSF interval [0, 61+).\n[Assessment Measure-NWF (CLS)-Levels]: NWF, Nonsense\nWord Fluency test, administered K-2 students. Levels\ninclude “Well Benchmark”, “Benchmark”, “\nBenchmark”, “Benchmark”.\n[Assessment Measure-NWF (CLS)-Score]: numerical\nmeasure NWF interval [0, 46+).\n[Assessment Measure-DORF (Fluency)-Levels]: DORF, \nDIBELS Oral Reading Fluency test, administered 1-2\nstudents. Levels include “Well Benchmark”, “\nBenchmark”, “Benchmark”, “Benchmark”.\n[Assessment Measure-DORF (Fluency)-Score]: \nnumerical measure DORF - Fluency interval [0, 164+).\n[Assessment Measure-DORF (Accuracy)-Levels]: DORF, \nDIBELS Oral Reading Fluency test, administered 1-2\nstudents. Levels include “Well Benchmark”, “\nBenchmark”, “Benchmark”.\n[Assessment Measure-DORF (Accuracy)-Score]: \nnumerical measure DORF - Accuracy interval [0, 96+).\nremaining assessment measures used historically, \nlonger actively tested.\n[Assessment Measure-Composite Score-Levels]: composite\nlevel assigned students, regardless complete\nsections. Levels include “Well Benchmark”, “\nBenchmark”, “Benchmark”, “Benchmark”.[Assessment Measure-Composite Score-Score]: composite\nscore assigned students, regardless complete\nsections. interval composite scores [200, 467+).[Assessment Measure-LNF-Levels]: LNF, Letter Naming\nFluency test, administered K-1 students . Levels\ninclude “Well Benchmark”, “Benchmark”, “\nBenchmark”.[Assessment Measure-LNF-Score]: numerical measure\nLNF interval [0, 59+).[Assessment Measure-PSF-Levels]: PSF, Phonemic\nSegmentation Fluency test, administered K-1 students\n. Levels include “Well Benchmark”, “Benchmark”,\n“Benchmark”, “Benchmark”.[Assessment Measure-PSF-Score]: numerical measure\nPSF interval [0, 61+).[Assessment Measure-NWF (CLS)-Levels]: NWF, Nonsense\nWord Fluency test, administered K-2 students. Levels\ninclude “Well Benchmark”, “Benchmark”, “\nBenchmark”, “Benchmark”.[Assessment Measure-NWF (CLS)-Score]: numerical\nmeasure NWF interval [0, 46+).[Assessment Measure-DORF (Fluency)-Levels]: DORF, \nDIBELS Oral Reading Fluency test, administered 1-2\nstudents. Levels include “Well Benchmark”, “\nBenchmark”, “Benchmark”, “Benchmark”.[Assessment Measure-DORF (Fluency)-Score]: \nnumerical measure DORF - Fluency interval [0, 164+).[Assessment Measure-DORF (Accuracy)-Levels]: DORF, \nDIBELS Oral Reading Fluency test, administered 1-2\nstudents. Levels include “Well Benchmark”, “\nBenchmark”, “Benchmark”.[Assessment Measure-DORF (Accuracy)-Score]: \nnumerical measure DORF - Accuracy interval [0, 96+).remaining assessment measures used historically, \nlonger actively tested.NAs certain tests student took \nassessment?DIBELS multiple required measures can implemented using\ngating rules stop assessment rule met. student\n(1) scores minimum threshold (2) tests scoring \nhighest benchmark specified gating measure, remaining\nassessments administered, measure left blank. \ngating measure changes, depending grade level benchmark\nperiod.can ask context?\nNkosi Geary-Smith Director Early Literacy. \ncontext DIBELS assessment used.\nChris Gonzalez VP Accountability. pulls DIBELS\ndata uploads warehouse.\nUniversity Oregon maintains DIBELS\nsite publishes guides \nadministering interpreting scores.\ncan ask context?Nkosi Geary-Smith Director Early Literacy. \ncontext DIBELS assessment used.Chris Gonzalez VP Accountability. pulls DIBELS\ndata uploads warehouse.University Oregon maintains DIBELS\nsite publishes guides \nadministering interpreting scores.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"renaissance-star-also-renstar-little-star","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.4 Renaissance STAR (also RenStar, Little Star)","text":"Renaissance Star\nAssessments \nsuite norm-referenced assessments used IDEA \nscreening (particularly identifying students need CSI\nsupport) well gauging achievement growth students \nway agnostic grade-level location (.e., Texas,\nLouisiana, Florida, Ohio).particularly useful evaluative purposes allows us use\nnormed data (e.g., national percentile rank, grade-level equivalent) \nunderstand students progressing learning; \neffectively gives indirect measure student acumen (though can\nconfounded student’s effort given test).","code":""},{"path":"key-tables-measures-and-metrics.html","id":"where-to-get-renstar-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.4.1 Where to get RenStar data?","text":"Accessing data warehouse juncture always\nobvious. number tables (e.g.\n[RGVPDSD-DWPRD2].[PROD2].[Assessments].[LittleStar]) \nfrequently updated. Math RenStar, best table use \n[RGVPDSD-DWSRC4].[SRC_AR].[dbo].[StarMathV2] best time \nReading RenStar [RGVPDSD-DWSRC4].[SRC_AR].[dbo].[StarReadingV2].Students take RenStar three testing windows, beginning \nyear (BOY), middle year (MOY), end year (EOY). CSI\nstudents take exam BOY, MOY, EOY well two additional\ntimes, one fall (BOY MOY) one spring\n(MOY EOY). Note students can take exam \nscreening window tables include scores.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"ap","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.5 AP","text":"IDEA’s Advanced Placement (AP) model requires 9th \n12th grade students take AP coursework provides opportunities \nstudents take AP Exams cost. campuses offer AP courses \nexams; however, IB schools offer far fewer options non-IB\ncampuses.AP student data downloaded directly College Board’s\nwebsite. downloaded imported, cleaned, added R&\nserver. order get data usable format, local\nstudent numbers deduplicated, several scripts AP\nproject GitHub need run specific order.Step One: pull recent year’s project GitHub. Step\nTwo: Open main R project within folder, example, “22-23\nAP Report & Requests”. Within project two main\nsub-project folders. Use AP Requests. Step Three: Run two\nscripts data folder. First run “1_Load_AP_Data”, pulls \nAP tables. Next run “2_Load_Students_Data”, pulls \nstudents excludes Thrive Rise students, students \nsevere cognitive disabilities age 18 (Thrive) \nstudents severe cognitive disabilities take AP course\nwork specified Individual Education Plan (IEP) \nage 18 (Rise). Step Four: Run three scripts munge\nfolder. First run “1_Clean_AP_Data”, script cleans AP data,\nlike making sure student takes AP Exam two different\nyears passes score counted\ntwice towards three exams passed AP Scholars classification.\nrun “2_Scaffold_AP_Data”, creates several scaffolds \nexams taken years take . script results \nbase data file can used call “ap_df”. file include\nduplicate tests taken different year student. \nmany students took exam \nalready passed attempt get better score. Finally run\n“3_Scaffold_AP_Scholars_Data”, script #2, \nensures file produced script doesn’t include\nduplicate exams calculation AP Scholars. resultant file\nlast script called “ap_df_scholars”.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"ib","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.6 IB","text":"International Baccalaureate, IB, \ninternational organization oversees rigorous education programme,\nsimilar College Board US. host four different\nprogrammes:PYP - Primary Years ProgrammeMYP - Middle Years ProgrammeDP - Diploma ProgrammeCP - Career-related Programme","code":""},{"path":"key-tables-measures-and-metrics.html","id":"coursework-and-scoring","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.6.1 Coursework and scoring","text":"CourseworkCurrently, five IDEA college preps - Donna, Frontier, Brownsville,\nMcAllen, South Flores - offer Diploma Programme. DP \nseries courses, assessments, portfolios six different groups\nCore:Group 1: Studies language literature (primary language)Group 2: Language acquisition (secondary language)Group 3: Individuals society (social sciences)Group 4: SciencesGroup 5: MathematicsGroup 6: artsCore: Theory knowledge (TOK); Extended essay (EE); Creativity,\nactivity, service (CAS)IDEA, students generally take one course group, \nDiploma students also work Core. Within IDEA, Core \nalso referred Group 7.Furthermore, IB course usually offered Higher Level\n(HL) Standard Level (SL). Due graduation requirements, IDEA \noffers Group 1 (English) Group 3 (History Americas) courses\nHL. However, remaining coursework can selected either HL \nSL, depending student’s preferences, goals, school offerings.Core, Theory Knowledge regularly taught course \ndesignated HL SL. Extended Essay independent\nresearch project conducted student specified subject \ncan supervised teacher. CAS portfolio student’s\ncreative endeavors, physical activities, community service\nthroughout programme.Course grades, predicted grades, assessmentA combination internally externally assessed components\nthroughout single course determine final course grade \nstudent, grades range 1 7, E , incomplete\nscores marked N P. course assessment given numeric\ngrade, 4 considered passing. course given \nletter grade, D, C, B, passing. grade N P \nassessment typically disqualifies student earning course\ngrade earning IB Diploma.Internal assessments graded teacher moderated \nIB external reader. External assessments graded IB\nexternal reader. May papers (examinations) externally assessed,\ncourses May papers. courses multiple\ninternally externally assessed components.Prior submitting coursework student, teacher must\nalso give predicted grade, single value predicting student’s\ncourse grade.Courses Groups 1 6 awarded numeric grade, TOK EE \nawarded letter grade, CAS awarded satisfactory /\nnon-satisfactory completion.IB Diploma vs. Certificate (Course)students required take courses groups. Students\nparticipate coursework required groups Core pursue\nIB Diploma,\nrecognition exemplary work, somewhat equivalent AP\nCapstone Diploma Program. business rules quite complicated \nearning diploma, students generally need certain\ncombination HL SL points cumulative course score across\ngroups least 24 passing requirements met Core.student may also opt Bilingual Diploma, usually\nsatisfied passing scores least two courses taken secondary\nlanguage. students earned Bilingual Diploma IDEA\ntaken Group 1 English course Group 1 Spanish\ncourse.Students participate Diploma labeled \nCertificate Course students.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.6.2 Data","text":"two main IB tables: [IBScores] [IBDiploma].IB tables offer snapshot final course grades. \ninclude breakdown internal external assessment scores taken\nthroughout course.reporting IB data, confirm level data needed. Suggested\ngroupings : course grades Groups 1-6 ; course grades\nTOK; course grades, TOK EE. individual assessments\nneeded, consult campus’ IB Coordinator.Table: [RGVPDSD-DWPRD2].[PROD2].[Assessments].[IBScores]Main metrics: final course grades predicted grades \nIB course, TOK, EEMain metrics: final course grades predicted grades \nIB course, TOK, EEUseful Fields:\nStudentNumber: student ID number\nSubjectID: use! correspond IB\nGroups\nCourseName: Long course name\nCourseNumber: course number\nTCPCourseCode: link TCP tables\nLevel: HL SL courses; TK Theory Knowledge; EE\nExtended Essay\nLanguage: primary language instruction (either English \nSpanish)\nCategory: Diploma, Course, Certificate\nPredictedGrade: teacher’s predicted course grade 1 7\nE \nGrade: actual course grade 1 7, E , N P\nScaledTotalMarkForSubject: used\nAcademicYear: yyyy-yyyy\nUseful Fields:StudentNumber: student ID numberSubjectID: use! correspond IB\nGroupsCourseName: Long course nameCourseNumber: course numberTCPCourseCode: link TCP tablesLevel: HL SL courses; TK Theory Knowledge; EE\nExtended EssayLanguage: primary language instruction (either English \nSpanish)Category: Diploma, Course, CertificatePredictedGrade: teacher’s predicted course grade 1 7\nE AGrade: actual course grade 1 7, E , N PScaledTotalMarkForSubject: usedAcademicYear: yyyy-yyyyTable: [RGVPDSD-DWPRD2].[PROD2].[Assessments].[IBDiploma]Main metrics: description IB Diploma results Diploma\ncandidateMain metrics: description IB Diploma results Diploma\ncandidateUseful Fields:\nStudentNumber: student ID number\nEETOKPoints: number bonus points awarded combination\nTOK EE letter grades; may missing, 0, 1, 2, 3\nTotalPoints: cumulative points earned course grades \nbonus points\nResult: description IB Diploma Bilingual Diploma\nawarded \nDiplomaRequirementsCode: describes diploma\nrequirements met; blank diploma awarded\nAcademicYear: yyyy-yyyy\nSchoolTermID: Indicates quarter year, Ex. 3000 =\n2020-2021 SY, 3100 = 2021-2022 SY\nUseful Fields:StudentNumber: student ID numberEETOKPoints: number bonus points awarded combination\nTOK EE letter grades; may missing, 0, 1, 2, 3TotalPoints: cumulative points earned course grades \nbonus pointsResult: description IB Diploma Bilingual Diploma\nawarded notDiplomaRequirementsCode: describes diploma\nrequirements met; blank diploma awardedAcademicYear: yyyy-yyyySchoolTermID: Indicates quarter year, Ex. 3000 =\n2020-2021 SY, 3100 = 2021-2022 SYData collection:Note IB data must obtained campus--campus, IB\nauthorizes individual campus, district, World\nSchool.three files contain relevant IB data:Candidate Report - summary course grades IB\ndiploma result student (corresponds [IBDiploma] table)Subject Report - summary course grades subject\n(corresponds [IBScores] table)Candidate-Subject-Component Report - detailed list \nassessments results student (currently captured \nwarehouse)","code":""},{"path":"key-tables-measures-and-metrics.html","id":"useful-queries","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.6.3 Useful queries","text":"Suppose wanted retreive recent IB scores.Note Extended Essay course, course names printed\n[CourseName] column. prevent unintentional aggregation\ngrouping [CourseName].aggregate final IB scores, note grading scheme:Groups 1-6 subjects use numeric grade.TOK EE use letter grade.Thus, [Grade] column character, numeric.code provide distribution numerical letter\ngrades.","code":"\nACADEMIC_YEAR <- \"2021-2022\"\n\ndf_ib <- get_table(.table_name = \"IBScores\",\n          .server_name = \"RGVPDSD-DWPRD2\",\n          .database_name = \"PROD2\",\n          .schema = \"Assessments\") %>%\n  filter(AcademicYear == ACADEMIC_YEAR) %>%\n  mutate(CourseName = if_else(Level == \"EE\", \"Extended Essay\", CourseName)) %>%\n  collect()\ndf_ib %>%\n  group_by(TCPCourseCode) %>%\n  count(Grade)"},{"path":"key-tables-measures-and-metrics.html","id":"act-exam","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.7 ACT exam","text":"ACT main college-entrance exam taken\nIDEA students. Students typically start taking exam 10th\ngrade, multiple attempts 11th grade taking ACT\nPrep course, final opportunity 12th grade prior \nsubmitting college applications.Note ACT handled College Success team, Assessments\nteam.Tables: [RGVPDSD-DWSRC2].[SRC_ACT].[ACT].[StudentScores]Main metrics: composite section scores; test date; CEEB codeImportant columns:[ID_Local]: student 1080/1081 number[F_Name]: first name[M_Initial]: middle initial[L_Name]: last name[HS_GradeLev]: grade level exam taken, labeled \n“11th Grade”, etc. (may also “6th 7th Grad”, “8th Grade” \nDuke TIP students)[HS_Code]: high school CEEB code (ACT school code)[HS_GradYr]: graduation year[Test_Dte]: month year test, labeled mmyyyy[Eng]: English test score[Mth]: mathematics test score[Rdg]: reading test score[Sci]: science test score[Composite]: composite score (average English, Math,\nReading, Science, rounded nearest integer)[Writing]: writing test score, taken[STEM]: overall performance math science tests[ELA]: overall performance English, reading, writing\ntestsImportant context:ACT section composite scores range 1 36, 36 \nhighest score possible.writing section scored 2 12. section \nincluded composite score often required many\nschools.[HS_GradeLev] current [GradeLevelID] - \ngrade level exam taken.high school CEEB (College Entrance Examination Board) code \n[SchoolNumber] - issued ETS (Educational\nTesting Service) use sending test scores colleges, \nalso CEEB codes.information scoring, refer page ACT:\nUnderstanding \nScoresTo filter scores test date, advised parse \n[Test_Dte] column [Month] [Year] column \nread dates correctly.Data collection:Full access ACT data belongs people Trusted Agent\naccount ACT website. data updated warehouse \nmonthly basis.Janna Wiley Director ACT Programming. context \nACT administration data.SQL example:R example:","code":"SELECT [ID_Local] AS [StudentNumber]\n      ,[F_Name] AS [FirstName]\n      ,[M_Initial] AS [MiddleInitial]\n      ,[L_Name] AS [LastName]\n        ,REPLACE([HS_GradeLev], 'th Grade', '') AS [GradeLevelTaken]\n      ,[HS_Code] AS [CEEBCode]\n      ,[HS_GradYr] AS [ClassYear]\n      ,[Test_Dte] AS [TestDate]\n        ,SUBSTRING([Test_Dte], 1, 2) AS [Month]\n        ,SUBSTRING([Test_Dte], 3, 6) AS [Year]\n      ,[Eng] AS [English]\n      ,[Mth] AS [Mathematics]\n      ,[Rdg] AS [Reading]\n      ,[Sci] AS [Science]\n      ,[Composite]\n      ,[Writing]\n      ,[STEM]\n      ,[ELA]\n  FROM [RGVPDSD-DWSRC2].[SRC_ACT].[ACT].[StudentScores]\n  WHERE [HS_GradYr] IN ('2023', '2024', '2025', '2026')\n    AND [HS_GradeLev] NOT IN ('8th Grade', '6th or 7th Grad')   \n  ORDER BY [HS_GradYr], [HS_Code], [L_Name], [Year], [Month]\nget_table(.table_name = \"StudentScores\",\n          .server_name = \"RGVPDSD-DWSRC2\",\n          .database_name = \"SRC_ACT\",\n          .schema = \"ACT\") %>%\n  \n  # filter for current high school students and tests taken in high school only\n  filter(HS_GradYr %in% c(\"2023\", \"2024\", \"2025\", \"2026\"),\n         !(HS_GradeLev %in% c(\"6th or 7th Grad\", \"8th Grade\"))) %>%\n  mutate(Month = str_sub(Test_Dte, 1, 2),\n         Year = str_sub(Test_Dte, 3, 6)) %>%\n  \n  # rename columns for readability, future joins\n  select(StudentNumber = ID_Local,\n         FirstName = F_Name,\n         MiddleInitial = M_Initial,\n         LastName = L_Name,\n         GradeLevelTaken = HS_GradeLev,\n         CEEBCode = HS_Code,\n         ClassYear = HS_GradYr,\n         TestDate = Test_Dte,\n         Month,\n         Year,\n         English = Eng,\n         Mathematics = Mth,\n         Reading = Rdg,\n         Science = Sci,\n         Composite,\n         Writing,\n         STEM,\n         ELA) %>%\n  collect() %>%\n  mutate(GradeLevelTaken = str_replace(GradeLevelTaken, \"th Grade\", \"\")) %>%\n  arrange(ClassYear, CEEBCode, LastName, Year, Month)"},{"path":"key-tables-measures-and-metrics.html","id":"leap","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.8 LEAP","text":"Louisiana Educational Assessment Program (LEAP) LEAP\nassessments \nLouisiana standardized tests administered every year. Students grades\n3 8 take assessments English Language Arts, mathematics,\nscience, social studies every year. High school students take \nEnglish , English II, Algebra , Geometry, U.S. History, Biology\ntests high school. Student results reported using five\nperformance levels (Advanced, Mastery, Basic, Approaches Basic,\nUnsatisfactory). assessments aligned Louisiana Students\nStandards provide consistent measure student performance \ngrowth grades three eleven.Students significant cognitive disabilities take LEAP Connect\n(Alternate Assessment). English learners K-12 take English\nLanguage Proficiency test (ELPT).LEAP test results summarized school grade level can downloaded\nLouisiana Department Education\nwebsite\n(file name: 2022 leap 2025 state lea school achievement level summary).\nStudents grades 3-8 need score Basic higher least three\ntests need score Approaching Basic higher fourth test.downloaded workbook tabs grade level tab high\nschool. Filter spreadsheet IDEA schools LA. Use \nexpected number students participate participation rate\ncolumns calculate actual number students participated. \ncalculate percentage students passed subject, add \npercentage students scored Advanced, Mastery, Basic\nlevels.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"student-level-leap","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.8.8.1 Student Level LEAP","text":"need student level LEAP data, can access (Spring 2021\n2022) 3-8 assessment results\n.\nFollow link LEAP2025 main stream results, LEAP Connect\nalternate assessment results, ELPT English Language\nProficiency assessment results. select campus \ninterested open Excel spreadsheet see data.Useful Fields: • SchoolNbr • SchoolName • LASID • Grade • ELAVoidFlag •\nELAAchievement (Advanced, Mastery, Basic scores represent passing\nsubject test) • MathVoidFlag • MathAchievement (Advanced, Mastery,\nBasic scores represent passing subject test) • SocialVoidFlag •\nSocialAchievement (Advanced, Mastery, Basic scores represent passing\nsubject test) • ScienceVoidFlag • ScienceAchievement (Advanced,\nMastery, Basic scores represent passing subject test)","code":""},{"path":"key-tables-measures-and-metrics.html","id":"student-course-grades","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.9 Student Course Grades","text":"two tables warehouse collect student course\ngrades, [RGVPDSD-DWPRD1].[PROD1].[Schools].[StudentCurrentGrades] \n[RGVPDSD-DWPRD1].[PROD1].[Schools].[StudentHistoricalGrades]. \n[StudentCurrentGrades] table course grades land \nPowerSchool students 8th 12th grade. table used\ncalculate track Graduate check students passing\ncourses. grades change! quarter complete \ngrades moved [StudentHistoricalGrades] table permanent\ngrade. [StudentHistoricalGrades] table contains grades \nstudents Pre-K though 12th. table used transcripts\nreport cards.Table: [RGVPDSD-DWPRD1].[PROD1].[Schools].[StudentCurrentGrades]Useful Fields:SchoolNumber: Local school numberSchoolName: Long school nameCourseName: Long course nameCourseNumber: Course numberCreditType: Abbreviated subject, ELA MA MathStudentNumber: Local student ID numberStudentName: Last, First Middle nameGradeLevelID: Grade level (8th 12th)StoreCode: Indicates whether grade year-long\ncourse, semester, quarterPercentGrade: numerical grade 0-100LetterGrade: Wouldn’t use column, mix letter\ngrades numerical gradesSchoolTermID: Indicates quarter year, Ex. 3000 =\n2020-2021 SY, 3100 = 2021-2022 SYTable: [RGVPDSD-DWPRD1].[PROD1].[Schools].[StudentHistoricalGrades]Useful Fields:StudentNumber: Local student ID numberAcademicYear: academic yearSchoolTermID: Indicates quarter year, Ex. 3000 =\n2020-2021 SY, 3100 = 2021-2022 SYSchoolNumber: Local school numberCourseName: Long course nameCourseNumber: Course numberCreditType: Abbreviated subject, ELA MA MathStaffID: Staff ID number teacher course (\nsure accurate)TeacherName: teacher’s name (Last, First), sure \naccurateGradeLevelID: Grade level (8th 12th)StoreCode: Indicates whether grade year-long\ncourse, semester, quarter (Y1 = end--course grade year)PercentageGrade: numerical grade 0-100LetterGrade: Appears letter grades (Character column)AbsentCount: Count absencesTardyCount: Count tardiesState: two letter abbreviation student’s state","code":""},{"path":"key-tables-measures-and-metrics.html","id":"staff-retention","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.10 Staff Retention","text":"","code":""},{"path":"key-tables-measures-and-metrics.html","id":"staff-retention-dashboard","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.10.1 Staff Retention Dashboard","text":"2022-2023 School Year Software Development team created \ndashboard track Staff Retention replacement previous \nweekly reports. dashboard tracks retention Region, Campus,\nSchool, Area, Chief, Teachers (), Demographics, \nincludes reason leaving, Race/Ethnicity, Tenure, First Year, 90 Day,\nFirst Year Teacher, Job Group, First Year Job Group. Staff\nRetention dashboard can found : Staff Retention\nDashboard\n(HUB -> Quick Links -> Dashboards -> Locus -> Staff\nRetention).can’t find need dashboard, following sections\nexplain tables store Staff Retention data.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"staff-headcount-new-table","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.10.2 Staff HeadCount New Table","text":"StaffHeadCountNew table contains current year’s staff retention\ndata.Table: [RGVPDSD-DWPRD1].[Staffing].[dbo].[StaffHeadCountNew]Useful Fields:NameID: Employee IDHireDate: date employee hiredStartDate: date employee started workEmployeeName: employees full nameCampus: Abbreviated Campus long nameRegion: Region nameJobTitle: Employee’s Job TitleJobRole: Employee’s Job RoleJobGroup: Short list categories employee’s job falls\n, Clerical/Technical, Teacher, Manual Trades, etc.AcademicYear: current academic yearPositionEndDate: position end date, teachers \nlast day previous academic year, 2023-06-30TerminatedDate: date employee terminated else \nNULLEthnicity: Race/Ethnicity mutually exclusive categories,\nhowever, 2 Races optionTenure: number year employee worked IDEAEmpStatus: 0 == Longer Employeed (NLE), 1 == ActiveTermReason: Termination ReasonTermReasonDescription: Longer description reasonManager: Employee’s ManagerRowIsCurrent: Indicates current row data \nemployeeFunctionalGroup: division employee inSubFunctionalGroup: Indicates employee National,\nCampus based, Regional, etc.ChiefName: abbreviated chiefDeptRename: Department name (Instructional, Campus Operations,\netc.)JobPaySkill: EmpStatus character (Nle, Active)ManagerID: Manager’s Employee IDGender: M == Male, F == FemaleTeacherStep: step level teacherDOB: Employee’s Date Birth","code":""},{"path":"key-tables-measures-and-metrics.html","id":"historic-staff-retention-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.10.2.1 Historic Staff Retention Data","text":"prior year’s Staff Retention data tables \ncolumns described .2018-2019 Table:\n[RGVPDSD-DWPRD1].[Staffing].[dbo].[StaffHeadCountNew1819]2019-2020 Table:\n[RGVPDSD-DWPRD1].[Staffing].[dbo].[StaffHeadCountNew1920]2020-2021 Table:\n[RGVPDSD-DWPRD1].[Staffing].[dbo].[StaffHeadCountNew2021]2021-2022 Table:\n[RGVPDSD-DWPRD1].[Staffing].[dbo].[StaffHeadCountNew2122]2022-2023 Table:\n[RGVPDSD-DWPRD1].[Staffing].[dbo].[StaffHeadCountNew2223]2023-2024 Table:\n[RGVPDSD-DWPRD1].[Staffing].[dbo].[StaffHeadCountNew2324]2024-2025 Table:\n[RGVPDSD-DWPRD1].[Staffing].[dbo].[StaffHeadCountNew2425]Data varied across years naming conventions (lack\n) varied across tables.data feeds Staff Retention Dashboard found \ndifferent table contains current year prior year’s\ndata.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"reporting-employees-table","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.10.3 Reporting Employees Table","text":"Reporting.Employees table contains current prior year’s\nstaff retention data. data feeds Staff Retention\nDashboard.Table: [RGVPDSD-DWPRD1].[Staffing].[Reporting].[Employees]Useful Fields:NAMEID: Employee IDHIREDATE: date employee hiredSTARTDATE: date employee started workEMPLOYEENAME: employees full nameREGION: Abbreviated region nameCAMPUSNAME: Campus long nameCAMPUS: Abbreviated Campus long nameCAMPUSTYPE: Campus type (College Prep, Academy, IDEA)JOBTITLE: Employee’s Job TitleSUBFUNCTIONAL GROUP: Indicates whether employee’s position\nCampus-based, Regional, NationalJOBGROUP: Short list categories employee’s job falls\n, Clerical/Technical, Teacher, Manual Trades, etc.YEARLONG: academic year “2024-2025” formatPOSITIONENDDATE: position end date, teachers \nlast day previous academic year, 2023-06-30EXITDATE: date employee terminated else NULLETHNICITY: Race/Ethnicity mutually exclusive categories,\nhowever, 2 Races optionTENURE: number year employee worked IDEAEMPLOYEESTATUS: 0 == Longer Employed (NLE), 1 == ActiveEXITREASON: Termination ReasonEXITDESCRIPTION: Longer description reasonCHIEF: abbreviated chiefAREA: Area name (Academic Team, Information Systems &\nTechnology, etc.)DIVISION: Division name (Curriculum-Instruction-Assessment,\nTechnology Operations, etc.)DEPARTMENT: Department name (Instructional, Campus Operations,\netc.)JOBPAYSKILL: EMPLOYEESTATUS character (NLE, Active)MANAGER: Employee’s ManagerMANAGERID: Manager’s Employee IDGENDER: M == Male, F == FemaleDOB: Employee’s Date BirthISTEACHER: 0/1 indicating employee teacherTEACHERSTEP: step level teacherHEADCOUNT: 0/1 indicating employee counted \noverall staff headcountLEAVER: 0/1 indicating employee considered leaverHEADCOUNTFIRSTYEAR: 0/1 indicating employee \nfirst yearLEAVERS90DAY: 0/1 indicating employee left within 90\ncalendar days start dateThere columns table useful, example\ncolumns indicate employee First Year Teacher\nleaver within first year employment.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"day-retention","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.10.3.1 90 Day Retention","text":"90 Day retention 1-(number first year staff left prior \nreaching 90 days start date / total number first year\nstaff).reporting.employees table binary column “LEAVERS90DAY”\n1 staff member left within 90 calendar days \nstart date 0 otherwise. calculate 90 Day retention, divide \nnumber 0’s column total count first year staff.Example: Total staff headcount: 101 staff member actively employed 45 calendar days\nstart date (staff member 1)1 staff member longer employed quit 60 calendar days \nstart date (staff member 2)1 staff member longer employed quit 90 calendar\ndays start date7 staff members actively employed 90 calendar days\nstart dateIn example, 90 Day retention 1-(1/10) = 90%. staff\nmember 1 remains employed first 90 calendar days \nemployment, rate remain unchanged. However, staff member 1\nleave prior 91st day employment, rate \nchange 1-(2/10) = 80%.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"tips-for-staff-retention-reporting","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.10.3.2 Tips for Staff Retention Reporting","text":"comparing current year--date retention last year’s retention\nusing reporting.employees data, two helper columns (TRUELEAVER \nTRUEHEADCOUNT) needed ensure accurate year--year comparisons.TRUELEAVER identifies employees exited current\nretention year cutoff date well employees exited\nequivalent period prior retention year.TRUEHEADCOUNT identifies employees part staff\nheadcount retention year cutoff date, \ncurrent year equivalent period prior year.columns can created follows (example uses SY 22-23 SY\n23-24 cutoff date May 1st years; years/dates can \nchanged needed):","code":"\nreporting.employees <-  reporting.employees %>% \n  mutate(TRUELEAVER = case_when(YEAR == \"2022\" & EXITDATE >= \"2022-07-01\" & EXITDATE <= \"2023-05-01\" ~ 1,\n                                YEAR == \"2023\"& LEAVERS == \"1\" & EXITDATE <= \"2024-05-01\" ~ 1,\n                                TRUE ~ 0)) %>%\n  mutate(TRUEHEADCOUNT = case_when(YEAR == \"2022\" & STARTDATE <= \"2023-05-01\" ~ 1,\n                                   YEAR == \"2023\" & HEADCOUNT == \"1\" & STARTDATE <= \"2024-05-01\" ~ 1,\n                                   TRUE ~ 0))"},{"path":"key-tables-measures-and-metrics.html","id":"all-staff-retention-table","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.10.4 All Staff Retention Table","text":"previously mentioned staff retention tables\n(StaffHeadCountNew Reporting.Employees) contain data full-time\nstaff . Staff Retention table contains retention data \nfull-time part-time employees.Table: [RGVPDSD-DWPRD1].[Staffing].[dbo].[AllStaffRetention]Useful Fields:EmployeeID: Employee IDEmployeeName: employee’s full nameHireDate: date employee hiredStartDate: date employee started workCampusName: Abbreviated Campus long nameRegionName: Abbreviated region nameJobRename: Employee’s Job TitleDeptRename: Department name (Instructional, Campus Operations,\netc.)EmploymentStatus: FULL TIME PART TIMEJobGroup: Short list categories employee’s job falls\n, Clerical/Technical, Teacher, Manual Trades, etc.AcademicYear: current academic yearRace: Race/Ethnicity mutually exclusive categories,\nhowever, 2 Races optionTerminationDate: date employee terminated else \nNULLTerminatedReason: Termination ReasonManagerName: Employee’s ManagerRowIsCurrent: Indicates current row data \nemployeeFunctional: division employee inSubFunctional: Indicates employee National, Campus\nbased, Regional, etc.Chief: abbreviated chiefManagerID: Manager’s Employee IDGender: M == Male, F == FemaleTeacher Step: step level teacherDate Birth: Employee’s Date BirthJobPaySkill: EmpStatus character (NLE, Active)EmpStatus: 0 == Longer Employeed (NLE), 1 == Active","code":""},{"path":"key-tables-measures-and-metrics.html","id":"staff-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.11 Staff Data","text":"","code":""},{"path":"key-tables-measures-and-metrics.html","id":"regrettable-vs-non-regrettable-separation","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.11.1 Regrettable vs Non Regrettable Separation","text":"Regrettable separation defined separation IDEA want\noccur. Non-regrettable separation defined separation \ntolerable IDEA.separation classified regrettable, leaver must \none following exit reasons:Voluntary Resignation NoticeVoluntary Resignation NoticeVoluntary Return LeaveFor separation classified non-regrettable, leaver must\none following exit reasons:Failed -9 VerificationInvoluntary MisconductInvoluntary Non-RenewInvoluntary Poor PerformanceNo Call ShowResignation Lieu TerminationLeavers following exit reason excluded population:Voluntary RetirementJob Change Seasonal/Part - TimeDid Return Next Year FT Position","code":""},{"path":"key-tables-measures-and-metrics.html","id":"high-stakes-roles","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.11.2 High Stakes Roles","text":"high stakes roles vw_CurrentStaffDirectory table\nlocated Surveys database RGVPDRA-DASQL server. However,\ninformation incomplete. get high stakes roles job\ntitle column:defining high stakes roles job titles, important go\norder groups overlap properly assigned (.e.,\nVP Schools HQ VPs). Make sure apply proper sentence case\ndataset used. Keep mind specialty titles may\ncontain words filter belong grouping,\nFlex Teacher Teacher Residency Coach.","code":"\n  mutate(HighStakesRoles = case_when(JOBTITLE %like% \"%TEACHER%\" & JOBTITLE %notlike% \"%CO-TEACHER%\" & JOBTITLE %notlike% \"%TEACHER RESIDENCY COACH%\" & JOBTITLE %notlike% \"%FLEX TEACHER%\" ~ \"Teacher\",\n                                     JOBTITLE %like% \"%ASSISTANT PRINCIPAL OF OPERATIONS%\" ~ \"APO\",\n                                     JOBTITLE %like% \"%ASSISTANT PRINCIPAL OF INSTRUCTION\" ~ \"API\",\n                                     JOBTITLE %like% \"%EXECUTIVE DIRECTOR%\" ~ \"Executive Director\",\n                                     JOBTITLE %like% \"%VP%\" ~ \"HQ VP\",\n                                     JOBTITLE %like% \"%PRINCIPAL\" ~ \"Principal\",\n                                     TRUE ~ \"Non- HighStakesRoles\"))"},{"path":"key-tables-measures-and-metrics.html","id":"teacher-staff-and-hiring-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12 Teacher, Staff, and Hiring Data","text":"","code":""},{"path":"key-tables-measures-and-metrics.html","id":"tyler-munis-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.1 Tyler Munis data","text":"Tyler Munis can accessed Maura Carter. munprod database\ncontains variety tables views staffing data. One \nmain tables employee data prempmst table. Another \npremppay_all view (munprod), employee’s step,\nsalary, pay rate, pay schedule, latest step “date” (current step),\nemployee ID number. data can filtered job type. \nexample, want see Teacher Salary, can filter job type\nTeacher.Currently, data used Teacher Tenure project \nMartin Winchester HA team, investigate \nrelationship student achievement (via Semester Exams STAAR\ntesting scores) teacher’s Step (pay scale). higher step\nindicates experience teaching, includes teaching IDEA \nprior years experience teaching elsewhere.22-23 SY Steps Teachers range 0 35, consecutively, \nskipping 32 34. teachers NA Step. Step “0”\nindicates prior experience teaching hired IDEA. \nstep “1+” indicates prior experience teacher’s first\nyear IDEA, indicates experience IDEA, \nteacher’s first year IDEA.employee data can queried pulled csv, excluding direct\ninformation Social Security Numbers Salary (per NDA Maura\nsigned).#prempmst table Tyler MunisThe prempmst table one primary sources employee data \ninformation. employee ID number, step level (salary),\nsocial security number (data deemed \nsensitive), start date IDEA, work start date school year,\ngender, race, ethnicity, pertinent employee information \ndata (much captured HRIS data reports \nsent weekly). also includes employee full name, marital status,\nhome phone number, spouse, bank account, supervisor, IDEA email address,\nalternate email address (personal email employee used likely \napply IDEA), pay type, pay frequency, sick bank.Prempmst one hundreds tables. accessed via path \nMSSQL: RGVPDEIS-TMTXDB-> Databases -> munprod -> Tables ->\ndbo.prempmst_origHere specific columns format :##Work Start Date: FORMAT(premppay_all.prep_work_st_dt,‘d’,‘en-us’) \n‘Work Start Date’##Job Status (NLE vs Active) ,CASE prempmst.prem_term_date <\nGETDATE() ‘NLE’\nELSE ‘Active’ END [JobPaySkill]based term dates. NLE employees longer \nIDEA, Active means employee active employee still\ncurrently working IDEA. Job Status column \nRetention Reports filtered NLE Active order \ncalculate retention rates see used employee \nlonger, date employee left, still current active\nemployee. (Active employees Job Status column used \nHRIS reports).##Start Date,FORMAT(prempmst.prem_hire,‘d’,‘en-us’) [StartDate]Start Date column used HRIS reports denotes date \nhire IDEA (employee start employment IDEA,\nregardless current IDEA role now.) example, employee\nstarted first time IDEA August 1, 2016 \nrole teacher, now current Work Start date August 1,\n2023 Principal. employee started IDEA 2016\ncurrent employee 2023 different role. However, \nperson doesn’t switch roles, Work Start Date \nstart date current school year’s job role particular\nschool year. employee new Work Start Date school\nyear (either role new current role, \ndifferent), one Start Date IDEA \norganization.###New Teacher IDEA Start Date Work Start Date important\ncolumns determining flag New Teacher IDEA. determine \nsomeone new teacher (existing flag field \nTyler Munis data), one first look Start Date, \nlook Work Start Date. years match , likely\nnew teacher. , example, Start Date year match\nWork Start Date year (Start Date older year), \nemployee new teacher (job roles \ncolumns, TEACHER). teacher’s Start Date July 15,\n2020 Work Start Date August 1, 2021, new\nteacher (given employee’s role “TEACHER” \ncases). However, possible example person \nhired co-teacher 2020, started role teacher \n2021. case, employee new IDEA, \nnew teacher IDEA.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"teachboost-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.2 TeachBoost Data","text":"TeachBoost observation data teachers leaders, well \nlesson plan submission useful information. main reason \ndepartment accessing TB data GET observations \nteachers SLL observations Leaders.TB contains Forms table Users table.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"forms","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.2.1 Forms","text":"connect Teachboost Forms table. \nfiltered 22-23 SY dates observations, also \nfiltered GET observations (excludes SLL observations \nleaders, lesson plan submissions, etc.). want SLL forms, can\nfilter instead. can also filter different dates. \nfiltered first month school.forms_try <- get_table(.table_name = “Forms”, .database_name =\n“SRC_Teachboost”, .schema = “dbo”, .server_name = “RGVPDSD-DWSRC3”) %>%\nselect(template_name, template_id, id, topic_ids, author_ids, group_ids,\nstatus, type_label, type, date, last_modified) %>% filter(type_label ==\n“GET Row Rating”) %>% filter(date == “2022-08-01” | date ==\n“2022-08-02” | date == “2022-08-03” | date == “2022-08-04” | date ==\n“2022-08-05” | date == “2022-08-06” | date == “2022-08-07” | date ==\n“2022-08-08” | date == “2022-08-09” | date == “2022-08-10” | date ==\n“2022-08-11” | date == “2022-08-12” | date == “2022-08-13” | date ==\n“2022-08-14” | date == “2022-08-15” | date == “2022-08-16” | date ==\n“2022-08-17” | date == “2022-08-18” | date == “2022-08-19” | date ==\n“2022-08-20” | date == “2022-08-21” | date == “2022-08-22” | date ==\n“2022-08-23” | date == “2022-08-24” | date == “2022-08-25” | date ==\n“2022-08-26” | date == “2022-08-27” | date == “2022-08-28” | date ==\n“2022-08-29” | date == “2022-08-30” | date == “2022-08-31” | date ==\n“2022-09-01” | date == “2022-09-02” ) %>% collect() forms_tryForms table topic_id, TB ID person \nform written. author_id TB ID person \nwrote form. form type describes whether GET, Lesson Plan,\nSLL, etc. topic_ID author_ID can , person\nwrote form , number matches “ID” number\nUsers table. ID users employee ID; rather, \nTeachboost user ID number (uniquely) assigned person \nTeachboost. find form (generally observation \nsubmitted, GET) Forms table, see \n(find employee ID number), connect Forms table \nUser table topic_id, find employee ID column \nusers table. , can connect joined table \nemployees table employee ID (found Users table) \nstaffing/employee table, get additional information Region \nSchool, example.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"users","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.2.2 Users","text":"UserID column denotes number loggin. example,\n3,541st loggin, UserID number Users\ntable. assigned Teachboost ID number column “ID” Users\ntable, separate column employee ID, \ndifferent UserID ID. can connect Users table \ntables, Staffing.Employees, get addtional information \nperson Teachboost Region School.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"teachboost-table-joins","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.2.3 TeachBoost Table Joins","text":"link TeachBoost Users, Scores, Forms tables, key \nnecessary join. visualization link \ntables well sample code. additional information \ntables, please see TeachBoost support\nguide.","code":"\n# load libraries\nlibrary(tidyverse)\nlibrary(ideadata)\nlibrary(janitor)\n\n# users ----\n# Note: Users table resource_id = staff ID number (name_id in Staffing table)\nusers <- get_table(.table_name = \"Users\", \n                    .database_name = \"SRC_Teachboost\",\n                    .schema = \"dbo\", \n                    .server_name = \"RGVPDSD-DWSRC3\") %>%\n\n  distinct() %>%\n  collect() %>%\n  janitor::clean_names() %>%\n\n  # reduce users to distinct staff ID numbers (resource_id)\n  distinct(resource_id, .keep_all = TRUE)\n\n# scores ----\nscores <- get_table(.table_name = \"Scores\", \n                        .database_name = \"SRC_Teachboost\",\n                        .schema = \"dbo\", \n                        .server_name = \"RGVPDSD-DWSRC3\") %>%\n  \n  # for use when filtering for a particular date range\n  filter(between(date, as.Date('2023-07-25'), as.Date('2023-12-31'))) %>%\n    \n  distinct() %>%\n  collect() %>%\n  janitor::clean_names()\n\n# merge scores with users ----\nscores_users <- scores %>% \n  mutate(id = topic_id) %>% \n  relocate(id, .after = topic_id) %>% \n  left_join(users, by = \"id\")\n\n# forms ----\nforms <- get_table(.table_name = \"Forms\", \n                      .database_name = \"SRC_Teachboost\",\n                      .schema = \"dbo\", \n                      .server_name = \"RGVPDSD-DWSRC3\") %>%\n  \n  # for use when the template_name includes GET\n  filter(template_name %like% \"%GET%\") %>%\n  \n  distinct() %>%\n  collect() %>%\n  janitor::clean_names() %>%\n  distinct(type_label, template_name, template_id)\n\n# merge scores/users with forms ----\ndata <- scores_users %>% \n  left_join(forms, by = \"template_id\")"},{"path":"key-tables-measures-and-metrics.html","id":"compass-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.3 Compass data","text":"Compass internally\ndeveloped application collects displays employee data. \napplications production database provides tidy tables staff\ndata considered source truth data.’ll need reach Chris Haid access database. set \ncompass functions [ideadata](idea-analytics.github.io/ideadata) \ndevelopment.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"key-tables","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.3.1 Key Tables","text":"2x2s TwoByTwos\nEmployee_ID\nQuestion_ID\nYear\nSortOrder (specific year Reviewer order displayed\nCornerstone)\nReviewer\nIsComplete (completed Staff Manager)\nEmployee_IDQuestion_IDYearSortOrder (specific year Reviewer order displayed\nCornerstone)ReviewerIsComplete (completed Staff Manager)TCPs\nEmployeeID\nManagerID\nCompositeScore\nCoreValues\nGETRAtings\nParentSurvey\nStudentAchievment\nStudentSurvey\nTCPPlacementLevel\nEmployeeIDManagerIDCompositeScoreCoreValuesGETRAtingsParentSurveyStudentAchievmentStudentSurveyTCPPlacementLevelTCPPlacementTalentReviewsSkywardPositions\nHistorical staffing positional data TylerMunis\nGet’s merged Position History data\nHistorical staffing positional data TylerMunisGet’s merged Position History dataRoadMap\nRoadmap Users (crosswalk roadmap UniqueID, Email address,\nEmployeeID)\nRoadmapPrograms\nRoadmapProgramScores\nRoadmap Users (crosswalk roadmap UniqueID, Email address,\nEmployeeID)RoadmapProgramsRoadmapProgramScoresQuestionsGPTW (going changed) super wideProfiles\nBig primary table\ntylermunis’s active employee data.\npull recent active directory data (AD_ fields)\nAD_SamAccountName\nPersonal Email\n\n\nPositions: Historical Positional Data\nProfileID\nEmployeeID\nDataSource (comes )\n\nBig primary tableAll tylermunis’s active employee data.\npull recent active directory data (AD_ fields)\nAD_SamAccountName\nPersonal Email\n\npull recent active directory data (AD_ fields)\nAD_SamAccountName\nPersonal Email\nAD_SamAccountNamePersonal EmailPositions: Historical Positional Data\nProfileID\nEmployeeID\nDataSource (comes )\nProfileIDEmployeeIDDataSource (comes )JobVite\nsimilar Roadmap\nJobviteUsers\napp id,\ncandidateid\ncan link JobVite tables\nsimilar RoadmapJobviteUsersapp id,candidateidcan link JobVite tablesGPTW\nPivoted employee id performance manager\nchange (moving tidy data)\nPivoted employee id performance managerThis change (moving tidy data)GoalsExternal Position (used, user added data captured \nJobvite)AnnualPerformanceReviews","code":""},{"path":"key-tables-measures-and-metrics.html","id":"jobvite-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.4 Jobvite Data","text":"Jobvite application hiring platform used staff. \njob listings posted, interview process managed, even initial\nonboarding tasks progress monitored.R&used data Jobvite analyze pre-hiring measures hired\nteachers.facts Jobvite data:Obtained HA team. data candidates apply\nIDEA jobs Jobvite. candidates applied \nJobvite past, HA trying streamline application\nprocess require applicants jobs (campuses) \napply Jobvite. particular Jobvite file labeled \nyear, “Jobvite 19-20”, \nCandidate Submit Date column , ranges October 2019 \nJuly 2019 (October July, proceeding year applicant \nlikely begin work). applicant range likely\nStart Date August 2019 (sometime calendar year\n2019, starting 19-20 Academic Year). However, \ncases applicants , example, apply 10/2018 -\n07/2019 cycle (Jobvite 19-20), Start Date \n2020 2021 (start following Fall \napplication cycle).file columns including Candidate Full Name, Candidate Email\n(personal email used application), pre-hire\nselection measures, GPA. However, five pre-hire\nselection measures included yet (STEM Major,\nTeach America status, Experience prior IDEA, GPA, \nTeacher Certification). data also Employee IDs yet, \nlist candidates. Hire Yes/column, \n“Yes” candidates offered position “” \noffered position. Also, Requisition ID\nbasically application ID number, unique per\napplication. single candidate applies one position,\ncandidate unique ID application. \nbullet points describing Jobvite Teacher Export (TCP) data.Jobvite Data: applications Teacher Roles Jobvite (\nfiltering Category == \"Teaching\")\nContains Hired = Yes Hired = . “Hired = Yes”\nmeans offered position, indicate \nactually accepted .\nperson may apply one job opening, \n, unique Requisition ID application\n(even though candidate applying separate\nposition).\nPersonal Email Full Name\nIDEA Work Email, EmployeeID\nContains everyone applied October following\nJuly, subsequent August Start Date (start dates \nyear).\npeople applied Jobvite 19-20 (10/18 7/19),\nstarted Fall 2019 (19-20 Academic Year)\nstarted Fall 2020 Fall 2021.\nJobvite Data: applications Teacher Roles Jobvite (\nfiltering Category == \"Teaching\")Contains Hired = Yes Hired = . “Hired = Yes”\nmeans offered position, indicate \nactually accepted .person may apply one job opening, \n, unique Requisition ID application\n(even though candidate applying separate\nposition).Personal Email Full NameDoes IDEA Work Email, EmployeeIDContains everyone applied October following\nJuly, subsequent August Start Date (start dates \nyear).people applied Jobvite 19-20 (10/18 7/19),\nstarted Fall 2019 (19-20 Academic Year)started Fall 2020 Fall 2021.Jobvite File facts 1. 19-20 – 2nd year Jobvite data (18-19 \nfirst starting year Jobvite data) * (renamed Jobvite 18-19 SY \nBrittany; email 10-12-21) * Contains Tentative Start Date column –\nshows month/year new hire started working (doesn’t \nimmediately following year’s hiring cycle)20-21 – 3rd year Jobvite data * (renamed Jobvite 18-19 SY \nBrittany; email 10-12-21) * Contains Tentative Start Date column20-21 – 3rd year Jobvite data * (renamed Jobvite 18-19 SY \nBrittany; email 10-12-21) * Contains Tentative Start Date column21-22 – 4th year Jobvite data * (renamed Jobvite 18-19 SY \nBrittany; email 10-12-21) * Contains Tentative Start Date column21-22 – 4th year Jobvite data * (renamed Jobvite 18-19 SY \nBrittany; email 10-12-21) * Contains Tentative Start Date column","code":""},{"path":"key-tables-measures-and-metrics.html","id":"tcpteacher-export-data","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5 TCP/Teacher Export Data","text":"TCP/Teacher Export Data: Teacher Performance data. * Includes TCP Level\nPlacements, TCP Composite Score, TCP component scores (5\ncomponents). + GET (35%): Manager Self Guidepost Ratings contain 6\ncomponents + Lesson Planning & Delivery + Culture, Etc. + Components 1-5\ncounted, Component 6 (Core Values) calculated outside \nscore (1 5 Components TCP, worth 5% ). \nGuidepost Component 4-5 items listed 1A, 1B, etc. +\nParent Survey (5%): Show BLANK <10 surveys completed per\nteacher + Student Survey (5%) Shows BLANK : + <10 surveys \ncompleted per teacher + campuses encourage students parents \nfill surveys, + Teacher taught SPED, pre-K, K,\n1st, 2nd Grades (students able take survey/\nyoung). + Student Achievement (50%) Testing STAAR, etc. +\nCore Values (5%) + Contains IDEA Work Email EmployeeID + Contains\nFirst Name Last Name (Full Name)2 year HOLD pandemic (don’t know \n“held”), meaning someone particular level (e.g., Level 5) \nstay level 2 years without composite score \nhigh level. Usually, hold 1 year.someone got 4.5+ composite TCP score two consecutive years\nrow, can move Level 5 TCP without required\nyears Experience.Student Achievement scores, highest\nTCP Level can reach Level 3 (since Student Achievement \n50% score).person missing one four TCP components, \nParent Survey, points score reallocated\ncomponents, weights ratios \ncomponents (’s equal allocation, meaning don’t\ndivide percentage four equal ways).SY 18-19Available www.tcp.ideapublicschool.org. Click “Export”, \nclick SY interested . Alex Saldivar can give \naccess; however Maura, Ilissa, Steven, Edison, Marlena \ngranted access. Maura requested access Chris, Karina,\nMishan, Aline.SY 19-20(“Maura Report”, Alex, new sheet Teacher Export 18-19\nfile Alex, see email).Need request Blanca (data table already using\nTSLIP grant, can re-use Teacher Hiring Round 3).20-21 – 3rd year Jobvite datafrom Blanca Carillo, contains “Teacher” roles New\nHires Promotions; co-teachers, etc., removed \nacademic yearContains started work 21-22 New Hires \nPromotions, rated Level 1 TCP (didn’t work 20-21\nschool year).like download TCP Export data SY 19-20,\nplease go TCP Application Website: www.tcp.ideapublicschools.org.SY 21-22 – please download export \nwww.tcp.ideapublicschools.org.SY 21-22 – please download export \nwww.tcp.ideapublicschools.org.SY 22-23SY 22-23Not available yet!one rated school year ’s yet, \nTCP ratings/placements yet conducted. likely\nfinalized Fall 2022 early-October.School Years, “appeals” process takes place fall \noriginal placements submitted October. \nroughly 50% appeal rate (50% teachers managers appealing \nplacements) year. Appeals go appeals committee, \nappeals denied (given placement holds), appeals\napproved (placement changes). can alter TCP Export\nreport, static. export report changes depending \ncurrent day month; like know “original”\nplacements prior appeals, need download TCP Export data\ndirectly tcp application website prior appeals \nchanges made placement levels. good idea \ndownload TCP Export year beginning October \nfirst posted data, case changes time goes\n.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"data-matching","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5.1 Data Matching","text":"Jobvite 19-20 Teacher Export 19-20Jobvite 20-21 Teacher Export 20-21 Jobvite 21-22 Teacher\nExport 21-22 – Can’t ! TE 21-22 available yet!Thus, looking 2 years data:\nJobvite 19-20 Teacher Export 19-20\nJobvite 20-21 Teacher Export 20-21 + Removing Jobvite 19-20\nHires Start Date Fall 2019 + Removing\nJobvite 20-21 Hires Start Date Fall 2020 +\nRemoving Teacher Export 19-20 Teacher Export 20-21, \nJob Title Teacher + Removing Teacher\nExport 19-20 Teacher Export 20-21, Internal Role :\nJobvite 19-20 Teacher Export 19-20Jobvite 20-21 Teacher Export 20-21 + Removing Jobvite 19-20\nHires Start Date Fall 2019 + Removing\nJobvite 20-21 Hires Start Date Fall 2020 +\nRemoving Teacher Export 19-20 Teacher Export 20-21, \nJob Title Teacher + Removing Teacher\nExport 19-20 Teacher Export 20-21, Internal Role :SPED CPSPED ACPE CP(due SPED PE state mandated license\nrequirements required subjects, \nanalyzed separately).\nRemoving Teacher Export 19-20 Teachers work 19-20\nAcademic Year\nRemoving Teacher Export 19-20 Teachers work 19-20\nAcademic Year(Removing New Hires, Promotions starting Fall 2020, TCP Level 1)\nRemoving Teacher Export 20-21 Teachers work 20-21\nAcademic Year\nRemoving Teacher Export 20-21 Teachers work 20-21\nAcademic Year(Removing New Hires, Promotions starting Fall 2020, TCP Level 1)","code":""},{"path":"key-tables-measures-and-metrics.html","id":"join-tables","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5.2 Join Tables","text":"join? * Jobvite Employee ID & Work Email Teacher\nExport Employee ID Work Email. * Possibly join \nPROD1.Staffing.Employees table, contains First Name, Last Name,\nBirthday, Employee ID, Work Email","code":""},{"path":"key-tables-measures-and-metrics.html","id":"apr-report-for-june-2022","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5.3 APR Report for June 2022","text":"","code":""},{"path":"key-tables-measures-and-metrics.html","id":"promotions","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5.3.1 Promotions","text":"Examining rate promotions teachers teacher-leaders,\n20-21 SY 21-22 SY. using HRIS report May 21,\n2021 comparing HRIS report June 10, 2022.","code":""},{},{},{"path":"key-tables-measures-and-metrics.html","id":"tcp-retention-and-tcp-levels","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5.4 TCP Retention and TCP Levels","text":"One part TSLIP looks Teacher Retention TCP Placement Level. \nreason know many teachers \nleaving particular levels, may able determine reasons\n, provide needed support help retain teachers. Mid-year\neven end--year teachers leaving huge disruption students\nexpensive time-intensive hiring team. can \nimpacts student achievement classroom culture.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"missing-tcp-placements","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5.4.1 Missing TCP Placements","text":"TCP Retention 20-21 SY calculated using predictions \nTCP Placements 50% leavers. 200/400 leavers \nplaced TCP Levels manager knew teacher \nreturning. 21-22 SY, teachers placed \nTCP Level regardless known leaver status, \navailable Teacher Export sheet TCP website application.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"leaver-rates","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5.4.2 Leaver Rates","text":"Leaver rates 21-22 SY approximately: 17% Level 1, 16% Level 2,\n11% Level 3, 7% Level 4, 6% Level 5. Level 1 makes largest total\nnumber teachers IDEA; approximately 1/3 teachers IDEA “New\nIDEA” Level 1. number followed closely Level 4, \nmakes next largest group teachers IDEA. Level 2 \nsmallest number teachers. level sort “holding” level \nteachers didn’t score high enough composite score go\nstraight Level 1 Level 3. traditional path promote\nstraight Level 1 first year, Level 3.Total n TCP Level, 3432 Teachers IDEA, 21-22 SY:\nLevel 1: 1185 Level 2: 90 Level 3: 813 Level 4: 1010 Level 5: 334Going forward 21-22 SY TCP, teachers supposedly placed\nTCP Placement Levels, regardless known leaver-status. \nhelp issue analyzing retention teachers TCP\nLevel, teachers TCP Level October 2022 TCP\ncomes . Teachers left still available Teacher\nExport file TCP website/application, according TCP Team.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"exit-surveys-for-teacher-leavers","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5.4.3 Exit Surveys for Teacher Leavers","text":"leavers TCP Retention project matched \ntook Exit Surveys. many cases, Exit Survey \nTeacher Leaver TCP Retention project, cases, \nleavers Exit Survey TCP Retention project list\nteachers. still reviewing Exit Survey data clues \nteachers various levels might leave (either mid-year EOY),\nhope can help inform ways support teachers \nleave instead retained.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"tcp-levels-and-composite-score-correlations","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.12.5.5 TCP Levels and Composite Score Correlations","text":"TCP Placement Levels high correlation TCP Composite\nScores. Composite Score composed five components (GET Ratings,\nStudent Achievement, Parent Surveys, Student Surveys, Core Values).\nscore loosely used decide teacher’s Placement Level, \ncan overridden manager, “hold”, appeal (generally\ninitiated manager). teachers get receive high\nenough Composite Score reach TCP Placement Level reached \nprior year, “hold” placed keep teacher prior year’s\nlevel (given higher year’s Composite Score). \nteacher one academic year get Composite Score raised\nhigh enough keep TCP Placement Level. Pandemic,\nteachers given two years (now, indefinite years \npandemic holds) “hold” time instead one. General cut-offs : 0\n1.4 rounds Level 1, 1.5 2.4 rounds Level 2, 2.5 3.4\nrounds Level 3, 3.5 4.4 rounds Level 4, 4.5+ rounds \nLevel 5. also hold changing content. teacher \nteaching chemistry now teaching physics, teacher \nplaced hold one year. teachers hold 2-3 years\nprior pandemic 19-20 SY, according TCP Team, thus \nteachers TCP hold 5-6 years point (end \n21-22 SY). Business rules may change updated added ,\n22-23 SY.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"big-board-databases","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.13 Big Board Databases","text":"big board databases provide information IDEA schools. \ndata available two databases, one historical data (starting SY\n22-23) current school year’s data.Current: [RGVPDRA-DASQL].[BigBoard]Historical: [RGVPDRA-DASQL].[BigBoardHistorical]database includes six tables, one following data\ntypes:Attendance ( [dbo].[attendance] )Attendance ( [dbo].[attendance] )Direct Instruction (Reading) ( [dbo].[direct_instruction_reading] )Direct Instruction (Reading) ( [dbo].[direct_instruction_reading] )Enrollment ( [dbo].[enrollment] )Enrollment ( [dbo].[enrollment] )Internal Assessments – ELA ( [dbo].[internal_assessments_ela] )Internal Assessments – ELA ( [dbo].[internal_assessments_ela] )Internal Assessments – Math ( [dbo].[internal_assessments_math] )Internal Assessments – Math ( [dbo].[internal_assessments_math] )Internal Assessments – Writing (SY 24-25) (\n[dbo].[internal_assessments_writing] )Internal Assessments – Writing (SY 24-25) (\n[dbo].[internal_assessments_writing] )Note. structure tables across current \nhistorical databases. difference addition academic\nyear column distinguish various SYs within historical tables.Columns common across tables:[data_type]: data type (list provided )[data_type]: data type (list provided )[time_frame]: time frame (week, biweekly, quarter, month)[time_frame]: time frame (week, biweekly, quarter, month)[date]: date start time frame (YYYY-MM-DD)[date]: date start time frame (YYYY-MM-DD)[grouped_by]: aggregation options\ntime_frame | date | subject\ntime_frame | date | region | subject\ntime_frame | date | grade_level | subject\ntime_frame | date | subject | region | school\ntime_frame | date | region | grade_level | subject\ntime_frame | date | region | school | grade_level | subject\n[grouped_by]: aggregation optionstime_frame | date | subjecttime_frame | date | subjecttime_frame | date | region | subjecttime_frame | date | region | subjecttime_frame | date | grade_level | subjecttime_frame | date | grade_level | subjecttime_frame | date | subject | region | schooltime_frame | date | subject | region | schooltime_frame | date | region | grade_level | subjecttime_frame | date | region | grade_level | subjecttime_frame | date | region | school | grade_level | subjecttime_frame | date | region | school | grade_level | subject[region]: region (includes IDEA whole)[region]: region (includes IDEA whole)[school]: school short name, includes “[insert region]\nSchools” option[school]: school short name, includes “[insert region]\nSchools” option[grade_level_number]: grade level number (e.g., -2 = Grades,\n0 = Kindergarten, 1 = 1st grade)\nAttendance enrollment: grades\nDirect instruction: kindergarten-2nd grade\nInternal assessments: 3rd-8th grades\n[grade_level_number]: grade level number (e.g., -2 = Grades,\n0 = Kindergarten, 1 = 1st grade)Attendance enrollment: gradesAttendance enrollment: gradesDirect instruction: kindergarten-2nd gradeDirect instruction: kindergarten-2nd gradeInternal assessments: 3rd-8th gradesInternal assessments: 3rd-8th grades[grade_level]: grade level (Grades, K-12)\nAttendance enrollment: grades\nDirect instruction: kindergarten-2nd grade\nInternal assessments: 3rd-8th grades\n[grade_level]: grade level (Grades, K-12)Attendance enrollment: gradesAttendance enrollment: gradesDirect instruction: kindergarten-2nd gradeDirect instruction: kindergarten-2nd gradeInternal assessments: 3rd-8th gradesInternal assessments: 3rd-8th grades[measure]: measured\nAttendance: ada (average daily attendance)\nEnrollment: budget_driver_percent (percent budget driver\nenrollment = number students enrolled / budget driver\nenrollment * 100)\nDirect instruction internal assessments: ogl_percent\n(percent students grade level defined earning \nperformance band score least 3)\n[measure]: measuredAttendance: ada (average daily attendance)Attendance: ada (average daily attendance)Enrollment: budget_driver_percent (percent budget driver\nenrollment = number students enrolled / budget driver\nenrollment * 100)Enrollment: budget_driver_percent (percent budget driver\nenrollment = number students enrolled / budget driver\nenrollment * 100)Direct instruction internal assessments: ogl_percent\n(percent students grade level defined earning \nperformance band score least 3)Direct instruction internal assessments: ogl_percent\n(percent students grade level defined earning \nperformance band score least 3)[value]: value measure[value]: value measureStatistical process\ncontrol\n[aux_data_lpl]: lower natural process behavior limit (lower\ncontrol limit)\n[aux_data_upl]: upper natural process behavior limit (upper\ncontrol limit)\n[indicators_spc_flag]: flag indicate value \noutside lower upper limit\nStatistical process\ncontrol[aux_data_lpl]: lower natural process behavior limit (lower\ncontrol limit)[aux_data_lpl]: lower natural process behavior limit (lower\ncontrol limit)[aux_data_upl]: upper natural process behavior limit (upper\ncontrol limit)[aux_data_upl]: upper natural process behavior limit (upper\ncontrol limit)[indicators_spc_flag]: flag indicate value \noutside lower upper limit[indicators_spc_flag]: flag indicate value \noutside lower upper limitThe remaining columns begin “aux_data” “indicators” \nspecific data type. Details remaining columns \nfollows:Attendance ( [dbo].[attendance] ):[aux_data_n_chronic_absent]: number chronically absent (ADA <\n90%)[aux_data_n_chronic_absent]: number chronically absent (ADA <\n90%)[aux_data_n_absent]: number absences[aux_data_n_absent]: number absences[aux_data_n_stu_days]: number days enrolled[aux_data_n_stu_days]: number days enrolled[aux_data_n_enrolled]: number students enrolled[aux_data_n_enrolled]: number students enrolled[indicators_percent_chronic_absent]: percent students \nchronically absent[indicators_percent_chronic_absent]: percent students \nchronically absentDirect Instruction (Reading) ( [dbo].[direct_instruction_reading] ):[aux_data_participant_count]: number students \nparticipated assessment(s)[aux_data_participant_count]: number students \nparticipated assessment(s)[aux_data_n_enrolled]: number students enrolled[aux_data_n_enrolled]: number students enrolled[indicators_participation_percent]: percent enrolled students\nparticipated assessment(s)[indicators_participation_percent]: percent enrolled students\nparticipated assessment(s)[indicators_low_participation_flag]: dichotomous variable \n1 indicates less 70% enrolled students participated[indicators_low_participation_flag]: dichotomous variable \n1 indicates less 70% enrolled students participatedEnrollment ( [dbo].[enrollment] ):[aux_data_n_enrolled]: number students enrolled[aux_data_n_enrolled]: number students enrolled[aux_data_budget_driver]: budget driver enrollment value[aux_data_budget_driver]: budget driver enrollment value[aux_data_campus_target]: campus target enrollment value[aux_data_campus_target]: campus target enrollment value[aux_data_over_enrollment]: -enrollment value[aux_data_over_enrollment]: -enrollment value[indicators_budget_driver_met]: dichotomous variable 1\nindicates budget driver enrollment met[indicators_budget_driver_met]: dichotomous variable 1\nindicates budget driver enrollment met[indicators_over_enrolled_count]: number students exceed\n-enrollment threshold (example: 120 \n-enrollment threshold enrollment 125,\nindicators_over_enrolled_count = 125 – 120 = 5.)[indicators_over_enrolled_count]: number students exceed\n-enrollment threshold (example: 120 \n-enrollment threshold enrollment 125,\nindicators_over_enrolled_count = 125 – 120 = 5.)Internal Assessments – ELA ( [dbo].[internal_assessments_ela] ),\nMath ( [dbo].[internal_assessments_math] ), Writing (\n[dbo].[internal_assessments_writing] ):[aux_data_participant_count]: number students \nparticipated assessment(s)","code":""},{"path":"key-tables-measures-and-metrics.html","id":"data-oddities-and-exceptions","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.14 Data Oddities and Exceptions","text":"","code":""},{"path":"key-tables-measures-and-metrics.html","id":"travis-campus","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.14.1 Travis Campus","text":"Accessing working data Travis campus Permian Basin\ncomes unique challenges. aren’t aware unique\ncontext, can easy end apparently “missing” data \nTravis may actually exist.Historically time writing (Fall 2025), IDEA Travis\nunique partnership Midland ISD (MISD). Although IDEA operates\nTravis, considered part MISD, therefore much \nTravis data provided us MISD rather collected \nstored manner IDEA Texas data.Although Travis, like IDEA Campuses, Academy (Elementary)\nCollege Prep (Middle High School), unique school IDs,\nmuch Travis data linked Travis Academy. example,\nTEA treats Travis campus single school (Academy), therefore\ndata accountability ratings STAAR assessment scores appear\nTravis Academy, despite older grades. \npulling STAAR scores, filter grades K-5 \nAcademy schools, miss STAAR scores grades 6-12 Travis\nCollege Prep, stored Academy.Another common challenge comes joining Travis data using school\nIDs. school IDs Travis within schools table 3-digit IDs,\nremainder schools use 9-digit state school number. \nmany (?) cases, data stored tables use Travis’ 9-digit\nstate school number.Please check school IDs data intend join check \npresence Travis data matches expectations joins.may use variation following R code create state\nschool number prior using joining.","code":"\nRegionSchools <- get_schools() %>%\n  select(SchoolNumber,\n         SchoolName,\n         SchoolShortName,\n         StateSchoolNumber,\n         SchoolAbbreviation,\n         SchoolLowestGrade,\n         SchoolHighestGrade,\n         CountyNumber,\n         CountyName,\n         RegionID,\n         Area,\n         RegionAltID,\n         IsDeprecated,\n         EstablishedYear) %>%\n  inner_join(get_regions(),\n             by = c(\"RegionID\" = \"RegionID\")) %>%\n  mutate(\n    StateSchoolNumber_permian = case_when(\n      CountyName == \"MIDLAND\" \n        ~ paste0(as.character(CountyNumber), as.character(StateSchoolNumber)), \n      .default = as.character(StateSchoolNumber)\n    )\n  )  %>%\n  mutate(StateSchoolNumber_permian = as.numeric(StateSchoolNumber_permian)) %>%\n  collect()"},{"path":"key-tables-measures-and-metrics.html","id":"joins","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.15 Joins","text":"possible information needed conduct analysis\nresides one table data warehouse. solve ,\njoin statement can used. appropriate join depends data\nneeds table structure. examples , five joins \ncovered: one inner four outer joins (left, right, full, anti).\njoin, matching key (common field tables) \nidentified. common keys IDEA data StudentNumber \nSchoolNumber.","code":""},{"path":"key-tables-measures-and-metrics.html","id":"inner-join","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.15.1 Inner Join","text":"inner join() retains observations matching key value \nfound x y. unmatched observations included\noutput. Visually,","code":""},{"path":"key-tables-measures-and-metrics.html","id":"left-join","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.15.2 Left Join","text":"left_join() outer join retains observations x.\nobservation x matching key y results\nNAs columns added y. observation y \nmatching key x included output. Visually,","code":""},{"path":"key-tables-measures-and-metrics.html","id":"right-join","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.15.3 Right Join","text":"right_join() outer join retains observations \ny. observation y matching key x\nresults NAs columns x. observation x \nmatching key y included output. Visually,","code":""},{"path":"key-tables-measures-and-metrics.html","id":"full-join","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.15.4 Full Join","text":"full_join() outer join retains observations x\ny. observation x matching key y\nresults NAs columns added y. observation y\nmatching key x results NAs columns\nx. Visually,","code":""},{"path":"key-tables-measures-and-metrics.html","id":"anti-join","chapter":"4 Key Tables, Measures, and Metrics","heading":"4.15.5 Anti-Join","text":"anti_join() outer join retains observations x\nmatching key y. observation x \nmatching key y included output. Visually,","code":""},{"path":"coding-standards.html","id":"coding-standards","chapter":"5 Coding Standards","heading":"5 Coding Standards","text":"naming convention “standard” R SQL typically used practices. Coding practices help future self others understand continue work.","code":""},{"path":"coding-standards.html","id":"general","chapter":"5 Coding Standards","heading":"5.1 General","text":"","code":""},{"path":"coding-standards.html","id":"introduction-headers","chapter":"5 Coding Standards","heading":"5.1.1 Introduction headers","text":"Include header beginning script. State purpose goal code, name, information can help anyone get speed code. Maintain log changes date indicate last changed - isn’t always necessary, good projects continue reused.templates can use different scripts.","code":""},{"path":"coding-standards.html","id":"r","chapter":"5 Coding Standards","heading":"5.1.1.1 R","text":"","code":"\n# header ----                                                                  #\n#                                                                              #\n# Filename: 01_describe_what_your_script_does.R                                #\n# Path: data/01_describe_what_your_script_does.R                               #\n# Author: Your Name                                                            #\n# Date created: 2025-10-15                                                     #\n# Date modified: 2025-10-31                                                    #\n# Purpose: Describe why you would use this script.                             #\n# Inputs: Identify any files, dependencies, etc. this script requires.         #\n# Outputs: Identify any named outputs, files, etc. this script produces.       #\n# Notes: Add any additional notes, links, etc. for others to execute your      #\n#        code properly.                                                        #"},{"path":"coding-standards.html","id":"sql","chapter":"5 Coding Standards","heading":"5.1.1.2 SQL","text":"","code":"/******************************************************************************/\n/* Filename: 01_describe_what_your_script_does.sql                            */\n/* Path: data/01_describe_what_your_script_does.R                             */\n/* Author: Your Name                                                          */\n/* Date created: 2025-10-15                                                   */\n/* Date modified: 2025-10-15                                                  */\n/* Purpose: Describe why you would use this script.                           */\n/* Inputs: Identify any files, dependencies, etc. this script requires.       */\n/* Outputs: Identify any named outputs, files, etc. this script produces.     */\n/* Notes: Add any additional notes, links, etc. for others to execute your    */\n/*        code properly.                                                      */\n/******************************************************************************/"},{"path":"coding-standards.html","id":"naming-conventions-1","chapter":"5 Coding Standards","heading":"5.1.2 Naming conventions","text":"Use informative names. naming variables functions always good make informative names help make sense code. short long, just enough concise informative.","code":""},{"path":"coding-standards.html","id":"language-r","chapter":"5 Coding Standards","heading":"5.2 Language R","text":"","code":""},{"path":"coding-standards.html","id":"projects","chapter":"5 Coding Standards","heading":"5.2.1 Projects","text":"three general approaches use work R project, methodical approach ProjectTemplate can found project section manual. report style approach good short quick assignments. Shiny project UI controls used scenarios information needs absorbed multiple perspectives.ProjectTemplateQuarto RMarkdownShiny","code":""},{"path":"coding-standards.html","id":"variables","chapter":"5 Coding Standards","heading":"5.2.2 Variables","text":"Use underscore_separated .k.. snake_case: e.g. my_data_setBeing descriptive specific: e.g. raw_act_2022_2023","code":""},{"path":"coding-standards.html","id":"functions","chapter":"5 Coding Standards","heading":"5.2.3 Functions","text":"use case function reuseability. Don’t copy paste code, create function.naming function use lowerCamelCase: e.g., addTaskCallback <- function()Start verb naming function. .e., add, make, create, populate, doStay scopeAvoid Global Variables costs - Think function receipt, function take items need make outcome.","code":""},{"path":"coding-standards.html","id":"dplyr","chapter":"5 Coding Standards","heading":"5.2.4 dplyr","text":"Use dplyr tidyverse designed enable dataframe manipulation intuitive, user-friendly way.","code":""},{"path":"coding-standards.html","id":"language-sql","chapter":"5 Coding Standards","heading":"5.3 Language SQL","text":"","code":""},{"path":"coding-standards.html","id":"hard-bracket-encapsulation","chapter":"5 Coding Standards","heading":"5.3.1 Hard bracket encapsulation","text":"SELECT [FirstName] [Students] [AcademicYear] = ‘2021-2022’","code":""},{"path":"coding-standards.html","id":"variables-1","chapter":"5 Coding Standards","heading":"5.3.2 Variables","text":"Use Camel Case: DECLARE @AcademicYear VARCHAR(9)","code":""},{"path":"coding-standards.html","id":"joins-1","chapter":"5 Coding Standards","heading":"5.3.3 Joins","text":"Know joins know data.","code":""},{"path":"visualization-standards.html","id":"visualization-standards","chapter":"6 Visualization Standards","heading":"6 Visualization Standards","text":"Data visualization standards outlined handbook available . guidebook’s goal provide best practices make visualizations simple yet elegant, allowing clear message conveyed.","code":""},{"path":"visualization-standards.html","id":"idea-branding","chapter":"6 Visualization Standards","heading":"6.1 IDEA Branding","text":"producing visualization presentation publication, use IDEA 2024 Branding Guidelines established Marketing team. Many guidelines, particularly colors, already incorporated R package, ideacolors.","code":""},{"path":"visualization-standards.html","id":"the-ideacolors-package","chapter":"6 Visualization Standards","heading":"6.1.1 The ideacolors package","text":"ideacolors package used conjunction ggplot2 produce graphs visualizations consistent primary secondary brand color schemes. information, consult ideacolors documentation.install package, use following code:","code":"\n# install.packages(\"devtools\")\ndevtools::install_github(\"idea-analytics/ideacolors\")"},{"path":"visualization-standards.html","id":"ideacolors-themes-and-scales","chapter":"6 Visualization Standards","heading":"6.1.1.1 ideacolors themes and scales","text":"Consider following chart using mtcars data set, create scatter plot engine displacement fuel efficiency measured miles per gallon ’ve set color aesthetic (channel) number cylinders car’s engine :can quickly apply IDEA brand compliant colors using scale_color_idea() function:Super easy! can also easily change palette even reverse :Available palettes given idea_palettes variable can seen :","code":"\np <- ggplot(mtcars, \n            aes(x = disp, \n                y = mpg)) +\n  geom_point(aes(color = as_factor(cyl)))\n\np\nlibrary(ideacolors)\n\np +\n  scale_color_idea()\np +\n  scale_color_idea(palette = \"blueorange\", reverse = TRUE)\ncolorspace::swatchplot(idea_palettes)"},{"path":"visualization-standards.html","id":"differences-between-branding-guidelines","chapter":"6 Visualization Standards","heading":"6.1.1.2 Differences between branding guidelines","text":"branding guidelines released 2024 modifies 2019 color palette removes magenta accent favor vermillion accent. switch palettes, use year argument scale_color_idea() scale_fill_idea(). Note default behavior use recent branding guidelines available (case, year = 2024).information using different branding guidelines, please refer package vignette.","code":"\np +\n  scale_color_idea(year = 2019)"},{"path":"visualization-standards.html","id":"color-blindness","chapter":"6 Visualization Standards","heading":"6.1.2 Color Blindness","text":"Note IDEA’s brand colors completely safe color blindness. ’s palette adjustments check predominant types color blindness population:chart includes following types color blindness:Deuteranopia: Deuteranopia type color blindness primarily affects perception green color spectrum. People deuteranopia deficiency absence green cone cells eyes, responsible perceiving green light. result, difficulty distinguishing green red hues. red green colors may appear similar indistinguishable individuals deuteranopia.Deuteranopia: Deuteranopia type color blindness primarily affects perception green color spectrum. People deuteranopia deficiency absence green cone cells eyes, responsible perceiving green light. result, difficulty distinguishing green red hues. red green colors may appear similar indistinguishable individuals deuteranopia.Protanopia: Protanopia type color blindness primarily affects perception red color spectrum. Individuals protanopia lack reduced number functional red cone cells eyes. Consequently, struggle differentiate red green colors. may perceive colors muted similar appearance.Protanopia: Protanopia type color blindness primarily affects perception red color spectrum. Individuals protanopia lack reduced number functional red cone cells eyes. Consequently, struggle differentiate red green colors. may perceive colors muted similar appearance.Tritanopia: Tritanopia, also known blue-yellow color blindness, rarer form color blindness affects perception blue yellow color spectrum. People tritanopia deficiency absence blue cone cells eyes, leading difficulty distinguishing blue yellow colors.Tritanopia: Tritanopia, also known blue-yellow color blindness, rarer form color blindness affects perception blue yellow color spectrum. People tritanopia deficiency absence blue cone cells eyes, leading difficulty distinguishing blue yellow colors.","code":"\ncolorspace::swatchplot(idea_palettes, cvd = c(\"desaturate\", 'deutan', \"protan\", \"tritan\"))"},{"path":"visualization-standards.html","id":"raceethnicity-colors","chapter":"6 Visualization Standards","heading":"6.1.3 Race/Ethnicity Colors","text":"creating visuals Race/Ethnicity want consistent colors chosen race/ethnicity. Additionally, want ensure colors offensive group. colors used Diversity, Equity, Inclusion (DEI) work completed last couple months 2022.American Indian/Alaskan Native: idea_colors$melon (#F9A054)Asian: idea_colors$cyan (#53B4CC)Black: idea_colors$magenta (#EE3A80)Hispanic: idea_colors$blue (#0079C1)Multi-racial: idea_colors$lime (#A4C364): idea_colors$yellow (#FFDE75)Pacific Islander: idea_colors$darkblue (#1A4789)White: idea_colors$coolgray (#626363)Suppose data frame, df_reading_levels, contains information Academy students’ grade-level reading equivalents GradeLevelEquivalent race ethnicity RaceEthnicity column. create visualization reading levels using custom palette, ’ll need code palette three places:vector colors, outside plotting functionas aesthetic, inside initial plotting callas value, inside manual scale functionLet’s define palette vector. may need adjust names race ethnicity match factors data frame., inside geom_*() layer, assign appropriate column RaceEthnicity appropriate aesthetic aes(). (Depending visualization, aesthetic might fill, shape, etc.).One additional call needed force ggplot() use palette specified earlier.scale_color_manual() call accept vector colors specified earlier values, drop = FALSE forces legend show possible values colors race_ethnicity_legend, regardless appear RaceEthnicity column. (aesthetic fill, use scale_fill_manual(values = race_ethnicity_legend, drop = FALSE), ).default legend title use column name. However, labs() call relabels legend title color aesthetic “Race / Ethnicity”. (aesthetic fill, use labs(fill = \"Race / Ethnicity\"), ).","code":"\n# step 1\nrace_ethnicity_legend <- c(\"American Indian\" = idea_colors$melon,\n                           \"Asian\" = idea_colors$cyan,\n                           \"Black\" = idea_colors$magenta,\n                           \"Hispanic\" = idea_colors$blue,\n                           \"Other\" = idea_colors$yellow,\n                           \"Pacific Islander\" = idea_colors$darkblue,\n                           \"Two or more races\" = idea_colors$lime,\n                           \"White\" = idea_colors$coolgray)\n# step 2\nggplot(df_reading_levels) +\n  geom_boxplot(aes(x = GradeLevelEquivalent,\n                   color = RaceEthnicity))\n# step 2\nggplot(df_reading_levels) +\n  geom_boxplot(aes(x = GradeLevelEquivalent,\n                   color = RaceEthnicity)) +\n  # other layers go here... +\n  # step 3\n  scale_color_manual(values = race_ethnicity_legend,\n                     drop = FALSE) +\n  labs(color = \"Race / Ethnicity\")"},{"path":"visualization-standards.html","id":"grade-level-colors","chapter":"6 Visualization Standards","heading":"6.1.4 Grade Level Colors","text":"visualization reporting requires grouping across grade levels, using IDEA polo color grade level familiar palette IDEA schools. information uniforms, refer parent guide.following current polo colors grade level:Clearly, grade levels present one plot individually labeled (say, scatterplot), using one color multiple grade levels advised. However, color coding document table colors can repeated, palette can provide visual cues contextualize report.","code":""},{"path":"visualization-standards.html","id":"separation-colors","chapter":"6 Visualization Standards","heading":"6.1.5 Separation Colors","text":"reporting separation reasons Tyler Munis (located reporting.employees table), following colors used:Return Next Year FT Position: Dark Green (#214F28)Entity Change: Purple (#7030A0)Failed -9 Verification: Light Yellow (#FFDE75)Involuntary Position Eliminated: Burnt Orange (#C55A11)Involuntary Misconduct: Pink (#EE3A80)Involuntary Non-Renew: Light Blue (#BDD7EE)Involuntary Poor Performance: Navy Blue (#1A4789)Job Change Seasonal/Part-Time: Tan (#E5C09F)Call Show: Light Purple (#CD9BFF)Resign Lieu Termination: Green (#00B050)Voluntary Resignation Notice: Orange (#F9A054)Voluntary Resignation Notice: Blue (#0079C1)Voluntary Return Leave: Light Green (#A4C364)Voluntary Retirement: Dark Grey (#626363)following code defines palette vector can easily used values scale_fill_manual().","code":"\nseparation_reason_legend <- c(\"DID NOT RETURN NEXT YEAR IN FT POSITION\" = \"#214F28\",\n                              \"ENTITY CHANGE\" = \"#7030A0\",\n                              \"FAILED I-9 VERIFICATION\" =   \"#FFDE75\",\n                              \"INVOL POSITION ELIMINATED\" = \"#C55A11\",\n                              \"INVOLUNTARY MISCONDUCT\" = \"#EE3A80\",\n                              \"INVOLUNTARY NON RENEW\" = \"#BDD7EE\",\n                              \"INVOLUNTARY POOR PERFORMANCE\" = \"#1A4789\",\n                              \"JOB CHANGE TO SEASONAL / PART-TIME\" = \"#E5C09F\",\n                              \"NO CALL NO SHOW\" = \"#CD9BFF\",\n                              \"RESIGN IN LIEU OF TERMINATION\" = \"#00B050\",\n                              \"VOL RESIGNATION NO NOTICE\" = \"#F9A054\",\n                              \"VOL RESIGNATION WITH NOTICE\" =   \"#0079C1\",\n                              \"VOLUNTARY NO RETURN FROM LEAVE\" = \"#A4C364\",\n                              \"VOLUNTARY RETIREMENT\" = \"#626363\")"},{"path":"visualization-standards.html","id":"idea-palette-color-ramp","chapter":"6 Visualization Standards","heading":"6.1.6 IDEA Palette Color Ramp","text":"obtain color ramp IDEA palette hex codes, use following R code:example, IDEA palette color ramp six colors follows:","code":"# load libraries\nlibrary(ideacolors)\nlibrary(scales)\n\nshow_col(idea_palette_ramp()(___) # substitute blank with the number of colors desired\nshow_col(idea_palette_ramp()(6))"},{"path":"visualization-standards.html","id":"typography","chapter":"6 Visualization Standards","heading":"6.1.7 Typography","text":"primary brand font Proxima Nova; secondary fonts Arial Helvetica. using code, ensure fonts already installed. , add fonts visualization, use following code:code apply font consistently text visualization created R session. stop using custom fonts session, use showtext_auto(FALSE) revert default fonts.","code":"\n# install.packages(\"showtext\")\nlibrary(showtext)\n\nshowtext_auto()\nfont_add(\"proxima\",\n         regular = \"proximanova-regular.ttf\",\n         bold = \"proximanova-extrabold.ttf\",\n         italic = \"proximanova-regularit.ttf\",\n         bolditalic = \"proximanova-extraboldit.ttf\")\n\n# showtext_auto(FALSE) # revert back to default fonts"},{"path":"visualization-standards.html","id":"camp-rio-branding","chapter":"6 Visualization Standards","heading":"6.2 Camp RIO branding","text":"Camp RIO-specific analyses, visualizations, publications, use Camp RIO 2022 brand guidelines Advancement Marketing teams.","code":""},{"path":"visualization-standards.html","id":"camp-rio-scales","chapter":"6 Visualization Standards","heading":"6.2.1 Camp RIO scales","text":"use Camp RIO scales visualization, use scale_color_camp_rio() scale_fill_camp_rio(). default palette year = 2022.","code":"\np +\n  scale_color_camp_rio()"},{"path":"visualization-standards.html","id":"camp-rio-palette-ramp","chapter":"6 Visualization Standards","heading":"6.2.2 Camp RIO palette ramp","text":"palette ramp Camp RIO shown :","code":"\nshow_col(camp_rio_palette_ramp()(6))"},{"path":"visualization-standards.html","id":"typography-1","chapter":"6 Visualization Standards","heading":"6.2.3 Typography","text":"primary brand fonts Baloo Baloo 2; secondary fonts Verveine, useful taglines, Assistant, useful subheadings body text.","code":""},{"path":"visualization-standards.html","id":"visualizing-hierarchical-data","chapter":"6 Visualization Standards","heading":"6.3 Visualizing Hierarchical Data","text":"data often presented displayed hierarchically (e.g., state, region, school, etc.). Therefore, may useful group visualizations hierarchy, rather arranging alphabetically another manner.Let’s use gapminder data R, row life expectancy, population, GDP per capita corresponding specific country specific year.visualize changes life expectancy vs. GDP per capita time like :line graphs arranged alphabetically country. However, might visually appealing intuitive reader graphs arranged continent country. , can use ggh4x package (documentation ), switch facet_grid() facet_wrap() ggplot2 facet_nested() facet_nested_wrap() ggh4x.","code":"\nlibrary(gapminder)\n\nset.seed(1234)\nsample <- gapminder::gapminder %>%\n  distinct(country) %>%\n  slice_sample(n = 10) %>%\n  pull()\n\ndf_gapminder_sample <- gapminder::gapminder %>%\n  group_by(country) %>%\n  filter(country %in% sample)\n\ndf_gapminder_sample %>%\n  slice_head(n = 2) %>%\n  knitr::kable()\ndf_gapminder_sample %>%\n  ggplot(aes(x = gdpPercap, y = lifeExp,\n             color = continent,\n             alpha = year)) +\n  geom_point(aes(size = pop)) +\n  geom_path(size = 1) +\n  \n  # each country has a separate panel, arranged alphabetically by country\n  facet_grid( ~ country,\n                labeller = labeller(country = label_wrap_gen(width = 10)),\n                scale = \"free_x\") +\n  theme_idea_min() +\n  theme(axis.text.x = element_text(size = 8,\n                                   angle = 90)) +\n  labs(size = \"Population\",\n       alpha = \"Year\",\n       color = \"Continent\",\n       x = \"Per capita GDP\",\n       y = \"Life expectancy\",\n       title = \"Life expectancy vs. per capita GDP\")\nlibrary(ggh4x)\n\ndf_gapminder_sample %>%\n  ggplot(aes(x = gdpPercap, y = lifeExp,\n           color = continent,\n           alpha = year)) +\n  geom_point(aes(size = pop)) +\n  geom_path(size = 1) +\n  \n  # each country has a separate panel,\n  # but arranged alphabetically by continent, then by country\n  facet_nested( ~ continent + country,\n                labeller = labeller(country = label_wrap_gen(width = 10)),\n                scale = \"free_x\") +\n  theme_idea_min() +\n  theme(axis.text.x = element_text(size = 8,\n                                   angle = 90)) +\n  labs(size = \"Population\",\n       alpha = \"Year\",\n       color = \"Continent\",\n       x = \"Per capita GDP\",\n       y = \"Life expectancy\",\n       title = \"Life expectancy vs. per capita GDP\")"},{"path":"visualization-standards.html","id":"saving-and-publishing-visualizations","chapter":"6 Visualization Standards","heading":"6.4 Saving and publishing visualizations","text":"Data visualization can also communicate findings effectively external (R&) audiences. Often, graphs tables publish included slide decks products around organization. Thus, important consider quality (.e. plot resolution size) device output (e.g. .png, .pdf, .svg, etc.) visualization produced.Often, clicking Plots -> Export -> Save image... produces low-resolution bitmap (.bmp) resize appropriately. suggested use one following methods instead:","code":""},{"path":"visualization-standards.html","id":"using-device-functions","chapter":"6 Visualization Standards","heading":"6.4.1 Using device functions","text":"save plot directly specified device, use “output sandwich” method.Open device using device function like png(), pdf(), jpeg(), etc.Include code produce output.Close device using dev.().Suppose needed save image .pdf file dimensions 3 inches 4 inches filename 01--high-quality-graph.pdf. , output sandwich look like :","code":"\n# 1. open the device\npdf(file = here::here(\"graphs\", \"01-my-high-quality-graph.pdf\"),\n    width = 3,\n    height = 4)\n\n# 2. include the code to produce the output\nggplot(my_data_frame) +\n  geom_histogram(aes(x = my_continuous_var)) +\n  \n  # other layers as needed\n  labs(title = \"My high quality graph\")\n\n# 3. close the device\ndev.off()"},{"path":"visualization-standards.html","id":"using-ggsave","chapter":"6 Visualization Standards","heading":"6.4.2 Using ggsave()","text":"function ggsave() provides wrapper around multiple device functions, like png() pdf(), gives nice defaults saving high quality plot object device choice. suggested use function like :Build plot assign plot object (<-).Determine dimensions, resolution, output needed final product.Use ggsave() specifications identified step 2. Note: file name MUST include extension device.Revise specifications needed.Suppose need include plot (.png) takes \\(\\frac{1}{4}\\) standard PowerPoint slide (16:9 widescreen). might want adjust zoom (scale = 1.5), change resolution (dpi = 320), change dimensions (6.5 inches 6.5 inches). used theme transparent background, also specify background (bg) white. , code look like :information saving output, reference ggplot2 book ggsave documentation.","code":"\nmy_plot <- ggplot(my_data_frame) +\n  geom_histogram(aes(x = my_continuous_var)) +\n  \n  # other layers as needed\n  labs(title = \"My high quality graph\")\n\nggsave(filename = here::here(\"graphs\", \"01-my-high-quality-graph.png\"),\n       plot = my_plot,\n       scale = 1.5,\n       width = 6.5,\n       height = 6.5,\n       units = \"in\",\n       dpi = 320,\n       bg = \"white\")"},{"path":"project-applications.html","id":"project-applications","chapter":"7 Project Applications","heading":"7 Project Applications","text":"team’s data analysis evaluation work done annual basis, annual performance reporting (APR) grant-funded evaluations analyzing academic performance state standardized tests student persistence data. project areas, data analyzed shared weekly monthly basis (.e., senior college applications, ACT test scores). -depth analyses also conducted team may involve multiple methods including quantitative, machine learning, qualitative methods gain breadth depth understanding particular topic.Work stored different places depending project team member(s). Generally, work stored Wrike project management ongoing projects ad hoc requests, GitHub repositories version control, R&Private Group folders accessibility collaboration.share work specific projects? chapter describes outlets publishing sharing results, findings, reports, dashboards.significant applications demonstrated chapter.","code":""},{"path":"project-applications.html","id":"section-github","chapter":"7 Project Applications","heading":"7.1 Version control with GitHub","text":"analysis projects need saved via Git (local computer) pushed GitHub. several benefits , future self, teammates:Since Git version control system, get save track changes work (data, source code, reports, PowerPoint decks, Shiny dashboards) incrementally.Incremental saving means can recover accidental plunders. ’s like Track Changes Word, multiple files folders. Spill Diet Coke laptop middle big analysis? big deal (’ve pushing commits GitHub, ’ll !)Collaboration much structured, powerful tools asynchronous work managing versions.Referencing reviewing code, tracking issues, sharing ’ve done seamless, means …work reproducible: anyone R&can pull repo GitHub, run analyses, add edit ’ve done, share changes back way communicative documented.setting web documentation R packages build becomes seamless.enough let’s get (want know , check excellent article Jenny Bryan)","code":""},{"path":"project-applications.html","id":"getting-started-with-git-github-and-rstudio","chapter":"7 Project Applications","heading":"7.1.1 Getting Started with Git, GitHub, and RStudio","text":"’s quick overview ’ll need , details follow:Dedicate directory (.k.. “folder”) .Dedicate directory (.k.. “folder”) .Make RStudio Project.Make RStudio Project.Make Git repository.Make Git repository.Go usual business. instead saving individual files, periodically make commit, takes multi-file snapshot entire project.Go usual business. instead saving individual files, periodically make commit, takes multi-file snapshot entire project.Push commits GitHub periodically.\nlike sharing document colleagues OneDrive DropBox sending email attachment.\nPush commits GitHub periodically.like sharing document colleagues OneDrive DropBox sending email attachment.","code":""},{"path":"project-applications.html","id":"first-steps","chapter":"7 Project Applications","heading":"7.1.1.1 First steps","text":"steps borrowed light editing Happy Git GitHub useR Jenny Bryan.Register GitHub account.Install update R RStudioInstall GitThose Windows want steps wellIntroduce Git.Prove local Git can talk GitHub.Cache username password don’t need authenticate GitHub interactively ad nauseum.Create save GitHub Personal Access Token (PAT).Prove RStudio can find local Git , therefore, can talk GitHub.","code":""},{"path":"project-applications.html","id":"feature-branch-workflow","chapter":"7 Project Applications","heading":"7.1.2 Feature Branch Workflow","text":"many workflows using Git remote repositories like GitHub. boil following steps:Pull fetch clone repo Github local machine. starting new project, ’ll need create new repo Github (can also start one machine). usually called main (formerly master) branch.Create new branch work .analysis, coding, writing.Periodically save snapshot entire project (files folders, except explicitly ignore). called *committing changes**.Every push commits remote repo. Congrats! ’ve just backed project remotely made easy share.Merge new analysis code back main branch. usually initiated something called pull request (admittedly little confusing).specific workflow use IDEA’s R&team Feature Branch workflow, benefit simple, minimizing merge conflicts. core idea behind Feature Branch Workflow feature development take place dedicated branch instead main branch. encapsulation makes easy multiple analysts work particular analysis without disturbing main codebase. also means main branch never contain broken code. Moreover, means ’ll likely get second third set eyes analysis. makes work transparent, helps enforce coding standards, helps spread cool new techniques ’ve implemented analysis.look like? Well, ’s picture feature branch workflow use manual:picture shows development manual time (left right) rendered GitHub’s network diagram: includes new branches created, commits made merges back main branch. black line main branch includes --date, “official” version book. green blue lines feature branches, diverge main checkout new branch. dots represent commits. Colored lines returning main branch indicate merge: new code now part main branch. might wondering unmerged yellow line labeld gh-page represents. special branch used GitHub Actions uses concept continuous integration/continuous delivery build website hosts manual. don’t need worry one; ’s simply used build site magically.","code":""},{"path":"project-applications.html","id":"example-workflow-with-this-manual-or-getting-your-feet-wet","chapter":"7 Project Applications","heading":"7.1.3 Example workflow with this manual, or getting your feet wet","text":"section going walk use git/github updating manual. ’ll () clone GitHub repo locally laptop, (ii) create feature branch, (iii) make changes documentation, save changes, commit changes git (.e., locally take snapshot), (iv) push changes (including commits) GitHub repo, (v) initiate pull request (.e., ask merge branch main branch), finally (vi) merge changes master branch.first things first:Verify initial set-steps aboveGet bio ready.**Note throughout steps ’ll show step. Ok. ready? Great! go.","code":""},{"path":"project-applications.html","id":"get-the-r_and_a_manual-repository-url","chapter":"7 Project Applications","heading":"7.1.3.1 Get the R_and_A_Manual repository URL","text":"Go R_and_A_Manual repo browser.Go R_and_A_Manual repo browser.main page repo click green Code button, Click HTTPS (default), click clipboard copy repo’s URL:\nmain page repo click green Code button, Click HTTPS (default), click clipboard copy repo’s URL:","code":""},{"path":"project-applications.html","id":"clone-the-repo","chapter":"7 Project Applications","heading":"7.1.3.2 Clone the repo","text":"Now ’ll pull remote repo GitHub onto computer. ’ll want think want save . example, save data analysis projects separate folders Data_Analysis/ folder. save manual just OneDrive.","code":""},{"path":"project-applications.html","id":"command-line","chapter":"7 Project Applications","heading":"7.1.3.2.1 Command line","text":"’m saving temporary space, navigating ~/tmp/~ cloning data:pull content repo: files, folders, commits, branches. Really whole kit kaboodle.","code":"cd ~/tmp/\ngit clone https://github.com/idea-analytics/r_and_a_manual.git"},{"path":"project-applications.html","id":"rstudio","chapter":"7 Project Applications","heading":"7.1.3.2.2 RStudio","text":"’s RStudio:RStudio, start new Project: File > New Project > Version Control > Git, click project icon upper right-hand corner IDE select New Project…. “repository URL” paste URL new GitHub repository. : https://github.com/idea-analytics/r_and_a_manual.gitBe intentional create project.click “Open new session”. Click Create Project create new directory, things:directory “folder” computera Git repository, linked remote GitHub repositoryan RStudio ProjectCool. now R&Manual files repo history computer!","code":""},{"path":"project-applications.html","id":"check-out-a-branch","chapter":"7 Project Applications","heading":"7.1.3.3 Check out a branch","text":"start anything check branch. branch like , temporary, disposable workspace. checkout branch create new copy repo changes make happen branch. ’re happy changes ready share ’ll create pull request. ’ll get .","code":""},{"path":"project-applications.html","id":"command-line-1","chapter":"7 Project Applications","heading":"7.1.3.3.1 Command line","text":"’s pretty straightforward. create branch, giving short meaningful name, check .can moves one line using git checkout -b flag:","code":"git branch update-bio-cjh\ngit checkout update-bio-cjhgit checkout -b update-bio-cjh"},{"path":"project-applications.html","id":"rstudio-1","chapter":"7 Project Applications","heading":"7.1.3.3.2 RStudio","text":"Click Git panel (usually upper right standard RStudio layout, YMMV ’ve customized layouts).Click purple “branch” icon (kinda looks like piece flowchart). Give short meaningful name (something like, update-bio-cjh). Make sure Sync branch remote checkbox selected; save step later push changes repo.","code":""},{"path":"project-applications.html","id":"making-changes-and-saving-them","chapter":"7 Project Applications","heading":"7.1.3.4 Making changes and saving them","text":"now new branch ready make changes. Go ahead open 02-Who_We_Are.Rmd file add name section, update bio save , usually .Now ’ll want commit changes, takes snapshot current state branch working .","code":""},{"path":"project-applications.html","id":"command-line-2","chapter":"7 Project Applications","heading":"7.1.3.5 Command line","text":"saving ’ll run git commit command -(adds changes) -m (add commit message) flag short description .often. awhile ’ll want push changes GitHub (frequently, often commits):’ve likely yet defined remote branch go, Git give helpful error gives command syncing local branch new remote branch:Go ahead copy run command.can just use git push branch changes saved remotely.","code":"git commit -a -m \"Updated Chris's bio\"git pushfatal: The current branch update-bio-cjh has no upstream branch.\nTo push the current branch and set the remote as upstream, use\n\n    git push --set-upstream origin update-bio-cjhgit push --set-upstream origin update-bio-cjh"},{"path":"project-applications.html","id":"maintaining-large-files","chapter":"7 Project Applications","heading":"7.1.3.6 Maintaining large files","text":"file 100 MB size (e.g., PowerBI dashboard), GitHub block commit (least send warning). two ways approaching issue:Use large file storage (LFS) extension commit file.Add file .gitignore file committed.","code":""},{"path":"project-applications.html","id":"large-file-storage-lfs","chapter":"7 Project Applications","heading":"7.1.3.6.1 Large file storage (LFS)","text":"Scenario: Suppose PowerBI file Persistence_Dashboard.pbix 137 MB size, handled normal Git workflow. need download LFS extension site: https://git-lfs.github.com/. download, follow steps:Open Git command line. (found solution RStudio GitHub Desktop).Switch repo branch large file.Install LFS extension correct repo branch usingTrack file extension (scenario, .pbix), usingTrack .gitattributesN.B. complete steps 3, 4, 5 switched correct repo branch. 6. Commit file push normally.commit, see message indicating LFS extension used file.","code":"git lfs installgit lfs track \"*.pbix\"git add .gitattributes"},{"path":"project-applications.html","id":"using-.gitignore","chapter":"7 Project Applications","heading":"7.1.3.6.2 Using .gitignore","text":"Alternatively, choose commit file just keep large file locally. (good option file can generated code, like .csv output). follow steps:file already exist, create text file called .gitignore repo.Add name file wish ignore .gitignore file (e.g., .Rdata ignored using ProjectTemplate).Save .gitignore commit.","code":""},{"path":"project-applications.html","id":"rstudio-2","chapter":"7 Project Applications","heading":"7.1.3.7 RStudio","text":"Git panel see changed (new) files show . ’ll want select check box file ’s modified (indicated M) needs added (indicated ). readies file updated commit: Click commit button new dialog box open, show changes ’ve made file. Select check box staged, isn’t already selected, add commit message click Commit ’re ready save repo, simply press Push button.","code":""},{"path":"project-applications.html","id":"merging-changes","chapter":"7 Project Applications","heading":"7.1.3.8 Merging changes","text":"Merging changes feature branch main branch requires go GitHub pull request. pull request essentially asking main branch “pull” changes technically known merge. steps:Go repo (https://github.com/idea-analytics/r_and_a_manual).may see info box suggesting can merge branch. , click Compare & pull request button. select branch click Pull Request icon.able merge (’ll know) click Create pull request button.Ask someone review request (ideally)Click Merge pull request button confirm merge.done feature branch feel free delete .’re done!’ll want careful working others. pulled main branch awhile ago risk main branch laptop --date main branch Github (others merged changes ).best remedy checkout pull main—gets date—checkout branch run git merge main. may resolve conflicts.","code":""},{"path":"project-applications.html","id":"project-process","chapter":"7 Project Applications","heading":"7.2 Project Process","text":"working project, need document analytical work, also organization management. multiple tools use plan, track, modify, evaluate progress among team stakeholders, evolve, certainly can add best practices tools. Namely, discuss set Wrike projects, set GRPI/RASI, use operating mechanisms, important project structures.key point backwards plan final product. project management tools document processes greater detail, way teacher might backwards plan assessment lesson, leader might document follow next steps meeting.","code":""},{"path":"project-applications.html","id":"general-project-management","chapter":"7 Project Applications","heading":"7.2.1 General project management","text":"project established, still need document progress move forward.project meeting, jot key points next steps comment, create new tasks.Add comments relevant tasks completed.Include links completed products.taking notes notebook, OneNote, Teams chat? Capture links relevant documents, GitHub repos, notes, pictures, etc. relevant task, comment, description Wrike project! ’ll able find things forgot months later.used GRPI/RASI project, sure update stakeholders, well.Include link GRPI/RASI Wrike project.update Wrike, update GRPI/RASI.GRPI/RASI succinctly summarize project.Things might change project. week, ask :scope work change?timeline project change?realize something else needed completed?, onIf need modify project, carve time . Evaluating progress help keep track, alert others project may take longer may end differently originally planned. course, document !","code":""},{"path":"project-applications.html","id":"wrike-projects-and-requests","chapter":"7 Project Applications","heading":"7.2.2 Wrike projects and requests","text":"use Wrike main project management system track workflow team. information requests generate Wrike task, accepted rejected work. know assigned request, can use Wrike following ways organize work.","code":""},{"path":"project-applications.html","id":"onboarding-and-setup","chapter":"7 Project Applications","heading":"7.2.2.1 Onboarding and setup","text":"tactical throughout week, review new Wrike requests.tactical throughout week, review new Wrike requests.Determine request accepted, , determine assigned task.Determine request accepted, , determine assigned task.Evaluate scope request team requester.Evaluate scope request team requester.Vet request thoroughly ask clarifying questions requester.ad-hoc request, keep request original queue set tasks (see next section).medium- long-term request, set project related tasks appropriate folder:\nEvaluation Projects\nImpact Analyses\nappropriate project folder\nEvaluation ProjectsImpact AnalysesAn appropriate project folderN.B. medium- long-term requests, consider establishing GRPI RASI stakeholders, common document scope progress work.","code":""},{"path":"project-applications.html","id":"goal-setting-and-deadlines","chapter":"7 Project Applications","heading":"7.2.2.2 Goal setting and deadlines","text":"Wrike project task page, start backwards planning deliverable. Ask :goal project? (document !)deliverable project? (document !)deliverable due? (document !)Assign goal deliverable task project.can create task deliverable assign due date.can use project/task description, leave comment, create task goal.Ex. “Deliver slide deck final report Dolores” deliverable, “2021-12-17” due date.","code":""},{"path":"project-applications.html","id":"defining-tasks-and-dependencies","chapter":"7 Project Applications","heading":"7.2.2.3 Defining tasks and dependencies","text":"Now, need accomplish goals produce deliverable. Ask :steps need produce deliverable?order need steps?certain steps require tasks completed first?step identified part (1), create new task.Tasks specific, bite-sized steps.Ex. “Make time series plot AP Spanish Language scores Mission CP” taskAssign tasks created step (2) backlog.Assign tasks created step (2) backlog.Create dependencies relevant steps.Create dependencies relevant steps.Link predecessors (.e., steps ) successors (.e., steps ) task/subtask.Establish due dates steps, including dependencies, etc.","code":""},{"path":"project-applications.html","id":"kanban-workflow","chapter":"7 Project Applications","heading":"7.2.2.4 Kanban workflow","text":"Kanban (Japanese word visual signal) workflow visualizing progress. track project tasks using Kanban board Wrike. Tasks can move workflow following order:\\(\\textrm{Backlog} \\rightarrow \\textrm{Work Progress} \\rightarrow \\textrm{Work Review} \\rightarrow \\textrm{Completed}\\)stage can roughly defined following:Backlog: category may hold tasks brainstorming future development. None tasks started.Work Progress: tasks pulled Backlog started. yet complete.Work Review: tasks reached critical benchmark development need final feedback revision. yet approved completion.Completed: tasks completed.use Kanban task workflow project:Open context menu project (right-click).Change default workflow -> tasks -> R&Kanban Task Board Workflow.choose “Board” view project, see Kanban board appropriate categories. Task cards created moved progress project.","code":""},{"path":"project-applications.html","id":"grpi-rasi","chapter":"7 Project Applications","heading":"7.2.3 GRPI and RASI","text":"use Wrike internally manage project, external teams access workspace. Therefore, must use different tools track goals roles cross-functional projects.GRPI tool governing Goals, Responsibilities, Processes, Interpersonal norms project. describes purpose group working project.RASI tool governing roles group member. task person : Responsible, Approving, Supporting, Informed.GRPI RASI shared relevant teams stakeholders. documents serve contract tracking system project. Note tools often paired together, smaller tasks benefit just RASI structure.information, visit Best Practices GRPI RASI.","code":""},{"path":"project-applications.html","id":"project-operating-mechanisms","chapter":"7 Project Applications","heading":"7.2.4 Project operating mechanisms","text":"monitor ongoing project group members (either internal external), consider appropriate operating mechanism. operating mechanism process (see GRPI) establishing work can done. meetings help establish maintain regular communication across teams (see Best Practice Strong Business Partnerships. IDEA, two common operating mechanisms :Daily huddle: (daily / morning / stand-) huddle short (less 10 minutes) recap progress prior day state priorities current day. team leader may also establish priorities team provide announcements. type operating mechanism optimal teams need align priorities day--day. Best Practice Daily Huddles also available.Daily huddle: (daily / morning / stand-) huddle short (less 10 minutes) recap progress prior day state priorities current day. team leader may also establish priorities team provide announcements. type operating mechanism optimal teams need align priorities day--day. Best Practice Daily Huddles also available.Tactical: (weekly / biweekly) tactical recurring meeting review goals, share information, solve short-term problems. Usually, recurring agenda items real-time agenda can flexible week--week. type operating mechanism optimal internal cross-functional teams working towards long-term goal. Best Practice Weekly Tactical also available.Tactical: (weekly / biweekly) tactical recurring meeting review goals, share information, solve short-term problems. Usually, recurring agenda items real-time agenda can flexible week--week. type operating mechanism optimal internal cross-functional teams working towards long-term goal. Best Practice Weekly Tactical also available.Consider reviewing Wrike, GRPI RASI, operating mechanisms record progress, notes, next steps.","code":""},{"path":"project-applications.html","id":"outgoing-data-requests","chapter":"7 Project Applications","heading":"7.2.5 Outgoing data requests","text":"data request project sent external--IDEA partner (potentially internal partners), data must vetted accuracy consistency prior data. team processes ensure publish consistent “source truth” can easily verified later.complete process, read document Outgoing Data Requests.","code":""},{"path":"project-applications.html","id":"section-ProjectTemplate","chapter":"7 Project Applications","heading":"7.3 ProjectTemplate (for analyses)","text":"ProjectTemplate R package approach. Simply put, ’s package builds scaffolding project, provides good features tracking package dependencies (though also use renv ), separating data loading prep analysis output, well caching long running processes, speeds analytical time.perfect? . features ’ll likely ever use (logging, code profiling, unit testing).new ProjectTemplate Getting Started Tutorial great. Indeed, ’s always good read docsSeriously, though. ProjectTemplate documentation great really set aside hour read . manual provide abbreviated overview use ProjectTemplate IDEA, stand official documentation.","code":""},{"path":"project-applications.html","id":"installing-projecttemplate","chapter":"7 Project Applications","heading":"7.3.1 Installing ProjectTemplate","text":"Installing package straightforward","code":"\ninstall.packages(\"ProjectTemplate\")"},{"path":"project-applications.html","id":"creating-a-project-with-projecttemplate","chapter":"7 Project Applications","heading":"7.3.2 Creating a project with ProjectTemplate","text":"Creating project pretty simple. Navigate typically save projects via RStudio run following commands:bestows upon following directory structure:’ll notice image .Rproj file, isn’t added ProjectTemplate. created Project RStudio first navigated direction ran following:create.project(\"../learning-pt/\", merge.strategy = \"allow.non.conflict\"),allows scaffold ProjectTemplate existing directory ignoring existing files folders (usually *.Rproj .git).","code":"\nlibrary(ProjectTemplate)\ncreate.project(\"learning-pt\")"},{"path":"project-applications.html","id":"what-goes-where","chapter":"7 Project Applications","heading":"7.3.3 What goes where","text":"use half directories ProjectTemplate Scaffolds. ’s use, order ’s evaluated ProjectTemplate run load.project():config directory contains configuration file global.dcf. first thing load.project() looks . full list setting . highlights, order importance.load_libraries: can set ‘’ ‘’. load_libraries , system load R packages listed libraries field described . default, load_libraries . highly recommend turn .‘libraries’: comma separated list R packages user wants automatically load load.project() called. packages must already installed calling load.project(). default, reshape2, plyr, tidyverse, stringr, lubridate packages included list. recommend dropping adding packages using project.data_loading: can set ‘’ ‘’. data_loading , system load data cache data directories cache taking precedence case name conflict. default, data_loading .cache_loading: can set ‘’ ‘’. cache_loading , system load data cache directory attempt load data directory. default, cache_loading .munging: can set ‘’ ‘’. munging , system execute files munge directory sequentially using order implied sort() function. munging , none files munge directory executed. default, munging .as_factors: can set ‘’ ‘’. as_factors , system convert every character vector factor creating data frames; importantly, automatic conversion occurs reading data automatically. ‘’, character vectors remain character vectors. default, as_factors . *good default, opposite base R.lib: directory used house helper functions. can store *.R file (like included helpers.R file). ** general rule thumb, ’ve copied--pasted block code twice, don’t third time; rather, abstract block function save directory. load.project sources files directory readying global.dcf.cache: ’ll store data sets () generated preprocessing step (ii) don’t need regenerated every single time analyze data. can use cache() function store data directory automatically. data set found cache data directories drawn cache instead data based ProjectTemplate’s priority rules. ProjectTemplate always checks running code data/ munge/ directories. can learn caching .data: store raw data files . encoded supported file format, ’ll automatically loaded call load.project(), *unless cached versions output exist cache/ directory.munge: can store preprocessing “data munging” code project. example, need add columns runtime, merge normalized data sets, globally censor data points, code stored munge directory. preprocessing scripts stored munge executed alphabetical order call load.project(), prepend numbers (digit like 01-aggregate_schools, 02-calc-means, …) filenames indicate sequential order. Files run cache/ data/ loaded.reports: can store output reports, especially RMarkdown reports, produce. final reports live.ProjectTemplate doesn’t always play well RMarkdown (well, really issue knitr). biggest issue running load.project() inside RMarkdown. ProjectTemplate complain reports/ directory ProjectTemplate directory, annoying. ’s easily fixed line code top RMarkdown Rproject:setwd(::()); load.project()change working directory top project run load.project. project loaded knitr set working directory back reports/, file references relative reports/src: ’ll store statistical analysis machine scripts. add following piece code start analysis script: library('ProjectTemplate); load.project() (don’t need tip ). also best ensure code ’s shared analyses src moved munge directory; , can execute analyses src directory parallel. future release ProjectTemplate provide tools automatically execute every individual analysis src parallel. may want cache() results well.graphs: can store graphs PowerPoints produce, exception already contained RMarkdown files.","code":""},{"path":"project-applications.html","id":"the-renv-package-ensuring-reproducibility","chapter":"7 Project Applications","heading":"7.4 The renv package: Ensuring reproducibility","text":"renv package goes long way solving pernicious problem: Dependency Hell. ’s good description problem:problem mostly manifests revisit recurring project year later. updated year variables code rerun code ready pat back BAM! code breaks. breaks previous 12 months packages relied upon year ago updated time don’t work packages. Sometimes need update packages everything hunky-dory; times brute force process doesn’t work. left trying understand changed multiple packages, need change code something thought take hour takes week, days feeling like ’re just banging head wall.issue alone enough convince need create reproducible environments.Another reason related often immediate: working analysis someone else. Perhaps fastidious use current version every package partner risk averse updates packages ’ve wild least year. boat ’re going problems., need create reproducible environments.common technique Python goes name virtual environments. renv R implementation concept pretty elegant. Along ProjectTemplate, use renv package ensure analysis projects :Isolated: project gets library R packages, can feel free upgrade change package versions one project without worrying breaking projects.Isolated: project gets library R packages, can feel free upgrade change package versions one project without worrying breaking projects.Portable: renv captures state R packages within lockfile, can easily share collaborate projects others, ensure everyone working common base.Portable: renv captures state R packages within lockfile, can easily share collaborate projects others, ensure everyone working common base.Reproducible: Use renv::snapshot() save state R library lockfile renv.lock. can later use renv::restore() restore R library exactly specified lockfile.Reproducible: Use renv::snapshot() save state R library lockfile renv.lock. can later use renv::restore() restore R library exactly specified lockfile.three points crucial working well others protection future self.usual, really read docs renv. thorough clear.’s also excellent FAQ","code":""},{"path":"project-applications.html","id":"setting-up-renv-with-a-new-project","chapter":"7 Project Applications","heading":"7.4.1 Setting up renv with a new project","text":"starting new project RStudio setting renv easy: just sure click Use renv project.Checking box add bootstrap renv, installing package necessary well folders files serve infrastructure.","code":""},{"path":"project-applications.html","id":"setting-up-renv-with-an-existing-project","chapter":"7 Project Applications","heading":"7.4.2 Setting up renv with an existing project","text":"’ve got project want starting using renv, ’s pretty straightforward.Install renv don’t : install.packages('renv')Use renv::init() initialize project. renv discover R packages used project, install packages private project library.’s really simple!","code":""},{"path":"project-applications.html","id":"using-renv","chapter":"7 Project Applications","heading":"7.4.3 Using renv","text":"renv workflow super duper simple, ’ve set :Work project usual, installing upgrading R packages required project evolves.Use renv::snapshot() save state project library. project state serialized file called renv.lock.want revert previous state project—.e., installed new version package ’s wreaking havoc project—simply use renv::restore().Following simple steps isolates project’s environment rest projects. downloading bleeding-edge, dev version package GitHub need new feature won’t pollute projects running just fine. isolation bit mentioned three points .","code":""},{"path":"project-applications.html","id":"collaborating-with-renv","chapter":"7 Project Applications","heading":"7.4.4 Collaborating with renv","text":"renv developers recommend following steps using renv collaborative settingsUse git/GitHub repo.Use git/GitHub repo.One user explicitly initialize renv project, via renv::init() starting RStudio project. create initial renv lockfile, also write renv auto-loaders project’s .Rprofile renv/activate.R. ensure right version renv downloaded installed collaborators start project.One user explicitly initialize renv project, via renv::init() starting RStudio project. create initial renv lockfile, also write renv auto-loaders project’s .Rprofile renv/activate.R. ensure right version renv downloaded installed collaborators start project.Share project sources, alongside generated lockfile renv.lock via GitHub. sure also share generated auto-loaders .Rprofile renv/activate.R via repo.Share project sources, alongside generated lockfile renv.lock via GitHub. sure also share generated auto-loaders .Rprofile renv/activate.R via repo.collaborator first launches project, renv automatically bootstrap , thereby downloading installing appropriate version renv project library. completed, can use renv::restore() restore project library locally machine.collaborator first launches project, renv automatically bootstrap , thereby downloading installing appropriate version renv project library. completed, can use renv::restore() restore project library locally machine.working project, collaborators may need update install new packages project. occurs, ’ll also want ensure collaborators using newly-installed packages. general, process looks like :user installs, updates, one packages local project library;user installs, updates, one packages local project library;user calls renv::snapshot() update renv.lock lockfile;user calls renv::snapshot() update renv.lock lockfile;user shares updated version renv.lock collaborators via github;user shares updated version renv.lock collaborators via github;collaborators —git pull—call renv::restore() install packages specified newly-updated lockfile.collaborators —git pull—call renv::restore() install packages specified newly-updated lockfile.bit care required collaborators wish update shared renv.lock lockfile concurrently – particular, multiple collaborators installing new packages updating local copy lockfile, conflicts need sorted afterwards.Use teams ensure changes renv.lock communicated everyone knows understands packages installed updated.information collaboration strategies, please visit environments.rstudio.com.","code":""},{"path":"project-applications.html","id":"renv-and-rstudio-connect","chapter":"7 Project Applications","heading":"7.4.5 renv and RStudio Connect","text":"short, issues, one important thing always keep mind publishing RStudio connect:renv generated .Rprofile file included deployments RStudio Connect.","code":""},{"path":"project-applications.html","id":"steps-to-create-a-github-repository-with-projecttemplate-and-renv","chapter":"7 Project Applications","heading":"7.5 Steps to Create a GitHub Repository with ProjectTemplate and renv","text":"step--step guide create GitHub repository ProjectTemplate renv. Note one way create repository.*Note. Replace “new_project” new project name1. Create folder repo2. Open R3. R: Set working directory use folder just created4. R: Set ProjectTemplate directory structure inside folder titled “new_project”5. R: Create project file named “new_project.Rproj” inside “new_project” folderStep 1: File > New ProjectStep 2: Existing DirectoryStep 3: Select “new_project” folder > check “Open new session” > click “Create Project”6. R: set reproducible environment within new RprojectStep 1: Tools > Project OptionsStep 2: Git/SVN > select “Git” Version control systemStep 3: Environments > check “Use renv project”7. GitHub: add repository GitHubStep 1: Open GitHub DesktopStep 2: File > Add local repository…Step 3: Select “new_project” folder > Add repositoryStep 4: Commit files repositoryStep 5: Publish repository > check “Keep code private” > select Organization “idea-analytics”8. R: install ideadata ideacolors packagesIf get error,use code instead10. R: open config > global.dcf change load_libraries TRUE + add ideadata ideacolors library list + add libraries needed + change configuration settings needed11. R: save state project library (time want save state project)","code":"\n\nsetwd(\"[insert your path]\")\n\ninstall.packages(\"ProjectTemplate\")\nlibrary(ProjectTemplate)\n\n# add to existing folder\ncreate.project(\"[insert your path]\", merge.strategy = \"allow.non.conflict\")\n\nlibrary(renv)\nrenv::install(\"idea-analytics/ideadata@main\")\n\ninstall.packages(\"devtools\")\nlibrary(\"devtools\")\ndevtools::install_github(\"idea-analytics/ideacolors\")\n\ndevtools::install_github(\"idea-analytics/ideacolors\", auth_token = \"my_personal_access_token\")\n\nrenv::snapshot()"},{"path":"project-applications.html","id":"publishing-projects","chapter":"7 Project Applications","heading":"7.6 Publishing Projects","text":"reports can published stakeholders variety sites. location , nice options .","code":""},{"path":"project-applications.html","id":"rstudio-connect","chapter":"7 Project Applications","heading":"7.6.1 RStudio Connect","text":"report written RMarkdown, can directly publish report RStudio RStudio Connect team site.publish report, following:Make sure output header section set output: html_document. can add options, like table contents formatting.Make sure output header section set output: html_document. can add options, like table contents formatting.Knit .Rmd find compiling errors publish.Knit .Rmd find compiling errors publish.Click blue Publish button upper right hand corner html output editor.Click blue Publish button upper right hand corner html output editor.Select RStudio Connect.Select RStudio Connect.Choose want publish source code just publish finished document. (source code useful report recurring can updated, finished document appropriate things like analytical reports.)Choose want publish source code just publish finished document. (source code useful report recurring can updated, finished document appropriate things like analytical reports.)Select analytics.ideapublicschools.org destination. , choose appropriate title report. Finally, click Publish.Select analytics.ideapublicschools.org destination. , choose appropriate title report. Finally, click Publish..Rmd filename long, report publish. ’ll need shorten filename get errors.Check report RStudio Connect make adjustments Settings gear.detailed guide publishing can found RStudio Connect documentation.","code":""},{"path":"project-applications.html","id":"power-bi","chapter":"7 Project Applications","heading":"7.6.2 Power BI","text":"dashboard created Power BI want directly publish dashboard app.powerbi.com (Power BI Online) steps . can go directly online view Power BI.Make sure top right signed account.Make sure top right signed account.Save report Publishing.Save report Publishing.Home menu, far right click PublishOn Home menu, far right click PublishSelect Workspace want Publish dashboard , click “Select”. want later post Published dashboard team site (TheHub), select “Research Analysis” Workspace Premium Content Workspace, noted diamond Workspace.Select Workspace want Publish dashboard , click “Select”. want later post Published dashboard team site (TheHub), select “Research Analysis” Workspace Premium Content Workspace, noted diamond Workspace.Go Power BI go dashboard Workspace Published two items, dashboard data.Go Power BI go dashboard Workspace Published two items, dashboard data.Click dashboard report go File > Embed report > Website portal copy link “’s link can use embed content.” Use link share post Team Site.Click dashboard report go File > Embed report > Website portal copy link “’s link can use embed content.” Use link share post Team Site.","code":""},{"path":"project-applications.html","id":"team-site-thehub","chapter":"7 Project Applications","heading":"7.6.3 Team Site (TheHub)","text":"R&Team Site Documents folder contains files upload Team Site.Team Site (TheHub) Documents folder confused R&Private Group Documents folder. [R&Private Group][R&Private Group] Documents folder contains shared folders R&team members use collaborative work storage.","code":""},{"path":"project-applications.html","id":"published-evaluation-plans","chapter":"7 Project Applications","heading":"7.6.3.1 Published Evaluation Plans","text":"annual basis, save copy final evaluation plan Team Site Documents folder select upload R&Team Site.Team Site (TheHub) Team Site Documents folder confused R&Private Group Documents folder. [R&Private Group][R&Private Group] Documents folder contains shared folders R&team members use collaborative work storage.Evaluation plans published annually Team Site (TheHub). Published evaluation plan files stored Team Site Documents folder > Evaluation > Evaluation Plans > FY 20## accessibility, consistency, organization purposes.annual basis, save copy final, approved, ready--publication evaluation plan appropriate Team Site Documents folder. Select files upload R&Team Site.","code":""},{"path":"models-and-methods.html","id":"models-and-methods","chapter":"8 Models and Methods","heading":"8 Models and Methods","text":"research involves wide variety methods statistics data science analyze problems answer questions educational data. consultation stakeholders, carefully select relevant approach(es) provide appropriate accurate product.use methods descriptive, inferential, predictive statistics understand information organization. choice frequentist vs. Bayesian methods always justified, choosing simplest, appropriate tool starting point analysis. , start analysis, design program influences establish methods research.","code":""},{"path":"models-and-methods.html","id":"research-design","chapter":"8 Models and Methods","heading":"8.1 Research design","text":"work requires us assign causation, must consider data collected deciding appropriate model.","code":""},{"path":"models-and-methods.html","id":"causal-inference","chapter":"8 Models and Methods","heading":"8.1.1 Causal inference","text":"data observational, want describe causal relationships data, must appeal potential outcomes. Thus, briefly cover relevant causal inference concepts techniques.student marked inclusion , say, tutorial group, like see much tutorial increased score test, compared scenario student attend tutorial. student attends tutorial, can measure outcome treatment (tutorial) seeing grade earned test; observe, however, outcome control (tutorial). Potential outcomes aims remedy .","code":""},{"path":"models-and-methods.html","id":"potential-outcomes","chapter":"8 Models and Methods","heading":"8.1.1.1 Potential outcomes","text":"Suppose treatment control outcomes student. like measure \\(\\delta_i = Y^1_i - Y^0_i\\), difference treatment outcome \\(Y^1_i\\) control outcome \\(Y^0_i\\) student \\(\\). , main estimators tutorial effect \\(ATE, ATT\\) \\(ATU\\), defined :\\(ATE = E[\\delta_i]\\) represents Average Treatment Effect \\(E[\\delta_i] = E[Y^1_i - Y^0_i]\\). words, \\(ATE\\) answers question “additional effect treatment?”\\(ATE = E[\\delta_i]\\) represents Average Treatment Effect \\(E[\\delta_i] = E[Y^1_i - Y^0_i]\\). words, \\(ATE\\) answers question “additional effect treatment?”\\(ATT = E[\\delta_i \\mid \\textrm{treatment group}]\\) represents Average Treatment effect Treatment group, \\(E[Y^1_i - Y^0_i \\mid \\textrm{treatment group}]\\). words, \\(ATT\\) answers question “additional effect treatment treatment group?”\\(ATT = E[\\delta_i \\mid \\textrm{treatment group}]\\) represents Average Treatment effect Treatment group, \\(E[Y^1_i - Y^0_i \\mid \\textrm{treatment group}]\\). words, \\(ATT\\) answers question “additional effect treatment treatment group?”\\(ATU = E[\\delta_i \\mid \\textrm{control group}]\\) represents Average Treatment effect Untreated (control) group, \\(E[Y^1_i - Y^0_i \\mid \\textrm{control group}]\\). words, \\(ATU\\) answers question “additional effect treatment control group?”\\(ATU = E[\\delta_i \\mid \\textrm{control group}]\\) represents Average Treatment effect Untreated (control) group, \\(E[Y^1_i - Y^0_i \\mid \\textrm{control group}]\\). words, \\(ATU\\) answers question “additional effect treatment control group?”\\(ATE\\) can decomposed weighted average \\(ATT, ATU\\), \\(ATE = p\\times ATT + (1-p)\\times ATU\\), \\(p\\) weight treatment group.\\(ATE\\) can decomposed weighted average \\(ATT, ATU\\), \\(ATE = p\\times ATT + (1-p)\\times ATU\\), \\(p\\) weight treatment group.scenario,\\(ATE\\) represents expected marginal effect tutorial group test scores students,\\(ATE\\) represents expected marginal effect tutorial group test scores students,\\(ATT\\) represents expected marginal effect tutorial group students participate tutorials, \\(ATT\\) represents expected marginal effect tutorial group students participate tutorials, \\(ATU\\) represents expected marginal effect tutorial group students participate tutorials.\\(ATU\\) represents expected marginal effect tutorial group students participate tutorials.Estimates may biased randomly assign students tutorials - select group based criteria. Using randomization inference, can separate assignment bias estimates \\(ATT, ATU\\) find appropriate estimates p-values \\(ATE\\).","code":""},{"path":"models-and-methods.html","id":"matching-models","chapter":"8 Models and Methods","heading":"8.1.1.2 Matching models","text":"can leverage large samples find potential outcome student matching students reasonably similar, using specified distance measure. Thus, can reasonably estimate \\(ATE\\) since treatment control outcomes.using matchit package R, can specify covariates like match data treatment control groups.","code":"\n#use matchit like a glm\nm_out <- matchit(ActiveIL ~ Race + Gender + Grade +\n                   SPED + LEP + EcoDis + GradeEquivalentBOY, #response specifies control/treatment, covariates specify what to match\n                 data = rs_il_mod,\n                 method = \"cem\", #specify matching method\n                 link = \"logit\",\n                 estimand = \"ATT\")\n\n#produces data frame with needed weights\nm_data <- match.data(m_out)\n\n#model uses weighted linear model to estimate causal effect of using Imagine Learning\nm_att <- lm_robust(GradeEquivalentGrowth ~ ActiveIL,\n                   data = m_data,\n                   weights = m_data$weights)\n\nsummary(m_att)"},{"path":"models-and-methods.html","id":"regression-discontinuity","chapter":"8 Models and Methods","heading":"8.1.1.3 Regression discontinuity","text":"","code":""},{"path":"models-and-methods.html","id":"instrumental-variables","chapter":"8 Models and Methods","heading":"8.1.1.4 Instrumental variables","text":"","code":""},{"path":"models-and-methods.html","id":"difference-in-differences","chapter":"8 Models and Methods","heading":"8.1.1.5 Difference-in-differences","text":"","code":""},{"path":"models-and-methods.html","id":"experimental-design","chapter":"8 Models and Methods","heading":"8.1.2 Experimental design","text":"ideal conditions, test effect program randomized controlled trials – usually happen. However, can still use tools design structure data variance appropriately.","code":""},{"path":"models-and-methods.html","id":"differences-among-distributions-of-groups","chapter":"8 Models and Methods","heading":"8.1.2.1 Differences among distributions of groups","text":"comparing means multiple groups, first need procedure compare means together. Afterward, might choose post-hoc procedure see pairs means different.common way comparing multiple means ANOVA (analysis variance). perform ANOVA:construct linear model save object lm_my_model <- lm() (see linear modeling )compare variance among groups using aov(lm_my_model)Suppose want use SEL survey results measure emotion regulation (quantitative variable) across multiple grade levels. see average EmotionRegulationScore differs grade levels, can use following code:, ANOVA suggests means , post-hoc analysis can reveal groups different.Determine many tests conducted.Use Bonferonni correction (appropriate correction) adjust p-values \\(\\alpha\\)-level.Choose appropriate post-hoc test:\nTukey HSD - check pairs means see pairs significantly different\nDunnett - compare means control\nHsu - check means “best”, either lowest highest group\nTukey HSD - check pairs means see pairs significantly differentDunnett - compare means controlHsu - check means “best”, either lowest highest group","code":"\n# linear model, where grade level is treated as a factor, not numeric\nlm_survey_results <- lm(EmotionRegulationScore ~ as.factor(GradeLevelID),\n                        data = df_sel_survey)\n\n# perform ANOVA\naov(lm_survey_results)"},{"path":"models-and-methods.html","id":"differences-among-levels-of-variables","chapter":"8 Models and Methods","heading":"8.1.2.2 Differences among levels of variables","text":"Educational data can often described hierarchy:Level 1: studentLevel 2: student within schoolLevel 3: student within school within regionA mixed model (also, hierarchical multilevel) allows fixed random effects, nesting give us different variances level. ideal modeling outcome can vary school regional differences - words, can vary slope intercept school region.Case 1: level 1 modelA model error term account grouping, modeling response student \\(\\), look like:\\(\\textrm{EmotionRegulationScore}_i = \\beta_0 + \\beta_1 \\times \\textrm{AvgDailyAttendance}_i + \\epsilon_i\\)can estimated using lm():Case 2: level 2 modelA mixed model error term accounts grouping student \\(\\) school \\(j\\), slope intercept dependent school, look like\\(\\textrm{LifeSatisfactionScore}_{ij} = \\beta_{0j} + \\beta_{1j} \\times \\textrm{AvgDailyAttendance}_{ij} + \\epsilon_{ij}\\)can estimated using lme4::lmer():Note intercept needs vary, code change towhile slope needs vary, code change toCase 3: level 3+ modelA mixed model three nested levels account , say student \\(\\) within school \\(j\\) within region \\(k\\). model look like\\(\\textrm{EmotionRegulationScore}_{ijk} = \\beta_{0jk} + \\beta_{1jk} \\times \\textrm{AvgDailyAttendance}_{ijk} + \\epsilon_{ijk}\\)coded asNote: initial level nesting coded using vertical pipe | subsequent levels nesting coded using backslash /.","code":"\nlm_survey_results <- lm(EmotionRegulationScore ~ AvgDailyAttendance,\n                        data = df_sel_survey)\n\nsummary(lm_survey_results)\n# install.packages(\"lme4\")\n# library(lme4)\nmm_survey_results <- lmer(EmotionRegulationScore ~ (1 + AvgDailyAttendance | SchoolName),\n                          data = df_sel_survey)\n\nsummary(mm_survey_results) # get all effects, correlations between fixed effects, ANOVA\nfixef(mm_survey_results) # get inference on fixed effects coefficients\nranef(mm_survey_results) # get estimates of random effects coefficients\nmm_random_intercept <- lmer(EmotionRegulationScore ~ (1 | SchoolName) + AvgDailyAttendance,\n                            data = df_sel_survey)\nmm_random_slope <- lmer(EmotionRegulationScore ~ (AvgDailyAttendance | SchoolName),\n                        data = df_sel_survey)\nmm_level_3 <- lmer(EmotionRegulationScore ~ (1 + AvgDailyAttendance | Region / SchoolName),\n                   data = df_sel_survey)"},{"path":"models-and-methods.html","id":"descriptive-statistics","chapter":"8 Models and Methods","heading":"8.2 Descriptive statistics","text":"summarizing distribution data, usually tasked describing (1) measures center, counts proportions categorical data, means medians quantitative data displaying values stakeholders. provide context increase statistical literacy team family, also describe (2) spread, (3) shape, (4) unusual features distribution.","code":""},{"path":"models-and-methods.html","id":"numerical-summaries---broad-principles","chapter":"8 Models and Methods","heading":"8.2.1 Numerical summaries - broad principles","text":"categorical data, consider distribution proportions counts (sample size) across various categories. One-way two-way frequency tables, marginal total proportions counts, useful displaying data.univariate, quantitative data, use shape distribution determine appropriate numerical measures. symmetric data, mean \\(\\bar{x}\\) mean(x) standard deviation \\(s\\) sd(x) can appropriate reporting accessible broad audience. skewed data, consider median \\(\\tilde{x}\\) median(x) (possibly MAD - median absolute deviation mad(x)), provide context choosing measures. Note: median also widely accessible statistic people, since describes midpoint distribution. Consider using alongside mean.bivariate data, use scatterplot determine linear measures can used appropriately. Pearson correlation \\(r\\) cor(x, y) can easily understood wide audience describe linear strength bivariate association. However, Spearman rank correlation cor(x, y, method = \"spearman\") can provide associative measure monotonic nonlinear associations, Kendall’s \\(\\tau\\) cor(x, y, method = \"kendall\") can describe concordance ordinal data.describing outliers report, care taken describing identify use (remove) outliers data set.One heuristic way deciding outlier ask , “observation belong sample?”decide observation fundamentally different others (e.g., school -model implement Imagine Learning way schools ), might consider removing observation. observation represents exceptional case proposed model, might consider keeping observation.general, modeling measure center spread function covariates (see Modeling predictive statistics).","code":""},{"path":"models-and-methods.html","id":"graphical-summaries---broad-principles","chapter":"8 Models and Methods","heading":"8.2.2 Graphical summaries - broad principles","text":"plenty ways display data, graphs accompanied explanation key features. aim help educators interpret data memorable, meaningful ways graphs without context can convey wrong information may obscure researcher attempted communicate. graph include descriptive title, axes, appropriate labels; consider using ideacolors package aesthetics.Selecting appropriate graphical display depends purpose analysis communication results. Bar graphs, line graphs, histograms, scatterplots place displaying central tendency; however, emphasis placed displaying variation within data.","code":""},{"path":"models-and-methods.html","id":"displaying-variation","chapter":"8 Models and Methods","heading":"8.2.2.1 Displaying variation","text":"Variation can addressed following (non-exhaustive) list:Comparing sample sizes, entire distribution within groupComparing sample sizes, entire distribution within groupComparing variation within groupsComparing variation within groupsDisplaying variation across timeDisplaying variation across timeClustering values region (conversely, gaps data)Clustering values region (conversely, gaps data)Different approaches altering alpha values, jittering, color scales, size, shape marker. sample code found :code spaces MedianGrowth multiple schools median growth, changes transparency level 0.2, changes color school. value MedianGrowthLaunch plotted “plus” shape larger size emphasize median growth school year.","code":"\n\nmake_Data_By_Launch_Cohort() %>%\n  ggplot(aes(x = LaunchSchoolYear,\n             y = jitter(MedianGrowth), #jittering of clustered points\n             group = School)) +\n  geom_point(aes(color = School, #change color by school\n                 alpha = 0.2), #set transparency level to 0.2\n             size = 3.5) + #increases size of point\n  geom_point(aes(y = MedianGrowthLaunch,\n                 color = LaunchOrder),\n             shape = 3, #changes shape to plus sign +\n             size = 5) +\n  scale_color_idea() + \n  theme_idea_light() +\n  facet_wrap(~LaunchOrder,\n             labeller = labeller(LaunchOrder = c(\"1\" = \"First Year\",\n                                                 \"2\" = \"Second Year\",\n                                                 \"3\" = \"Third Year\"))) +\n  labs(title = \"Median RenStar Reading Growth\",\n       subtitle = \"Results grouped by schools launching in the same year\",\n       caption = \"+ represents median RenStar reading growth for that launching cohort\",\n       x = \"Launch Year\",\n       y = \"Median RenStar Growth\") +\n  scale_x_discrete(labels = c(\"2017-2018\" = \"2017-18\",\n                              \"2018-2019\" = \"2018-19\",\n                              \"2019-2020\" = \"2019-20\",\n                              \"2020-2021\" = \"2020-21\")) + \n  theme(legend.position = \"none\")"},{"path":"models-and-methods.html","id":"inferential-statistics","chapter":"8 Models and Methods","heading":"8.3 Inferential statistics","text":"goal project inference, drawing conclusions population data, provide context conclusions, particularly around variability likelihood.","code":""},{"path":"models-and-methods.html","id":"interval-estimates","chapter":"8 Models and Methods","heading":"8.3.1 Interval estimates","text":"Suppose providing estimate, like forecasted student persistence rates. single point estimate may give us best target, due variability, surely reach exact forecast. Thus, also provide confidence interval (Bayesian credible interval) give lower upper bound around estimate. bounds found computing margin error around point estimate, determined bootstrapped quantiles.may instructive general audience interpret bounds “worst case scenario” “best case scenario”give visual around estimates. reference, see Persistence Dashboard (longer actively updated).","code":""},{"path":"models-and-methods.html","id":"p-values-and-hypothesis-testing","chapter":"8 Models and Methods","heading":"8.3.2 p-values and hypothesis testing","text":"deciding pattern relationship even exists, can choose model set hypotheses test. Given type explanatory response variables model, choose appropriately designed test (reference common tests). Often, test statistics p-values already given using package. Note term “statistical significance” may carry lot weight audience, use great caution. using explaining p-value, first recall thata p-value probability obtaining result extreme greater repeated sampling proposed distribution null hypothesismeaning probability operates assumption proposed model (null hypothesis) correct. (means change null hypothesis, get entirely different p-value data). Thus, look carefully choices modeling distribution affected significance result. Furthermore, choice level (typically, \\(\\alpha = 0.05\\)) arbitrary, make certain conclusions, :result p-value 0.06, another 0.04, one result necessarily “significant” .p-value imply large effect size .Statistical significance necessarily represent practical significance.communicating results, merely rely p-value. Supplement p-value explanations effect context, like interval estimate, graphs, margin error, transformed values.reference, see American Statistical Association’s statement p-values (2016).","code":""},{"path":"models-and-methods.html","id":"inferential-methods-with-the-infer-package","chapter":"8 Models and Methods","heading":"8.3.3 Inferential methods with the {infer} package","text":"{infer} package provides tidyverse grammar statistical inference. Like many packages referenced manual, read doc, excellent. section simply provide examples get started.infer implements straightforward inferential workflow, encapsulated four verbs:specify() relationship variableshypothesize() null relationship (.e., declare null hypothesis)generate() data holds null hypothesis true (.e, draws form null distribution)calculate()distribution statistics null distributions dataAdditionally package provides tools visualizing relationship null distributions observed data. workflow illustrated :Inferential methods based observed variable types numbersSample mean1 continuous variablemeans paired values1 continuous variable, measured twiceDifferences means across groups1 continuous variable grouped categorical variableAnalysis Variance (ANOVA)F-test","code":"\n hypothesize(null = \"point\", mu = hypothesized_value)\n hypothesize(null = \"point\", mu = 0)\ngss %>%\n  specify(age ~ partyid) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 1000, type = \"permute\") %>%\n  calculate(stat = \"F\")\nnull_dist_sim <- gss %>%\n  specify(college ~ finrela) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 1000, type = \"permute\") %>%\n  calculate(stat = \"Chisq\")"},{"path":"models-and-methods.html","id":"modeling-and-predictive-statistics","chapter":"8 Models and Methods","heading":"8.4 Modeling and predictive statistics","text":"large chunk statistical work involves developing model making predictions new set data. methods use range basic models, like least-squares linear model, non-parametric methods machine learning, like random forests. choice model largely depends goal project.","code":""},{"path":"models-and-methods.html","id":"linear-modeling","chapter":"8 Models and Methods","heading":"8.4.1 Linear modeling","text":"measure association two variables, usually start simple linear regression, essentially models mean (quantitative) response value function explanatory variables. mathematical model looks like :\\(\\mu_i = \\beta_0 + \\beta_1 x_{1i} + \\cdots \\beta_n x_{ni} + \\epsilon_i\\)Suppose want model number questions student gets correct STAAR exam function semester exam questions correct course grade.\\(\\textrm{STAARCorrect}_i = \\beta_0 + \\beta_1\\times\\textrm{SemesterExamCorrect}_i + \\beta_2\\times\\textrm{CourseGrade}_i + \\epsilon_i\\)estimate coefficients evaluate fit, can use following workflow:can describe coefficients additional unit effect number STAAR questions correct. example, coefficient SemesterExamQuestionsCorrect 1.34, say student gets additional correct answer semester exam, average, predicted increase STAAR questions correct 1.34.model identified using DAG, can interpret coefficient direct path causal effect.","code":"\n# df_staar_scores has columns StudentNumber, STAARQuestionsCorrect, SemesterExamQuestionsCorrect, CourseGrade, SchoolName, Approaches, Meets, Masters\n# all columns are numeric except SchoolName; StudentNumber, STAARQuestionsCorrect, SemesterExamQuestionsCorrect, CourseGrade are integers; Approaches, Meets, Masters are 0 or 1\n\n# run the regression (a linear model)\n# lm(formula = response ~ explanatory_1 + explanatory_2 + ..., \n#    data = data.frame)\nlm_staar <- lm(STAARQuestionsCorrect ~ SemesterExamQuestionsCorrect + CourseGrade,\n               data = df_staar_scores)\n\n# view the coefficients, std errors, model error, t-statistics, p-values, R^2\nsummary(lm_staar)\n\n# view residual plots, Q-Q plots, leverage plot (Cook's D)\n# par(mfrow = c(2, 2)) # use this if you want to view all 4 plots at once\nplot(lm_staar)"},{"path":"models-and-methods.html","id":"generalized-linear-modeling","chapter":"8 Models and Methods","heading":"8.4.2 Generalized linear modeling","text":"transformed response linear betas, use generalized linear model (GLM). common example GLM logistic regression, response binary, effectively predict odds event happening relative another event. mathematical model looks like :\\(g(\\mu_i) = \\beta_0 + \\beta_1 x_{1i} + \\cdots + \\beta_n x_{ni} + \\epsilon_i\\)\\(g(\\cdot)\\) link function mean\\(\\mu\\) mean responseNote many link functions, choice link mean response affect interpretation model. Different implementations R provide differing pieces information, best look documentation. However, base R provides glm() function, gives options choose link.Now suppose modeling probability student passing STAAR (probability approaches \\(P(\\textrm{App}_i)\\)) function semester exam questions correct course grade.\\(\\log{\\frac{P(\\textrm{App}_i)}{1 - P(\\textrm{App}_i)}} = \\beta_0 + \\beta_1\\times\\textrm{SemesterExamCorrect}_i + \\beta_2\\times\\textrm{CourseGrade}_i + \\epsilon_i\\), used logistic regression, models log odds (can converted probability), defining binomial family logit link. coefficient SemesterExamQuestions 0.04, student gets additional question correct semester exam, average, predicted odds passing increases \\(e^{0.04}\\), probability \\(\\frac{e^{0.04}}{1 + e^{0.04}}\\). (Use exp() function Euler’s constant, e.g. \\(e^{0.04} =\\)exp(0.04)).response multinomial (multiple categories), suggested use multinomial logistic regression. categories ordered, common assessment data, TCP ratings, Likert scales, etc., model may benefit using ordered responses ordinal logistic regression, improves power.example, modeling AP score (takes ordered levels 1 5) function semester exam questions correct course grade :\\(g(\\textrm{APScore}_i) = \\beta_0 + \\beta_1\\times\\textrm{SemesterExamCorrect}_i + \\beta_2\\times\\textrm{CourseGrade}_i + \\epsilon_i\\)See reference implementations ordinal logistic regression using various packages.","code":"\n# logistic regression to determine log odds of passing STAAR\nglm_staar <- glm(Approaches ~ SemesterExamQuestions + CourseGrade,\n                 family = binomial(link = \"logit\"),\n                 data = df_staar_scores)\n\n# view the coefficients, std errors, model error, z-scores, p-values, deviance\nsummary(glm_staar)"},{"path":"models-and-methods.html","id":"ordinal-logistic-regression-in-r","chapter":"8 Models and Methods","heading":"8.4.2.1 Ordinal logistic regression in R","text":"seen previous section, ordinal logistic regression appropriate regression model use levels categorical response variable ordered. sufficient sample size, training testing data frames can utilized. training data frame used estimate model testing data frame used, name implies, test . Predictions made testing data confusion matrix misclassification error following. sample R code accomplish steps.","code":"\n# load packages\nlibrary(tidyverse)\nlibrary(titanic)\nlibrary(tidymodels) \nlibrary(MASS)\n\n# load data\ndf <- titanic_train %>% \n  mutate(Pclass = as.factor(Pclass))\n\n# prepare training and testing data frames ----\nset.seed(21) \ndf_split <- initial_split(df, prop = 0.7) \ndf_train <- training(df_split) \ndf_test <- testing(df_split)\n\n# model ----\nolr <- polr(Pclass ~ Fare, \n            data = df_train,\n            Hess = TRUE)\nsummary(olr)\n\n# predict using testing data ----\npredicted_class <- predict(olr, df_test)  # predict the classes\nhead(predicted_class)\npredicted_probs <- predict(olr, df_test, type = \"probs\")  # predict the probabilities\nhead(predicted_probs)\n\n# confusion matrix and misclassification error ----\ntable(df_test$Pclass, predicted_class)  # confusion matrix\nmean(as.character(df_test$Pclass) != as.character(predicted_class))  # misclassification error"},{"path":"models-and-methods.html","id":"generalized-additive-modeling","chapter":"8 Models and Methods","heading":"8.4.3 Generalized additive modeling","text":"relationship explanatory response variables specified simple functions (linear, log, etc.), generalized additive model (GAM) can used fit nonlinear relationship. model uses splines, flexible somewhat less restrictive fitting polynomials.Suppose notice sharp increase enrollment beginning year, gradual decrease remainder year. parabola assumes rate increase decrease, polynomial fit data well. However, spline locally fit curvature data better describe shape.Note splines fit relationships within domain data. words, extrapolate 2021-22 enrollment splines 2022-23, unless believe relationship hold . Splines also may overfit data relationship unclear, use caution choosing model nonlinear relationships spline.resources learning GAMs listed :Wood, S. N. (2017). Generalized Additive Models: Introduction R (2nd ed.). Chapman Hall/CRC. (Comprehensive introduction author mgcv package)GAMs R (Short course Noam Ross)Generalized Additive Models (Short book Michael Clark)","code":"\nlibrary(mgcv) # widely used for fitting different types of GAMs\n\n# model enrolled students using a GAM\n# fit a linear relationship with years_open\n# fit a spline with date\ngam_enrollment <- gam(enrolled ~ years_open + s(date),\n                      data = df_enrollment) # use s() to enclose variables with a nonlinear relationship\n\n# check fitted coefficient on years_open, degrees of freedom on s(date)\nsummary(gam_enrollment)\n\n# plot fitted splines against response variable\nplot(gam_enrollment)"},{"path":"models-and-methods.html","id":"machine-learning","chapter":"8 Models and Methods","heading":"8.4.4 Machine learning","text":"goal moves beyond inference (describing estimating relationships) towards prediction (getting accurate response possible), can use machine (statistical) learning methods model data. tools particularly useful modeling nonlinear trends assume functional form.Note communicating results models may beyond general audience’s reach, caution taken describing marginal effect variable.ISLR website tidymodels implementation consulted details models.","code":""},{"path":"models-and-methods.html","id":"supervised-learning","chapter":"8 Models and Methods","heading":"8.4.4.1 Supervised Learning","text":"","code":""},{"path":"models-and-methods.html","id":"unsupervised-learning","chapter":"8 Models and Methods","heading":"8.4.4.2 Unsupervised Learning","text":"Unsupervised learning type machine learning algorithms used different type input data supervised learning. Namely, unsupervised learning uses unlabeled data (whereas, supervised learning uses labeled data train models inputting test data) infer rules based looking patterns, grouping, anomalies, without explicit guidance instruction.\nstatistician prefer use unsupervised learning model? First, huge amount unlabeled data. Unlabeled data everywhere abundant easy access. Second, putting labels data takes hours, weeks even months, can extremely tedious. also often requires human labor put labels data. Next, can helpful useful explore raw data unknown data, looking patterns, associations, groupings. also helpful conducting pattern recognition statistician large data sets.","code":""},{"path":"models-and-methods.html","id":"clustering","chapter":"8 Models and Methods","heading":"8.4.4.2.1 Clustering","text":"technique used unlabeled data, explore break data groups (e.g., “clusters used”). groups based similarities differences.\ncommon type clustering K-means. method, data points assigned K groups, K number clusters based distance group’s centroid.","code":""},{"path":"models-and-methods.html","id":"association-rules","chapter":"8 Models and Methods","heading":"8.4.4.2.2 Association Rules","text":"rule-based approach discover correlations, co-occurrences, relationships within data, usually large data sets; , uses unlabeled data.","code":""},{"path":"models-and-methods.html","id":"dimensionality-reduction","chapter":"8 Models and Methods","heading":"8.4.4.2.3 Dimensionality Reduction","text":"method reduce number dimensions (.e., number variables one might used regression model) exclude extraneous, random, irrelevant factors data.","code":""},{"path":"models-and-methods.html","id":"examples","chapter":"8 Models and Methods","heading":"8.4.4.2.4 Examples:","text":"Anomaly detection identifying data points atypical type dataset\nOne type anomaly detection looking behaviors data deviate normal patterns data, expose fraudulent transactions","code":""},{"path":"models-and-methods.html","id":"references","chapter":"8 Models and Methods","heading":"8.4.4.2.5 References","text":"https://cloud.google.com/discover/--unsupervised-learning#section-5\nhttps://learn.g2.com/unsupervised-learning","code":""},{"path":"models-and-methods.html","id":"natural-language-processing-sentiment-analysis","chapter":"8 Models and Methods","heading":"8.4.5 Natural Language Processing (Sentiment Analysis)","text":"Natural Language Processing (NLP) process analyze, understand interpret linguistics, involves using machine learning algorithms linguistic techniques analyze classify subjective information. NLP can broken five parts: lexical analysis (structure), parse (tokenization), semantic analysis (meaning), discourse integration (contextualization), pragmatic analysis (intent).Within NLP, team specifically utilizes Sentiment Analysis. Sentiment analysis NLP process determining sentiment emotion expressed piece text, positive, negative, neutral. libararies use tidytext sentimentr tidyverse. example:","code":"\nlibrary(tidyverse)\nlibrary(tidytext)\n\nps_tb <- tibble(statment = \"The R&A manual is awesome and I love to working with it\") %>%\n  unnest_tokens(word, statment)\n\n# we can get overall positive vs. negative with the Bing lexicon **\nps_tb %>%\n  inner_join(get_sentiments(\"bing\"))"},{"path":"models-and-methods.html","id":"qualitative-methods","chapter":"8 Models and Methods","heading":"8.5 Qualitative Methods","text":"","code":""},{"path":"models-and-methods.html","id":"qualitative-research","chapter":"8 Models and Methods","heading":"8.5.1 Qualitative Research","text":"Qualitative Research provides IDEA Public Schools rich, contextual information various data collection analysis techniques aimed understand meaning information collected. qualitative research can used exploratory confirmatory research, useful context important, rich description needed, participant interpretation meaning experiences need considered.R&team specializes construction qualitative methods approaches, data collection, data analysis several qualitative methods.Common methods used collect data include:Individual InterviewsFocus GroupsReview archival documents.Common methods used analyze data include:Thematic analysisTriangulationLinguistic analysis\n– Emotions (including Natural Language Processing).","code":""},{"path":"models-and-methods.html","id":"qualitative-tools","chapter":"8 Models and Methods","heading":"8.5.2 Qualitative Tools","text":"","code":""},{"path":"models-and-methods.html","id":"maxqda","chapter":"8 Models and Methods","heading":"8.5.2.1 MaxQDA","text":"R&team engages qualitative analyses using several approaches (.e., Natural Language Processing, thematic analysis) tools. Qualitative analysis provides rich contextual information research projects IDEA Public Schools.One tool used thematic analyses MaxQDA, software program used assist analysis qualitative mixed-methods data.Data can imported :Survey data,Interview focus group data, andMedia (texts, images, audio, video) files.MaxQDA mainly used R&Evaluation team. Qualitative analyses used MaxQDA include:GPTW Annual OER Survey AnalysisCNP May Survey AnalysisEVP Analysis (Interviews, Focus Groups, Staff Survey)GPTW Pulse Check OER Survey AnalysisCore Values 2x2 Analysis","code":""},{"path":"models-and-methods.html","id":"importing-files","chapter":"8 Models and Methods","heading":"8.5.2.1.1 Importing Files","text":"various types text file formats can used MaxQDA analysis, Word, PDF, Excel documents. following section provides walk creating new project importing Excel documents MaxQDA.Create folders store original data, MaxQDA analysis, description visualizations, project deliverables.\nTip: sure prep save raw data folder prior opening MaxQDA.\n\nimage shows folder structure MaxQDA project.\n\nCreate folders store original data, MaxQDA analysis, description visualizations, project deliverables.Tip: sure prep save raw data folder prior opening MaxQDA.Tip: sure prep save raw data folder prior opening MaxQDA.\nimage shows folder structure MaxQDA project.\nOpen MaxQDA software select ‘New’ project. Create file name project save analysis folder created step 1 (e.g., ‘OER Analysis’).Open MaxQDA software select ‘New’ project. Create file name project save analysis folder created step 1 (e.g., ‘OER Analysis’).‘Import’ tab, click ‘Texts, PDFs, Tables’ icon.‘Import’ tab, click ‘Texts, PDFs, Tables’ icon.Select data file used analysis.\nIdentify columns ‘Document Group’ ‘Document name.’ Document group may describe certain characteristics groups (.e., students, regions). Document name refers individual documents (.e., participant #).\nSelect columns want imported ‘Code’ /‘Variable’. Code reflects text data OER analysis. Variable reflects data (.e., Likert responses, demographics) coded via OER analysis.\n\nimage shows import process new MaxQDA project.\n\nClick ‘Ok’, review data field, Click ‘Import’.\nSelect data file used analysis.Identify columns ‘Document Group’ ‘Document name.’ Document group may describe certain characteristics groups (.e., students, regions). Document name refers individual documents (.e., participant #).Identify columns ‘Document Group’ ‘Document name.’ Document group may describe certain characteristics groups (.e., students, regions). Document name refers individual documents (.e., participant #).Select columns want imported ‘Code’ /‘Variable’. Code reflects text data OER analysis. Variable reflects data (.e., Likert responses, demographics) coded via OER analysis.Select columns want imported ‘Code’ /‘Variable’. Code reflects text data OER analysis. Variable reflects data (.e., Likert responses, demographics) coded via OER analysis.\nimage shows import process new MaxQDA project.\nClick ‘Ok’, review data field, Click ‘Import’.Click ‘Ok’, review data field, Click ‘Import’.","code":""},{"path":"models-and-methods.html","id":"randomly-selecting-files","chapter":"8 Models and Methods","heading":"8.5.2.1.2 Randomly Selecting Files","text":"Depending purposes analysis total number responses, may want randomly select responses analysis.importing files Document System MaxQDA, responses can randomly selected using following steps:Select document group interest.Select document group interest.Right click highlighted document group.Right click highlighted document group.‘Activation’ section, select ‘…’ option.‘Activation’ section, select ‘…’ option.Select ‘Activate Documents Random’.Select ‘Activate Documents Random’.small window pop-. Enter desired n, click ‘Ok’.small window pop-. Enter desired n, click ‘Ok’.randomly selected documents appear Code System section MaxQDA. may need alter display frequency display ‘Coded segments activated documents’.Note: save randomly selected documents. suggest applying code randomly selected documents (.e., “random_sample”).","code":""},{"path":"evaluation-projects.html","id":"evaluation-projects","chapter":"9 Evaluation Projects","heading":"9 Evaluation Projects","text":"R&team conducts evaluations annual grant-funded projects specific ad hoc projects needed request.","code":""},{"path":"evaluation-projects.html","id":"evaluation-plans","chapter":"9 Evaluation Projects","heading":"9.1 Evaluation Plans","text":"organize guide work evaluation projects? Evaluation plans prepared annually annually funded grant project published Team Site. Annual evaluation projects may include several specific projects directly inform ongoing evaluation work. Evaluation plans also developed ad hoc specific evaluation needs, topics, projects.","code":""},{"path":"evaluation-projects.html","id":"about-evaluation-plans","chapter":"9 Evaluation Projects","heading":"9.1.1 About Evaluation Plans","text":"Annual Evaluation PlansThe annual evaluation plan provides summary plan work specific program, grant, service fiscal year. Evaluation plans adhere American Evaluation Association (AEA) guidelines standards high quality evaluation. Individual plans may customized best reflect work appropriate project.Evaluation plans serve communicate plan work guide expectations among stakeholders interested evaluation work. Evaluation plans may include following components: program description; evaluation purpose, objectives, evaluation research questions; methods scope evaluation, data collection, data analysis; timeline; required reporting deliverables; program support. Components described detail Evaluation Plan Guidelines.Evaluation plans created program grant managers. Evaluation plans drafted evaluation staff shared program managers partners review, feedback, approval. Annual evaluation plans must finalized approved September 30. Although annual evaluation plan agreed upon beginning year, unexpected events, challenges, circumstances may necessitate changes plan. evaluation plan subject change agreed upon decision making program manager evaluation staff. Evaluators held accountable producing evaluation plans meeting milestone requirements included timeline overall evaluation plan.","code":""},{"path":"evaluation-projects.html","id":"evaluation-plan-guidelines","chapter":"9 Evaluation Projects","heading":"9.1.1.1 Evaluation Plan Guidelines","text":"Standard components found evaluation plansBecause evaluation plans customized project, components may included every evaluation plan.Fiscal Year: 2022-2023Program/Grant Name:Program Manager/Partner:Grant/Fund Contact Person:Research Analytics Team Staff: (R&team members responsible work)Program Description\nGeneral information program. May include program goals, objectives, pertinent information understanding importance IDEA Public Schools (e.g., organizational goals, strategic plan, key action steps supported program).Fiscal Considerations\nCost-Effectiveness Cost-Benefit Measures (included evaluation)Evaluation Purpose\nMay include purpose statement, primary objectives, evaluation research questions addressed evaluation.Evaluation ObjectivesEvaluation Research QuestionsMethods Scope\nIncludes methods relevant data collected analyzed.Data CollectionData AnalysisRequired Reporting, Deliverables\nMandatory reporting requirements (funding agency entities) planned deliverables.Program/Project Support\nTypes ongoing support provided program staff course year. Ex: recurring meetings, data requests, etc.Sample language: Evaluation staff participate ongoing, regularly scheduled meetings program staff evaluation collaboration provision continuous feedback.Timeline\nLists organizes tasks, activities, focus areas planned year. timeline may combine months list month--month appropriate project. timeline serves communicate plans throughout year guide expectations among stakeholders interested evaluation work. Evaluators held accountable milestones highlighted timeline overall evaluation plan.Special Projects\nmay include ad hoc requests. applicable.Notes\nReaders document encouraged direct comments questions evaluations services Christopher Haid, VP Data Analytics, contact person(s) named plan.Although planned activities agreed upon beginning year may necessitate changes timeline due unforeseen challenges circumstances, timeline subject change agreed upon decision making program manager evaluation staff.","code":""},{"path":"evaluation-projects.html","id":"published-evaluation-plans-1","chapter":"9 Evaluation Projects","heading":"9.1.2 Published Evaluation Plans","text":"Evaluation Plans current fiscal year published Team Site (TheHub).Evaluation planning resources files stored [R&Private Group][R&Private Group] Evaluation folder.","code":""},{"path":"evaluation-projects.html","id":"annual-evaluation-projects","chapter":"9 Evaluation Projects","heading":"9.2 Annual Evaluation Projects","text":"R&team evaluates four (4) annually funded grants including: 1) 21st Century Afterschool Program, 2) Camp Rio, 3) Charter School Program (CSP), 4) Teacher School Leader Incentive Program (TSLIP).","code":""},{"path":"evaluation-projects.html","id":"st-century-afterschool-program","chapter":"9 Evaluation Projects","heading":"9.2.1 21st Century Afterschool Program","text":"IDEA Public Schools’ 21st Century Afterschool program provides high quality programming students hours traditional school day ended. afterschool program allows IDEA schools make positive difference lives students greatest needs, program aims provide additional support ensure students receiving guidance assistance need successfully progress towards college completion. 21st Century program centered around four main goals students: increasing achievement scores, improving student behavior attendance, increasing rates graduation grade promotion towards timely graduation.2021-2022 school year, majority IDEA schools implementing Afterschool Program funded 10th cycle 21st Century grant Elementary Secondary School Emergency Relief Fund (ESSER). schools located South Texas Rio Grande Valley served students pre-K 12th grade. following campuses funded 21st Century grant: IDEA Alamo, IDEA Donna, IDEA Frontier, IDEA McAllen, IDEA Mission, IDEA Pharr, IDEA Quest, IDEA San Benito, IDEA San Juan, IDEA Weslaco. following campuses covered ESSER funds: IDEA Brownsville, IDEA Edinburg, IDEA Elsa, IDEA Harlingen, IDEA La Joya, IDEA Los Encinos, IDEA North Mission, IDEA Owassa, IDEA Palmview, IDEA Rio Grande City, IDEA Robindale, IDEA Riverview, IDEA Sports Park, IDEA Toros, IDEA Tres Lagos, IDEA Weslaco Pike. addition, IDEA Health Professions funded Department Education IDEA Innovation funded Louisiana Department Education.Afterschool Program evaluation plan school year 2022-2023 can found . 2021-2022 program evaluation annual report can found .Student participation Afterschool program tracked PowerSchool pulled R&data warehouse server. program coordinators track programs students participate participated 45 days. Students participate 45 days classified “Regular Participants”. Student participate fewer 45 days classified “Non-Regular Participants”.Database: [RGVPDRA-DASQL].[Program21stCentury].[dbo].[Students][dbo].[Students] table tracks student program activity participation.Columns:\n* [AcademicYear]: Academic Year (.e., 2022-2023)\n* [Summer]: Summer data Indicator (0/1 indicator)\n* [FIRST_NAME]: Student First Name\n* [LAST_NAME]: Student Last Name\n* [STUDENT_NUMBER]: Student local ID number (108 number)\n* [ACADEMIC_SUPPORT]: Participation academic support programs (0/1 indicator)\n* [COLLEGE_CAREER_READINESS]: Participation College Career Readiness programs (0/1 indicator)\n* [FAMILY_ENGAGEMENT]: Participation Family Engagement programs (0/1 indicator)\n* [ENRICHMENT]: Participation Enrichment programs (0/1 indicator)\n* [DAY45]: 45 days participation one 21st Century programs (0/1 indicator)\n* [WHENCREATED]: Date record created\n* [WHENMODIFIED]: Date record modified\n* [WHENInserted]: Date record insertedA flag added beginning 2022-2023 school year indicate student participated 45 days .Chapter 4 (Temporary Insert):21st Century Afterschool Programs provide students afterschool opportunities get academic support, college career guidance, well family engagement activities. programs funded several avenues, grant Texas Education Agency, federal ESSER funds, Department Education, Louisiana Department Education. programs offered 26 campuses RGV, Health Professions Austin, Innovation Louisiana.FIRST_NAME: student’s first name;LAST_NAME: student’s last name;STUDENT_NUMBER: student’s 108 number;ACADEMIC_SUPPORT: binary indicator participation academic support activities;COLLEGE_CAREER_READINESS: binary indicator participation college career readiness activities;FAMILY_ENGAGEMENT: binary indicator participation family engagement activities;WHENCREATED: date/time stamp indicating date participation;WHENMODIFIED: date/time stamp indicating date record modified. values null.","code":""},{"path":"evaluation-projects.html","id":"st-century-afterschool-program-data-life-cycle","chapter":"9 Evaluation Projects","heading":"9.2.1.1 21st Century Afterschool Program Data Life Cycle","text":"21st Century Afterschool Program data found [RGVPDRA-DASQL].[Program21stCentury].[dbo].[Students] pulled nightly 12am. initial process deletes current data current school session data (2022-2023 Summer) new Academic Year changes longer summer, data deleted left last update. query run PowerSchool [U_IDEA_STUDENTS_OSS] table receive latest records 21st Century Afterschool Programs.","code":"SELECT   \n  FIRST_NAME, \n  LAST_NAME,\n  a.STUDENT_NUMBER,\n  b.ACADEMIC_SUPPORT, \n  b.COLLEGE_CAREER_READINESS, \n  b.FAMILY_ENGAGEMENT, \n  b.ENRICHMENT,  \n  b.DAY45, \n  b.WHENCREATED, \n  b.WHENMODIFIED \nFROM  STUDENTS a\nINNER JOIN \n(SELECT a.* FROM U_IDEA_STUDENTS_OSS a \n  INNER JOIN \n  (SELECT STUDENTSDCID, MAX(WHENCREATED) AS WHENCREATED \n    FROM U_IDEA_STUDENTS_OSS \n    WHERE YEARID = (SELECT \n  CASE WHEN (SELECT TO_CHAR((SELECT CURRENT_DATE FROM DUAL), 'MM') - 0 FROM DUAL) > 7 \n  THEN (SELECT TO_CHAR((SELECT CURRENT_DATE FROM DUAL), 'YYYY') - 1990 FROM DUAL) \nELSE (SELECT TO_CHAR((SELECT CURRENT_DATE FROM DUAL), 'YYYY') - 1991 FROM DUAL) \nEND FROM DUAL) \n    GROUP BY STUDENTSDCID ) b \n  ON a.STUDENTSDCID = b.STUDENTSDCID \n  AND a.WHENCREATED = b.WHENCREATED \n  WHERE a.YEARID = (SELECT \n  CASE WHEN (SELECT TO_CHAR((SELECT CURRENT_DATE FROM DUAL), 'MM') - 0 FROM DUAL) > 7 \n  THEN (SELECT TO_CHAR((SELECT CURRENT_DATE FROM DUAL), 'YYYY') - 1990 FROM DUAL) \nELSE (SELECT TO_CHAR((SELECT CURRENT_DATE FROM DUAL), 'YYYY') - 1991 FROM DUAL) \nEND FROM DUAL) )  b\nON a.DCID = b.STUDENTSDCID\nORDER BY  a.STUDENT_NUMBER"},{"path":"evaluation-projects.html","id":"camp-rio","chapter":"9 Evaluation Projects","heading":"9.2.2 Camp Rio","text":"Camp RIO operation since 2015 year-round outdoor education summer camp facility. located 85-acres predominantly untouched wildlife preserve Brownsville, Texas accessible regardless school district, ability, age. Camp RIO facility designed outdoor discovery adventure mission promoting healthy lifestyles exposing children benefits exploration, land stewardship, staying active various hands-activities.program provides guided outdoor activities fishing, canoeing, building campfires, geocaching, hiking, archery help connect participants community nature. inception 2015, number students attending Camp Rio per year increased hundred 28,000 students 2021-2022 school year.program evaluation Camp Rio focuses three main goals:\n1) understand short- long-term association students’ participation Camp RIO students’ interests natural resources land stewardship\n2) evaluate short- long-term association participation Camp RIO student academic achievement well-\n3) understand long-term association participation Camp RIO student college career choices natural sciences\nevaluation plan school year 2022-2023 can found . 2021-2022 annual report can found .","code":""},{"path":"evaluation-projects.html","id":"charter-school-program-csp-grants","chapter":"9 Evaluation Projects","heading":"9.2.3 Charter School Program (CSP) Grants","text":"Charter School Program (CSP) Replication Expansion grant awarded IDEA Public Schools provides funds support successful launch expansion new IDEA schools five years. Replication refers launching new schools. Expansion refers scaling existing schools.CSP grant applications submitted approved funding Department Education (DOE). grant application provides general guidance evaluation.CSP evaluation work informed evaluation questions aims address following areas: implementation IDEA model, needs challenges, organizational supports, sustainability strategies.main measures metrics reporting outcomes include student enrollment, student persistence, student average daily attendance, student academic performance, employee retention.","code":""},{"path":"evaluation-projects.html","id":"csp-2017","chapter":"9 Evaluation Projects","heading":"9.2.3.1 CSP 2017","text":"Evaluation work CSP Grants 2016 2017 conducted contracted agency, Copia Consulting, provided reports 2020 2021. 2021, contract Copia discontinued. fall 2022, R&staff conducted analyses prepared final evaluation report.CSP 2017 Final Evaluation Report OverviewThe 2017 CSP grant dedicated expanding IDEA schools Austin, San Antonio, Rio Grande Valley, launching new schools Tarrant County/Fort Worth. IDEA awarded CSP 2017 funds specific focus Department Education priorities serve low-income demographic promote diversity. stated approved grant application, aims five-year study two-fold: 1) understand whether support place new schools effective, 2) evaluate whether school model adaptations done fidelity. firm, Copia Consulting, hired conduct evaluation CSP 2017 grant grant cycle partnership IDEA Public Schools. Consistent objectives outlined grant evaluation, internal evaluation team within IDEA Division Research Analytics established end grant.report described performance IDEA schools receiving funds CSP 2017 grant terms school characteristics, student demographics, key outcomes associated organizational goals priorities. Key outcomes reported include student persistence, student average daily attendance (ADA), academic performance state assessments, staff retention.CSP 2017 Data Collection AnalysisData collected analyzed using R Excel.Data sources included:Documentation stored R&Private Group folder CSP Grants, CSP_2017 R Project, Idea Analytics Team Github repository CSP 2017.","code":""},{"path":"evaluation-projects.html","id":"csp-2019-and-2020","chapter":"9 Evaluation Projects","heading":"9.2.3.2 CSP 2019 and 2020","text":"R&conducts internal evaluation work two CSP grants:\n1) CSP Grant 2019-2024 2) CSP Grant 2020-2025.evaluation work CSP Grant guided annual CSP Grant Evaluation Plan.\ndetails, see Evaluation Plans.","code":""},{"path":"evaluation-projects.html","id":"csp-schools","chapter":"9 Evaluation Projects","heading":"9.2.3.2.1 CSP Schools","text":"CSP Schools Regions\nCSP evaluation focuses schools launching scaling SY 2018-2019, 2019-2020, 2020-2021, 2021-2022, 2022-2023, 2023-2024, 2024-2025 12 regions.CSP Schools Regions\nCSP evaluation focuses schools launching scaling SY 2018-2019, 2019-2020, 2020-2021, 2021-2022, 2022-2023, 2023-2024, 2024-2025 12 regions.Regions: Rio Grande Valley, San Antonio, Austin, El Paso, Baton Rouge, Tarrant County, Permian Basin, Houston, Tampa, Jacksonville, Cincinnati, Headquarters.Regions: Rio Grande Valley, San Antonio, Austin, El Paso, Baton Rouge, Tarrant County, Permian Basin, Houston, Tampa, Jacksonville, Cincinnati, Headquarters.Schools: List schools.Schools: List schools.Changes School Numbers & NamesChanges School Numbers & NamesTable documents changes School NumbersTable documents changes School Names (specifically, Amber Creek Robinson)Grade Levels: schools open launch Kindergarten, 1st, 2nd grades Academy level 6th grade College Prep level. However exceptions model.Grade Levels: schools open launch Kindergarten, 1st, 2nd grades Academy level 6th grade College Prep level. However exceptions model.School Opening Grade Exceptions:\nPrice Hill opened 6th 7th CP level.\nConverse opened PK, K, 1st Academy level.\nHidden Meadow opened PK, K, 1st Academy level.\nSchool Opening Grade Exceptions:Price Hill opened 6th 7th CP level.Converse opened PK, K, 1st Academy level.Hidden Meadow opened PK, K, 1st Academy level.","code":""},{"path":"evaluation-projects.html","id":"evaluation-questions","chapter":"9 Evaluation Projects","heading":"9.2.3.2.2 Evaluation Questions","text":"CSP Evaluation Question 1: extent replication expansion schools consistently implement key model elements defined IDEA leadership? , , implementation noted elements differ Academy College Prep campuses, school maturity (years operation) region?","code":""},{"path":"evaluation-projects.html","id":"csp-idea-model","chapter":"9 Evaluation Projects","heading":"9.2.3.2.3 CSP IDEA Model","text":"Research evaluation work aimed answer following question, “IDEA model launching scaling new schools?”CSP IDEA Model DevelopmentWhy develop model? preliminary research discussion, existing, comprehensive model launching /scaling new IDEA schools found.develop model? preliminary research discussion, existing, comprehensive model launching /scaling new IDEA schools found.develop initial model? reviewed accessible content online held series weekly discussions focused CSP.\nResearch conducted locate review IDEA model launching scaling new schools. Contents available online via Hub web reviewed analyzed. Specific examples included Academic Books, APO Playbooks, GET Rubrics, TCP Handbooks, Onboarding Guides, School Culture Components, Team Sites, IDEA Schools, Year 0.\nDiscussions focused CSP. R&Team Members various professional experiences administrators, evaluators, researchers, statisticians, students, teachers, volunteers. weekly discussion focused unique aspect CSP: 1) key components IDEA model; 2) processes involved launching scaling schools; 3) challenges needs launching scaling schools; 4) sustaining new schools; 5) roles leaders teams; 6) regions, new regions, new states; 7) viable metrics measures.\npart evaluation process, evaluators collected information, recorded notes, synthesized content three areas investigation: 1) IDEA model launching scaling new schools?; 2) challenges, needs, supports provided launching scaling schools?; 3) sustainability strategies implemented support launch expansion new schools?\ndevelop initial model? reviewed accessible content online held series weekly discussions focused CSP.Research conducted locate review IDEA model launching scaling new schools. Contents available online via Hub web reviewed analyzed. Specific examples included Academic Books, APO Playbooks, GET Rubrics, TCP Handbooks, Onboarding Guides, School Culture Components, Team Sites, IDEA Schools, Year 0.Research conducted locate review IDEA model launching scaling new schools. Contents available online via Hub web reviewed analyzed. Specific examples included Academic Books, APO Playbooks, GET Rubrics, TCP Handbooks, Onboarding Guides, School Culture Components, Team Sites, IDEA Schools, Year 0.Discussions focused CSP. R&Team Members various professional experiences administrators, evaluators, researchers, statisticians, students, teachers, volunteers. weekly discussion focused unique aspect CSP: 1) key components IDEA model; 2) processes involved launching scaling schools; 3) challenges needs launching scaling schools; 4) sustaining new schools; 5) roles leaders teams; 6) regions, new regions, new states; 7) viable metrics measures.Discussions focused CSP. R&Team Members various professional experiences administrators, evaluators, researchers, statisticians, students, teachers, volunteers. weekly discussion focused unique aspect CSP: 1) key components IDEA model; 2) processes involved launching scaling schools; 3) challenges needs launching scaling schools; 4) sustaining new schools; 5) roles leaders teams; 6) regions, new regions, new states; 7) viable metrics measures.part evaluation process, evaluators collected information, recorded notes, synthesized content three areas investigation: 1) IDEA model launching scaling new schools?; 2) challenges, needs, supports provided launching scaling schools?; 3) sustainability strategies implemented support launch expansion new schools?part evaluation process, evaluators collected information, recorded notes, synthesized content three areas investigation: 1) IDEA model launching scaling new schools?; 2) challenges, needs, supports provided launching scaling schools?; 3) sustainability strategies implemented support launch expansion new schools?move forward evaluation, draft model needed created developed showcase main elements IDEA Model opening new schools based review information discussions. notes reviewed, discussed, documented, content informing IDEA Model organized five key components.","code":""},{},{},{"path":"evaluation-projects.html","id":"teacher-and-school-leader-incentive-program-tslip","chapter":"9 Evaluation Projects","heading":"9.2.4 Teacher and School Leader Incentive Program (TSLIP)","text":"Grant contains four key components/areas research questions. Main points analysis: Level 5 Pilot Program “Best Practices” library; TCP Level percentages District/Region/Campus/School look percentage distribution TCP Level 5 teachers across schools possibly grade level.","code":""},{"path":"evaluation-projects.html","id":"focus-group-interviews-sampling-and-models","chapter":"9 Evaluation Projects","heading":"9.2.4.1 Focus Group Interviews, Sampling, and Models","text":"interviewing students 10 College Preps 10 Academies asking several questions find “working” “working” schools. sample carefully created using model fits Different Systems Design (MDSD). considered using Similar Systems Design, ran issue finding schools scored similarly across independent variables.Similar\n• Keep x’s except one xn; particular xn can vary different levels bins\n• Expect see different y values (outcome variable)\n• can say xn caused changes y (dependent variable varies xn)\n• Can eliminate x’s causes change/variation yFor Different Systems Design\n• x’s different, better yet “random” (don’t care different), except one xn (xn thing across subjects)\n• Expect see /similar y (differences outcome variable)\n• can say regardless different values various x’s, value xn caused /similar values y (independent variable xn – subjects – caused outcome variable subjects)Variables\n• x’s (independent/predictor variable)\no x1 = School Maturity (Scaling vs. Fully Scaled)\no x2 = Econ Dis\no x3 = Overall rating\no x4 = Domain 1/student achievement\no x5 = Domain 2/ growth\no x6 = Domain 3/\no x7 = Unknown variable (similar across schools, hoping extract interview process)\n• y (dependent/outcome variable)\no y = Teacher Retention RateMost Similar Systems Design (MSSD)\n(NOTE: two MSSD designs: one AC, one CP; comparing AC CP)\nDifferent x1 + x2 + x3 + x4 = Different y\nDifferent maturity + econ dis + overall rating + Domain1 = Different Retention Rate\no *can substitute another xi “different” x (doesn’t Maturity x different levels/bins); wanting see another particular xi predicts variation y (retention). example, can hold Maturity constant differences EconDis.Similar Systems Design (MSSD)\n(NOTE: two MSSD designs: one AC, one CP; comparing AC CP)\nDifferent x1 + x2 + x3 + x4 = Different y\nDifferent maturity + econ dis + overall rating + Domain1 = Different Retention Rate\no *can substitute another xi “different” x (doesn’t Maturity x different levels/bins); wanting see another particular xi predicts variation y (retention). example, can hold Maturity constant differences EconDis.Different Systems Design (MDSD)\n(NOTE: two MDSD designs: one AC, one CP; comparing AC CP)\nx1 + different x2 + different x3 + different x4 = y\nunknown variable + different maturity + different econ dis + different overall rating + different Domain1/student achievement = Retention Rate\no *can substitute another xi “” x (doesn’t Maturity x values across subjects); wanting see another particular xi predicts sameness/lack variation values y (retention). example, can differences Maturity, hold EconDis constant/across subjects.Different Systems Design (MDSD)\n(NOTE: two MDSD designs: one AC, one CP; comparing AC CP)\nx1 + different x2 + different x3 + different x4 = y\nunknown variable + different maturity + different econ dis + different overall rating + different Domain1/student achievement = Retention Rate\no *can substitute another xi “” x (doesn’t Maturity x values across subjects); wanting see another particular xi predicts sameness/lack variation values y (retention). example, can differences Maturity, hold EconDis constant/across subjects.using #2 Different Systems Design, model. Focus group interviews process scheduled. 8-12 students spanning STAAR tested subjects/grades selected AC CP (3rd-5th Academy, 6th-12th College Prep), total 20 focus groups.","code":""},{"path":"evaluation-projects.html","id":"tslip-continuanceyear-4-of-the-grant","chapter":"9 Evaluation Projects","heading":"9.2.4.2 TSLIP Continuance/Year 4 of the Grant","text":"Blanca Carillo applied extension grant Year 4. departments teams involved grant submitted requested budget Year 4 (October 1, 2023 September 30, 2024), Supplies, Equipment, Training Professional Development, Travel, Stipends (teacher leaders pilot groups), contractor hours/work.Ilissa Maura submitted budget last week April 2023 included requests funds contractor analyst 20 hours per week 32 weeks (2 semesters SY 23-24), well contractor services transcription 20 hours focus group interviews students teachers (possibly teacher leaders). analyst provide high level technical service analyzing grant data possibly synthesizing cumulative years grant product help school leaders decision making.Funds also requested audio recorders, travel conduct interviews, travel NLI NTI observations, travel 1-2 professional conferences per teammate, additional training professional development (technical qualitative training help analysis grant work help inform leaders information improve metrics teacher retention. Budget fund requests processed Blanca let team know approved. still close $4M TSLIP grant budget requests come funding 4th year (continuance year).usual supplies funding provided year grant office supplies items pencils, planners, printers, paper, etc., aid work TSLIP grant.","code":""},{"path":"evaluation-projects.html","id":"ad-hoc-evaluation-projects","chapter":"9 Evaluation Projects","heading":"9.3 Ad Hoc Evaluation Projects","text":"","code":""},{"path":"surveys.html","id":"surveys","chapter":"10 Surveys","heading":"10 Surveys","text":"chapter describes surveys, survey research, best practices conducted IDEA Public Schools.","code":""},{"path":"surveys.html","id":"about-survey-research","chapter":"10 Surveys","heading":"10.1 About Survey Research","text":"Surveys popular common way collect information sample people responses survey items (questions statements) aim understand population whole.Participants, instrumentation, data collection essential survey research.Survey research involves strategies qualitative, quantitative, mixed methods.","code":""},{"path":"surveys.html","id":"surveys-at-idea","chapter":"10 Surveys","heading":"10.2 Surveys at IDEA","text":"*Organization-wide surveys often conducted annual basis : Annual Employee Experience Survey (AEES), Great Place Work (GPTW), Student Survey, Family Survey, .*Program-specific surveys may conducted one times depending survey purpose, size scope program, program needs. R&supported data analysis surveys support programs including Child Nutrition Program (CNP), Social Emotional Learning (SEL), Camp Rio, 21st Century Afterschool Programs, .","code":""},{"path":"surveys.html","id":"best-practices","chapter":"10 Surveys","heading":"10.3 Best Practices","text":"","code":""},{"path":"surveys.html","id":"survey-planning","chapter":"10 Surveys","heading":"10.3.1 Survey Planning","text":"conduct survey? need plan conducting survey project?","code":""},{"path":"surveys.html","id":"survey-items","chapter":"10 Surveys","heading":"10.3.2 Survey Items","text":"","code":""},{"path":"survey-platforms.html","id":"survey-platforms","chapter":"11 Survey Platforms","heading":"11 Survey Platforms","text":"section R&Manual concerns details various software platforms use: general purpose software, steps using software, useful links learning .","code":""},{"path":"survey-platforms.html","id":"qualtrics","chapter":"11 Survey Platforms","heading":"11.1 Qualtrics","text":"Qualtrics survey data collection platform. allows survey building, distribution links via email text, response analysis, reporting. particularly useful feature Qualtrics ability upload list email addresses information associated email address send personalized survey link email address selected list. example, surveying district teachers one may want responses disaggregated race/ethnicity, school employment, grade level. information can linked teacher’s email address uploaded Qualtrics prior surveying teachers. data collected, response uploaded pieces information associated .following sessions outline create survey, upload list email addresses survey, create basic live report survey.","code":""},{"path":"survey-platforms.html","id":"creating-a-new-survey","chapter":"11 Survey Platforms","heading":"11.1.1 Creating a New Survey","text":"can start new survey blank survey form copying modifying existing survey. Either way, log Qualtrics, option want next. Assuming user license, log Qualtrics go IDEAps.Qualtrics.com select single sign-(SSO) option. projects created shared listed left side window right list find button creating new survey.next page, option create project survey. Select option press get started.\nnext page, name survey allowed start survey blank project, copy survey existing project, use survey previously stored library. starting blank project, next sections manual discuss types items next steps building survey.","code":""},{"path":"survey-platforms.html","id":"item-types","chapter":"11 Survey Platforms","heading":"11.1.2 Item Types","text":"come","code":""},{"path":"survey-platforms.html","id":"survey-flow","chapter":"11 Survey Platforms","heading":"11.1.3 Survey Flow","text":"come","code":""},{"path":"survey-platforms.html","id":"survey-logic","chapter":"11 Survey Platforms","heading":"11.1.3.1 Survey Logic","text":"come","code":""},{"path":"survey-platforms.html","id":"survey-blocks","chapter":"11 Survey Platforms","heading":"11.1.3.2 Survey Blocks","text":"Come","code":""},{"path":"survey-platforms.html","id":"survey-participant-lists","chapter":"11 Survey Platforms","heading":"11.1.4 Survey Participant lists","text":"come","code":""},{"path":"survey-platforms.html","id":"embeded-data","chapter":"11 Survey Platforms","heading":"11.1.4.1 Embeded Data","text":"come","code":""},{"path":"survey-platforms.html","id":"live-summary-reports","chapter":"11 Survey Platforms","heading":"11.1.5 Live Summary Reports","text":"come","code":""},{"path":"survey-platforms.html","id":"advanced-reports","chapter":"11 Survey Platforms","heading":"11.1.6 Advanced Reports","text":"Qualtrics, can create advanced report found ‘Reports’ tab. Reports tool allows create static live reports blank form copying modifying existing report.able customize reports based survey. Visualizations include charts (.e., bar, line, pie, breakdown), tables (.e., data, statistics, results), heat maps.Using breakdown visualization, can breakdown items certain demographics apply Display Logic (displays data presented visual certain criteria met). However, important keep mind Display Logic applies total count (N) specific Breakout Groups count (n).","code":""},{"path":"survey-platforms.html","id":"exporting-survey-data","chapter":"11 Survey Platforms","heading":"11.1.7 Exporting Survey Data","text":"","code":""},{"path":"survey-platforms.html","id":"export-survey-data-to-file","chapter":"11 Survey Platforms","heading":"11.1.7.1 Export survey data to file","text":"Survey data can exported various file types (.csv, .xlsx, among others). , go Data & Analysis tab, click Export & Import. , can select file type download data.Note 3 lines header .csv export - variable name, title, ImportId (html tags). attempt import .csv export R using readr::read_csv(), encounter errors. Instead, use qualtRics package (next section).","code":""},{"path":"survey-platforms.html","id":"read-survey-data-into-r","chapter":"11 Survey Platforms","heading":"11.1.7.2 Read survey data into R","text":"can directly read survey data metadata R. get Qualtrics data, need qualtRics package (notice capital R).following one-time steps ’ll need establish connection R Qualtrics API:Obtain API key Qualtrics. Click Account button (upper-right corner), choose Account Settings. , new version Account Settings, click Generate Token. Copy token.Determine base URL Qualtrics. Account Settings page, Datacenter ID already active. also use unique ID installing credentials.Install API credentials .Renviron file. R session, use following code install credentials.completed steps, can now simply load qualtRics library start importing survey data.However, need import survey directly exported .csv file Qualtrics, qualtRics package provides special function export. read_survey() function automatically handle three lines header removing html tags using title label variable.","code":"\n# install.packages(\"qualtRics\")\nlibrary(qualtRics)\n\nqualtrics_api_credentials(api_key = \"paste-your-api-key\",\n                          base_url = \"base_url.qualtrics.com\",\n                          install = TRUE)\nall_my_surveys <- all_surveys() # get survey IDs and names for surveys you can access\n\n# copy the survey ID you need\nmy_specific_survey <- fetch_survey(surveyID = \"paste-survey-id\") # gets survey in tidy format\nmy_survey_questions <- survey_questions(\"paste-survey-id\") # gets names of survey questions (but not each part)\nmy_metadata <- metadata(\"paste-survey-id\") # gets list of metadata\ncsv_survey <- read_survey(\"file-path.csv\") # only use to read a Qualtrics .csv export"},{"path":"survey-platforms.html","id":"where-can-you-learn-more","chapter":"11 Survey Platforms","heading":"11.1.8 Where Can You Learn More?","text":"Links added","code":""},{"path":"geospatial-methods-and-gis.html","id":"geospatial-methods-and-gis","chapter":"12 Geospatial Methods and GIS","heading":"12 Geospatial Methods and GIS","text":"chapter provides gentle introduction Geographic Information Systems (GIS) R simple features.","code":""},{"path":"geospatial-methods-and-gis.html","id":"what-is-a-simple-feature","chapter":"12 Geospatial Methods and GIS","heading":"12.1 What is a simple feature?","text":"Simple Features set ISO Open Geospatial Consortium (OGC) standards specify common storage access model geographic feature made mostly two-dimensional geometries (point, line, polygon, multi-point, multi-line, etc.) used geographic information systems. Simple features underlie common commercial open-source GIS platforms (e.g., ESRI ArcGIS, PostGIS, GeoJSON standard).feature essentially thing world. simple feature specification feature geometry describing Earth feature located, attributes, describe properties, like names metrics population.","code":""},{"path":"geospatial-methods-and-gis.html","id":"how-are-simple-features-implemented-in-r","chapter":"12 Geospatial Methods and GIS","heading":"12.1.1 How are simple features implemented in R","text":"word, simply. special feature R essentially row data.frame class sf. data.frame normal suspects—names things, metrics care —columns special column named geometry geom. typically list-column, meaning instead holding characters numbers, contents list list collection 2-d coordinates describe plot draw geometry. image illustrates structure sf data.frame","code":""},{"path":"geospatial-methods-and-gis.html","id":"sf-workflow","chapter":"12 Geospatial Methods and GIS","heading":"12.2 Workflows using sf objects","text":"Importing transforming data sf data frame somewhat different using data frames extra metadata encoded sf object. R&uses following skills (October 2023) …… basic sf handling:Distinguishing ordinary data frames sf data framesGeocoding using addressEstablishing coordinate reference system (CRS)Identifying using geometry columnUsing modifying bounding box (bbox)Using spatial joins… mapping data:Using mapping packagesCommon types map visualizations, including chloropleths dot densitiesAccessing transforming shapefilesComputing mapping isochronesComputing commute timesLayers vs. facetsStatic vs. interactive maps… working Census data:Census surveysCensus geographiesUsing Census API","code":""},{"path":"geospatial-methods-and-gis.html","id":"taco-gis","chapter":"12 Geospatial Methods and GIS","heading":"12.2.1 Guided example using TACO schools","text":"Let’s start getting schools Tarrant County (TACO). can get schools addresses data warehouse:","code":"\n# library(tidyverse)\n# library(ideadata)\n\n# schools_conn <- get_schools()\n\n# regions_conn <- get_regions() %>% \n#   filter(RegionDescription == \"Tarrant County\") %>%\n#   select(RegionID)\n\n# get the addresses of schools for geocoding \n\n# taco_schools <- schools_conn %>% \n#   inner_join(regions_conn, by = \"RegionID\") %>% \n#   select(SchoolShortName, SchoolStreet, SchoolCity, SchoolState, SchoolZipCode) %>% \n#   distinct() %>% \n#   collect() %>% \n#   janitor::clean_names()  \n\n# taco_schools\n\n# save(taco_schools, file = \"./taco_schools.Rda\")\n\nload(\"./taco_schools.Rda\")\n\nknitr::kable(taco_schools)"},{"path":"geospatial-methods-and-gis.html","id":"geocoding","chapter":"12 Geospatial Methods and GIS","heading":"12.2.2 Geocoding","text":"’ve got schools addresses! isn’t sufficient plot schools map, certainly don’t simple features data.frame.first stop geocoding addresses, simply getting latitude longitude. straightforward [tidygeocoder](https://jessecambon.github.io/tidygeocoder/) package provides great interface number different geocoders (e.g., US Census, OpenStreetMaps, geocod.io).Brilliant! ’ve got lat long variables addresses. Super Cool!Let’s transform now sf object:Notice lat long variables replaced geometry column.","code":"\nlibrary(tidygeocoder)\n\n# note that different geocoders may require a full address OR\n# an address split into components\ntaco_schools_geocoded <- taco_schools %>% \n    tidygeocoder::geocode(\n      street = school_street,\n      city = school_city,\n      state = school_state,\n      postalcode = school_zip_code, \n      method = \"osm\" # we also use method = \"geocodio\"\n    )\n#> Passing 4 addresses to the Nominatim single address geocoder\n#> Query completed in: 4.3 seconds\n\nknitr::kable(taco_schools_geocoded)\nlibrary(sf)\n#> Linking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2()\n#> is TRUE\n\n# st_as_sf() requires a user to specify what column(s) to use for geometry\ntaco_schools_sf <- taco_schools_geocoded %>%  \n  st_as_sf(coords = c(\"long\", \"lat\")) # use coords to specify a POINT geometry\n\nknitr::kable(taco_schools_sf)"},{"path":"geospatial-methods-and-gis.html","id":"coordinate-reference-system","chapter":"12 Geospatial Methods and GIS","heading":"12.2.3 Coordinate Reference System","text":"Notice meta-data CRS NA. CRS refers Coordinate Reference System, framework measuring locations precisely coordinates. CRS includes coordinate system, horizontal datum binds coordinates real space spheroid Earth estimate Earth’s curvature set control points, finally projection converts spherical coordinates Cartesian coordinates.always set common CRS latitude longitude WGS84 (used GPS satellite navigation system) following CRS string \"+init=epsg:4326\" formal identifier, also simply name:","code":"\nst_crs(taco_schools_sf) <- \"WGS84\"\n\n# alternate ways of establishing a CRS in the same pipe\n\n# option 1: use if no CRS has been established\n# taco_schools_sf <- taco_schools_geocoded %>%  \n#   st_as_sf(coords = c(\"long\", \"lat\")) %>%\n#   st_set_crs(\"WGS84\")\n\n# option 2: use if no CRS has been established\n# taco_schools_sf <- taco_schools_geocoded %>%\n#   st_as_sf(coords = c(\"long\", \"lat\"),\n#            crs = \"WGS84\")\n\n# option 3: use if CRS has already been established\n# taco_schools_sf <- taco_schools_geocoded %>%\n#   st_as_sf(coords = c(\"long\", \"lat\")) %>%\n#   st_transform(\"WGS84\")"},{"path":"geospatial-methods-and-gis.html","id":"basic-mapping","chapter":"12 Geospatial Methods and GIS","heading":"12.2.4 Basic mapping","text":"now enough information draw map! create map, need ggmap object, base layer map, additional sf layers want display. sf objects can plotted geometry column specified. function geom_sf() reads geometry column automatically plots data using specified metadata.many types map tiles can used display geographic data. don’t always love Google Maps’ look display purposes slides, let’s change Stamen, give us different styles map tiles. particular, use toner-lite, provides neutral, grey-white background. Stamen tiles, now provided Stadia Maps, requires API key.get baselayer map, must specify bounding box, set longitudes latitudes respectively establish left/right top/bottom edges map. can either get bounding box attributes Google Map baselayer, can create .","code":"\n# {ggsflabel} is not available on CRAN, {ggmap} requires get_stadiamap()\n# that is not yet on CRAN\n# renv::install(\"yutannihilation/ggsflabel\")\n# renv::install(\"dkahle/ggmap\")\n\nlibrary(ggmap)\n\n# starting with a Google map can give us a quick bounding box\n# this pulls appropriate Google map tiles around zip code 76117 at zoom level 11\n# and becomes our base layer map\nbase_google_map <- get_googlemap(\"76117\", zoom = 11)\n\n# before creating other layers/features, create a quick map with labels\n# to verify the correct bounding box and zoom level\nbase_google_map %>% # baselayer map\n  ggmap() + # create the ggmap object\n  \n  # additional layers\n  # plots school locations with a hotpink dot\n  geom_sf(\n    data = taco_schools_sf, \n    color = \"hotpink\",\n    inherit.aes = FALSE\n  ) +\n  \n  # adds hotpink labels of school names\n  ggsflabel::geom_sf_label_repel(\n    data = taco_schools_sf,\n    aes(label = school_short_name), \n    color = \"hotpink\",\n    inherit.aes = FALSE\n  ) \n# gets bounding box from Google Map base layer attributes\nbbox <- bb2bbox(attr(base_google_map, \"bb\"))\n\n# if you need a different bounding box, adjust the individual parameters\n# using your preferred coordinates\n\n# bbox <- c(left = -97.5, right = -97.1, top = 32.8, bottom = 32.5)\n\n# get a new base layer map using the specified bounding box\nbase_stamen_map <- get_stadiamap(bbox, \n                                 zoom = 11, \n                                 maptype = \"stamen_toner_lite\")\n\nbase_stamen_map %>% \n  ggmap() +\n  geom_sf(\n    data = taco_schools_sf, \n    color = \"hotpink\",\n    inherit.aes = FALSE\n  ) +\n  ggsflabel::geom_sf_label_repel(\n    data = taco_schools_sf,\n    aes(label = school_short_name), \n    color = \"hotpink\",\n    inherit.aes = FALSE\n  ) "},{"path":"geospatial-methods-and-gis.html","id":"getting-drive-times","chapter":"12 Geospatial Methods and GIS","heading":"12.2.5 Getting drive times","text":"often interested getting isochrone, radius around geographic feature respect time. Isochrones can useful identifying communities within 10- 15-minute drive-time school. calculation requires MapBox API, requires API key.","code":"\n# install.packages(\"mapboxapi\")\nlibrary(mapboxapi)\n\ndrive_10min <- mb_isochrone(\n    taco_schools_sf,\n    profile = \"driving\", # can also get walking distances\n    time = 10\n  )\n\n\n# this step removes the simple features metadata from a data frame\nschools_drive_10min_sf <- drive_10min %>%\n  bind_cols(as_tibble(taco_schools_sf) %>%\n              select(-geometry))\n\n\nbase_stamen_map %>% \n  ggmap() +\n  \n  geom_sf(\n    data = schools_drive_10min_sf,\n    aes(\n      color = school_short_name,\n      fill = school_short_name\n    ),\n    alpha = .2,\n    inherit.aes = FALSE\n  ) +\n  \n  geom_sf(\n    data = taco_schools_sf,\n    aes(color = school_short_name),\n    inherit.aes = FALSE\n  ) +\n  \n  ggsflabel::geom_sf_label_repel(\n    data = taco_schools_sf,\n    aes(\n      label = school_short_name, \n      color = school_short_name\n    ),\n    inherit.aes = FALSE\n  ) +\n  guides(fill = \"none\", color = \"none\")"},{"path":"geospatial-methods-and-gis.html","id":"spatial-joins","chapter":"12 Geospatial Methods and GIS","heading":"12.2.6 Spatial joins","text":"Using spatial join somewhat different joining data frames. many types spatial predicates, join type, spatial data, including:equalsdisjointcontainsintersectswithinand , can found sf documentation predicates.Spatial joins operate geometry column check relationship shapes (POINT, POLYGON, LINE, etc.) data frames spatial predicate.Suppose data frame describing locations school POINT, second data frame describing drive time radius around school POLYGON. might want check schools located certain school’s drive time radius. Spatially, using intersecting join check certain points fall inside polygon.schools found area overlapping isochrones? can use st_filter() st_within join help us identify points inside polygon.may look like Edgecliff within 10-minute drive time overlap area, truth just outside boundary.","code":"\nsf_use_s2(FALSE)\n\n# use spatial joins with two sf objects\ntaco_area_of_max_intersection <- schools_drive_10min_sf %>% # contains POLYGON geometry\n  filter(school_short_name == \"Edgecliff\") %>% \n  \n  # we can use st_intersection to check if the school locations are inside the drive time\n  st_intersection(schools_drive_10min_sf %>% \n                    filter(school_short_name == \"Southeast\")) # contains POINT geometry\n\n\nbase_stamen_map %>% \n  ggmap() +\n  geom_sf(\n    data = taco_area_of_max_intersection, \n    color = \"goldenrod\",\n    fill = \"goldenrod\",\n    alpha = .2,\n    inherit.aes = FALSE\n  ) +\n  \n  geom_sf(\n    data = taco_schools_sf, \n    aes(color = school_short_name), \n    inherit.aes = FALSE\n  ) +\n  \n  ggsflabel::geom_sf_label_repel(\n    data = taco_schools_sf,\n    aes(\n      label = school_short_name, \n      color = school_short_name\n    ),\n    inherit.aes = FALSE\n  ) +\n  guides(fill = \"none\", color = \"none\")\nschools_in_overlap <- taco_schools_sf %>%\n  st_filter(\n    taco_area_of_max_intersection, \n    join = st_within\n  )\n\nschools_in_overlap"},{"path":"geospatial-methods-and-gis.html","id":"census-data","chapter":"12 Geospatial Methods and GIS","heading":"12.3 Census Data","text":"Kyle Walker written exceptional [tidycensus](https://walker-data.com/tidycensus/)package, fantastic documentation, allows pull US Census data sources (including Decennial Census yearly American Community Survey).Let’s load Census data. ’ll need Census API key first gain access.","code":"\n# install.packages('tidycensus')\nlibrary(tidycensus)\n\n# NEt command saves Census API key to your .Renviron file\n# census_api_key(\"YOUR API KEY GOES HERE\")\n# census_api_key(Sys.getenv(\"CENSUS_API_KEY\"))"},{"path":"geospatial-methods-and-gis.html","id":"getting-basic-data","chapter":"12 Geospatial Methods and GIS","heading":"12.3.0.0.1 Getting Basic Data","text":"two major functions implemented tidycensus:get_decennial(), grants access 2000, 2010, 2020 decennial US Census APIs, andget_acs(), grants access 1-year 5-year American Community Survey APIs.Let’s get median age state 2010:Census data structured make usual tasks, like cleaning plotting, work ways expect using tidyverse. example, can plot median age state using ggplot:","code":"\nage10 <- get_decennial(geography = \"state\", \n                       variables = \"P013001\", \n                       year = 2010)\n#> Getting data from the 2010 decennial Census\n#> Using Census Summary File 1\n\nage10 %>%\n  slice_head(n = 5) %>%\n  knitr::kable()\nage10 %>%\n  ggplot(\n    aes(\n      x = value, \n      y = reorder(NAME, value)\n    )\n  ) + \n  geom_point() +\n  labs(\n    x = \"Median Age\",\n    y = \"State\",\n    title = \"Median Age by State\"\n  )"},{"path":"geospatial-methods-and-gis.html","id":"searching-for-variables","chapter":"12 Geospatial Methods and GIS","heading":"12.3.0.0.2 Searching for variables","text":", pray tell, one know P013001 variable median age? Getting variables Census ACS requires knowing variable ID - thousands IDs across different Census files. rapidly search variables, use load_variables() function. details package’s documentation page.browse variables, assign result load_variables() variable use View() function RStudio. optional argument cache = TRUE cache dataset computer future use.Let’s get estimates many school-aged children live Tarrant County, TX. , use get_acs() function, requires:geography: statistical geographic unit used Census (brief overview provided ESRI)variables: variable code/ID, can optionally renamedstate: two-letter postal codes acceptedcounty: avoid ambiguity API, type full county parish name (e.g. “Tarrant County”, “Tarrant”)year: ACS survey-year requestedgeometry: TRUE pull appropriate geometry tigris package return sf objectBecause looked appropriate variable names load_variables() function, know appropriate table B01001, choose correct variables. want data smallest geographic unit, choose “block group” geography, need data 2020. eventually like map data, choose include geometry column sf data frame.","code":"\nv_2020 <- load_variables(2020, \"acs5\", cache = TRUE)\n\n# View(v_2020)\ntarr <- get_acs(\n    geography = \"block group\", \n    variables = c(\n      # variable codes (e.g. \"B01001_001\") are mandatory\n      # renaming is optional\n      # ex. \"B01001_001\", \"B01001_004\" are acceptable arguments\n      \n      \"Total\" = \"B01001_001\",\n      \"Male, 5 to 9 years\" = \"B01001_004\",\n      \"Male, 10 to 14 years\" = \"B01001_005\",\n      \"Male, 15 to 17 years\" = \"B01001_006\", \n      \"Female, 5 to 9 years\" = \"B01001_028\",\n      \"Female, 10 to 14 years\" = \"B01001_029\",\n      \"Female, 15 to 17 years\" = \"B01001_030\"\n    ),\n    state = \"TX\", \n    county = \"Tarrant County\",\n    year = 2020,\n    geometry = TRUE, \n  )"},{"path":"geospatial-methods-and-gis.html","id":"plotting-geographic-data","chapter":"12 Geospatial Methods and GIS","heading":"12.4 Plotting geographic data","text":"Spatial data can broadly represented discrete processes, aggregations, continuous processes.can use point pattern analysis data merely locate longitude latitude variable. example, plot every school-aged child lives Tarrant County. Areal data aggregate data describe geographic area region. total number school-aged children living Tarrant County, Dallas County, surrounding counties example areal data. Continuous processes map point value - case, age single child given point. also add time variable make data spatiotemporal.Specific resources modeling types data can found Introduction Spatial Data Analysis Statistics.mapping geographic data, also different methods depending type spatial data used.","code":""},{"path":"geospatial-methods-and-gis.html","id":"chloropleth","chapter":"12 Geospatial Methods and GIS","heading":"12.4.1 Chloropleth","text":"chloropleth type plot used areal data takes different colors, depending data. Let’s sum school aged children (5-17 year old boy girls) block group:map, can use color identify block groups high densities school-aged children .","code":"\nlibrary(viridis)\n\n# aggregate school-aged children by block group\n# remove \"Total\" category\ntarr_school_aged <- tarr %>% \n  filter(variable != \"Total\") %>%\n  \n  # when summarizing multiple Census variables in a single Census location,\n  # group by the GEOID, which is a unique identifier for a Census geography\n  group_by(GEOID, NAME) %>% \n  \n  # best practice - keep the estimate AND margin of error columns\n  summarise(\n    estimate = sum(estimate),\n    moe = moe_sum(moe, estimate = .9) # recomputes the grouped margin of error at 90%\n  )\n\n\nbase_stamen_map %>% \n  ggmap() +\n  \n  geom_sf(\n    data = tarr_school_aged, \n    aes(fill = estimate), \n    inherit.aes = FALSE, \n    alpha = .82, \n    color = NA\n  ) +\n  \n  # shades the isochrone intersection\n  geom_sf(\n    data = taco_area_of_max_intersection, \n    color = \"goldenrod\",\n    fill = NA,\n    alpha = .2,\n    inherit.aes = FALSE\n  ) +\n  geom_sf(\n    data = taco_schools_sf, \n    inherit.aes = FALSE, \n    color = \"green\"\n  ) +\n  theme_void() +\n  \n  scale_fill_viridis(option = \"magma\")"},{"path":"geospatial-methods-and-gis.html","id":"dot-density","chapter":"12 Geospatial Methods and GIS","heading":"12.4.2 Dot-density","text":"Areal representation data suffer problems. One problem geographically large areas draw eye can often -emphasize areas versus smaller geographies. distortion familiar follow elections, geographically large states small populations, like Wyoming, loom larger geographically small, densely populated states, like Delaware (Wyoming 1/2 population Delaware, 42x land mass). distortion occurs Census geographies blocks, block groups, tracts created roughly equal populations (e.g., Census tracts generally population size 1,200 8,000 people, optimum size 4,000 people); geographies consequently larger rural places urban centers.second issue ’s hard show heterogeneity spatial distributions. plot shows estimates count children aged 5-17 years tract. , may interested differently distributed students .method remedy issues use dot-density plots simply plot sample points within geography group (often sampled dot represents number people (e.g., 20 100 persons per dot). ’s pretty straightforward get need using tidycensus::as_dot_density()Note as_dot_density() convert areal value (count children), represented POLYGON, value represented POINT. data prepped dot density, ready plot data.Dot densities can particularly useful variables faceted, differences distributions can seen.","code":"\n# library(terra) # as_dot_density() requires the {terra} package\n\n# this table will be used to combine the male and female groups for estimating\nacs_ages <- dplyr::tribble(\n  ~ acs_var,     ~ variable,                ~ age_range,   ~ gender,\n  \"B01001_001\",  \"Total\",                   \"All\",         \"All\",\n  \n  # male\n  \"B01001_004\",  \"Male, 5 to 9 years\",      \"5-9\",         \"Male\",\n  \"B01001_005\",  \"Male, 10 to 14 years\",    \"10-14\",       \"Male\",\n  \"B01001_006\",  \"Male, 15 to 17 years\",    \"15-17\",       \"Male\",\n  \n  # female\n  \"B01001_028\",  \"Female, 5 to 9 years\",    \"5-9\",         \"Female\",\n  \"B01001_029\",  \"Female, 10 to 14 years\",  \"10-14\",       \"Female\",\n  \"B01001_030\",  \"Female, 15 to 17 years\",  \"15-17\",       \"Female\"\n)\n\n# gets the estimated number of children per age group per block group\nsf_tarrant_children <- tarr %>% \n  inner_join(acs_ages, by = \"variable\") %>% \n  filter(gender != \"All\") %>% \n  select(-acs_var, -gender) %>% \n  \n  # this will count the number of boys and girls into one group\n  group_by(GEOID, NAME, age_range) %>% \n  summarize(estimate = sum(estimate),\n            moe = moe_sum(moe, estimate = 0.9))\n\n\n# converts to a dot density\nsf_tarrant_children_dots <- sf_tarrant_children %>% \n  as_dot_density(\n    value = \"estimate\", # use the summary column to determine number of dots\n    values_per_dot = 20,  # specify the dot-to-value ratio\n    group = \"age_range\"   # specify how dots should be categorized (if needed)\n  ) \nbase_stamen_map %>% \n  ggmap() +\n  \n  # plot dot density\n  geom_sf(\n    data = sf_tarrant_children_dots %>%\n      mutate(age_range = fct_relevel(age_range, \n                                     \"5-9\", \"10-14\", \"15-17\")),\n    aes(color = age_range),\n    inherit.aes = FALSE,\n    alpha  = .25,\n    size = .25\n  ) +\n  \n  # plot spatial intersection of drive times\n  geom_sf(\n    data = taco_area_of_max_intersection, \n    color = \"goldenrod\",\n    fill = \"goldenrod\",\n    alpha = .2,\n    inherit.aes = FALSE\n  ) +\n  \n  # plot school locations\n  geom_sf(\n    data = taco_schools_sf,\n    inherit.aes = FALSE,\n    color = \"hotpink\",\n    size = 2\n  ) +\n  \n  # use more options to move labels out of the way\n  ggsflabel::geom_sf_label_repel(\n    data = taco_schools_sf,\n    aes(label = school_short_name),\n    color = idea_colors$coolgray,\n    \n    # use nudge values to align all labels to one side of the map\n    direction = \"y\",\n    nudge_x = -97.1 - st_coordinates(taco_schools_sf)[,\"X\"], # uses right edge of bbox\n    nudge_y = 0.02,\n    size = 3,\n    inherit.aes = FALSE\n  ) +\n  \n  facet_wrap(~ age_range) +\n  theme_void() +\n  \n  scale_color_viridis(option = \"viridis\", discrete = TRUE) +\n  guides(color = \"none\")"},{"path":"geospatial-methods-and-gis.html","id":"gis-based-mcda","chapter":"12 Geospatial Methods and GIS","heading":"12.5 GIS-Based MCDA","text":"Suitability analyses can used variety contexts choosing best candidate, car, phone. Additionally, can used Geographic Information System (GIS) land suitability assessed. land suitability analysis conducted variety reasons identifying good locations park landfill.making decisions regarding suitability piece land particular purpose, multiple criteria considered thus multi-criteria decision analysis (MCDA) conducted. focus section, GIS-based MCDA. Three different methods covered, simple weighted linear combination analytical hierarchy process.","code":""},{"path":"geospatial-methods-and-gis.html","id":"simple-and-weighted-linear-combination","chapter":"12 Geospatial Methods and GIS","heading":"12.5.1 Simple and Weighted Linear Combination","text":"simple weighted linear combination methods two MCDAs. simple linear combination method, criteria equally weighted weighted linear combination method allows criteria weighted according importance.one interested locating suitable sites landfill (example), criteria identified rasters created. cell rasters considered potential alternative site landfill score assigned . Raster algebra used compute combination scores threshold set distinguish cells suitable landfill site.Assume three criteria used landfill land suitability analysis: Distance Schools (farther better), Slope (flatter better), Distance Population Centers (decently far away, far). first step linear combination methods create raster criteria (school_raster, slope_raster, pop_center_raster) cell assessed respect raster’s criteria. complete, combine linearly either equal (simple linear combination method) unequal (weighted linear combination method) weights compare threshold value. sample R code accomplish .","code":"\nlayer_stack <- c(school_raster, \n                 slope_raster,\n                 pop_center_raster)\n\n# linear combo, equal weights ----\n\nequal_combo_raster <- layer_stack[[1]] + \n  layer_stack[[2]] + \n  layer_stack[[3]]\n\n(equal_combo_raster > your_threshold) %>% \n  plot(type = \"classes\", \n       axes = F, \n       main = \"Simple Linear Combination\")\n\n# linear combo, weighted ----\n\n# note that weights have been arbitrarily assigned here\nweighted_combo_raster <-  layer_stack[[1]]* 0.40 + \n  layer_stack[[2]]* 0.35 + \n  layer_stack[[3]] * 0.25\n\n(weighted_combo_raster > your_threshold) %>% \n  plot(type = \"classes\", \n       axes = F, \n       main = \"Weighted Linear Combination\")"},{"path":"geospatial-methods-and-gis.html","id":"analytical-hierarchy-process","chapter":"12 Geospatial Methods and GIS","heading":"12.5.2 Analytical Hierarchy Process","text":"analytical hierarchy process (AHP) developed Thomas Saaty 1970s can used Geographic Information System (GIS) multi-criteria decision analysis (MCDA) method. AHP creates set weights can used weighted linear combination (WLC) method , example, conjunction Ordered Weighted Averaging (OWA). , step--step process AHP method presented, hand R.","code":""},{"path":"geospatial-methods-and-gis.html","id":"context","chapter":"12 Geospatial Methods and GIS","heading":"12.5.2.1 Context","text":"number uses suitability analyses vast. examples identifying locations new restaurants, parks, retail sites; identifying best candidate job; choosing best car individual. example, goal identify best location new landfill.","code":""},{"path":"geospatial-methods-and-gis.html","id":"ahp-steps","chapter":"12 Geospatial Methods and GIS","heading":"12.5.2.2 AHP Steps","text":"general steps perform AHP :\n• Identify criteria\n• Create hierarchical structure\n• Make pairwise comparisons create matrix\n• Check consistency matrix\n• Compute criteria weights","code":""},{"path":"geospatial-methods-and-gis.html","id":"identify-the-criteria","chapter":"12 Geospatial Methods and GIS","heading":"12.5.2.3 Identify the Criteria","text":"Three arbitrary+ criteria used:\n• Distance schools\n• Slope\n• Distance population centers\n+Please note example based sample land suitability analysis. criteria utilized identify appropriate locations landfill.","code":""},{"path":"geospatial-methods-and-gis.html","id":"create-the-hierarchical-structure","chapter":"12 Geospatial Methods and GIS","heading":"12.5.2.4 Create the Hierarchical Structure","text":"AHP hierarchy includes, minimum, three levels: goal, criteria, alternatives. alternatives candidates cars interest (see examples Context section ). case raster data used, alternatives every cell raster data.","code":""},{"path":"geospatial-methods-and-gis.html","id":"make-pairwise-comparisons-and-create-matrix","chapter":"12 Geospatial Methods and GIS","heading":"12.5.2.5 Make Pairwise Comparisons and Create Matrix","text":"nodes level must compared two--two relation contribution node . values entered matrix used compute criteria weights.AHP fundamental scale (see ) used making pairwise comparisons.pairwise comparison, 1 assigned weaker criteria (respect node ). , criteria assigned value based AHP fundamental scale.begin, Distance Schools Slope compared. individual group tasked making pairwise comparisons believes Distance Schools stronger criteria respect location landfill. , 1 assigned Slope pairwise comparison. individual group believes landfill away school site strongly favored area flatter. Thus, value 5 assigned Distance Schools pairwise comparison.method continues pairwise comparisons results follows:results can now transferred matrix.accomplish R, following code can used:","code":"\n# create a 3x3 matrix with all 1s\nAHP_matrix <- matrix(1,\n                     nrow = 3, \n                     ncol = 3)\n#       [,1] [,2] [,3]\n# [1,]    1    1    1\n# [2,]    1    1    1\n# [3,]    1    1    1\n\n# name the rows and columns\nrow.names(AHP_matrix) <- \n  colnames(AHP_matrix) <- \n  c('Distance to Schools', \n    'Slope', \n    'Distance to Population Centers')\n#                                   Distance to Schools Slope Distance to Population Centers\n# Distance to Schools                 1                   1       1\n# Slope                               1                   1       1\n# Distance to Population Centers      1                   1       1\n\n# add the rankings to the upper triangle\nAHP_matrix[upper.tri(AHP_matrix)] <- c(5,4,2)\n#                                   Distance to Schools Slope Distance to Population Centers\n# Distance to Schools                 1                   5       4\n# Slope                               1                   1       2\n# Distance to Population Centers      1                   1       1\n\n# put the reciprocal in the lower triangle of the matrix\nfor(i in 1:dim(AHP_matrix)[1]){\n  for(j in i:dim(AHP_matrix)[2])\n    AHP_matrix[j,i] = 1/AHP_matrix[i,j]\n}\n#                                   Distance to Schools Slope Distance to Population Centers\n# Distance to Schools                 1.00              5.0       4\n# Slope                               0.20              1.0       2\n# Distance to Population Centers      0.25              0.5       1"},{"path":"geospatial-methods-and-gis.html","id":"check-the-consistency-of-the-matrix","chapter":"12 Geospatial Methods and GIS","heading":"12.5.2.6 Check the Consistency of the Matrix","text":"AHP matrix must consistent. measure , Consistency Ratio (CR) computed dividing Consistency Index (CI) Random Consistency Index (RCI) (Saaty, 1980).CR < 0.10 AHP matrix considered consistent. consistency confirmed, criteria weights can computed.CI computedwhere λmax = largest eigenvalue matrix n = number criteria.R,value CR less 0.10 AHP matrix considered consistent example.","code":"\nCI <- (Mod(eigen(AHP_matrix)$values[1]) - 3)/ 2\n# [1] 0.04700755\n\n# RCI for n = 3 is 0.58\nCR <- CI / 0.58 \n# [1] 0.08104751"},{"path":"geospatial-methods-and-gis.html","id":"compute-the-criteria-weights","chapter":"12 Geospatial Methods and GIS","heading":"12.5.2.7 Compute the Criteria Weights","text":"final step AHP compute criteria weights. weights computed normalizing largest eigenvector matrix. , value largest eigenvector divided sum values vector.R,results show Distance Schools highest weighted criteria followed Slope Distance Population Centers. Now criteria weights computed, can used WLC method , example, conjunction OWA.","code":"\n# compute criteria weights by normalizing the largest eigenvector \nweights <- eigen(AHP_matrix, symmetric = F)$vectors[,1] / sum(eigen(AHP_matrix, symmetric = F)$vectors[,1])\n# [1] 0.6869815+0i 0.1864755+0i 0.1265431+0i"},{"path":"communicating-results.html","id":"communicating-results","chapter":"13 Communicating Results","heading":"13 Communicating Results","text":"","code":""},{"path":"communicating-results.html","id":"technical-communication","chapter":"13 Communicating Results","heading":"13.1 Technical Communication","text":"","code":""},{"path":"communicating-results.html","id":"non-technical-communication","chapter":"13 Communicating Results","heading":"13.2 Non-Technical Communication","text":"","code":""},{"path":"tips-and-tricks.html","id":"tips-and-tricks","chapter":"14 Tips and Tricks","heading":"14 Tips and Tricks","text":"section R&Manual sharing various tricks make life easier. Rules thumb, explanations things work, useful design patterns fair game.","code":""},{"path":"tips-and-tricks.html","id":"data-processing","chapter":"14 Tips and Tricks","heading":"14.1 Data processing","text":"","code":""},{"path":"tips-and-tricks.html","id":"de-duplicating-rows-in-a-table","chapter":"14 Tips and Tricks","heading":"14.1.1 De-duplicating rows in a table","text":"two general purpose design patterns de-duplicating rows table either R SQL.R use dplyr::distinct() function SQL use DISTINCT clause. pretty simple robust, typical use case wanting reduce many identical rows single row.R use dplyr::distinct() function SQL use DISTINCT clause. pretty simple robust, typical use case wanting reduce many identical rows single row.trying de-duplicate may non-identical rows (e.g., student taken assessment multiple times testing window ’d like get latest date) can use group_by-arrange-row_number-filter pattern:\nGroup data columns uniquely identify object inquiry (e.g., student number)\nArrange sort data column puts ordering care within grouped data (e.g., assessment date)\nCreate new column contains row number within group (e.g, student 5 assessments window row_number = 1 first date row_number = 5 last date).\nFilter maximum row number(dplyr::filter() R clause SQL)\n(optional) Ungroup data.\ntrying de-duplicate may non-identical rows (e.g., student taken assessment multiple times testing window ’d like get latest date) can use group_by-arrange-row_number-filter pattern:Group data columns uniquely identify object inquiry (e.g., student number)Arrange sort data column puts ordering care within grouped data (e.g., assessment date)Create new column contains row number within group (e.g, student 5 assessments window row_number = 1 first date row_number = 5 last date).Filter maximum row number(dplyr::filter() R clause SQL)(optional) Ungroup data.","code":""},{"path":"tips-and-tricks.html","id":"hierarchical-aggregation-or-the-list-group_by-trick","chapter":"14 Tips and Tricks","heading":"14.1.2 Hierarchical aggregation, or the list-group_by trick","text":"Schools data, especially student-level data, embedded hierarchical groupings.Let’s look Zillow Home Value Index homes (.e, single family homes, condos, coops), smoothed, seasonally adjusted measure typical home value market changes across given region. reflects typical value homes 35th 65th percentile range neighborhood level. home values available every month January 2000 May 2022.’s large dataset ’ll use Apache Arrow Project’s feather file format read data R subset housing costs IDEA metro areas since 2020.Table 14.1: first 10 rows Zillow Home Value Index dataThese data nested: 22 years home prices within neighborhoods, cities, counties, metro areas, states. Often ’d like aggregations various levels. , ’d like know mean home price neighborhood, city, county. typical work flow achieve write dplyr pipeline one group_by combination copy--paste pipeline change columns group_by call. works pinch, repetitive (violating DRY doctrine), prone copying errors leaves bunch dataframe increasingly awkward names.elegant solution leverage purrr’s map_df function pass list already grouped data frames. ’s simple example:now data frame county-level state-level means one data frame. Notice however county_name field NA state level data:makes sense, since map_df uses bind_rows concatenate aggregated tables together fill columns missing data frame NA values. simple example like add extra step end pipeline provide information:one data frame? can now easily graphed:","code":"\nlibrary(arrow)\n#> \n#> Attaching package: 'arrow'\n#> The following object is masked from 'package:lubridate':\n#> \n#>     duration\n#> The following object is masked from 'package:utils':\n#> \n#>     timestamp\nzillow <- read_feather(\"./zillow.feather\")\n\n\nidea_metros <- tibble(Metro = c(\"Austin-Round Rock\",\n                                \"Dallas-Fort Worth-Arlington\",\n                                \"San Antonio-New Braunfels\",\n                                \"Brownsville-Harlingen\",\n                                \"El Paso\",\n                                \"Houston-The Woodlands-Sugar Land\",\n                                \"Baton Rouge\",\n                                \"Tampa-St. Petersburg-Clearwater\",\n                                \"Jacksonville\",\n                                \"Cincinnati\"\n                                )\n                      )\n\n\n\nzillow_idea <- zillow %>% \n  inner_join(idea_metros, by = \"Metro\") %>% \n  select(RegionID:CountyName, matches(\"202*-\")) %>% # matches() selects columns with regular expressions\n  janitor::clean_names()\n\nknitr::kable(\n  head(zillow_idea),\n   booktabs = TRUE,\n  caption = 'first 10 rows of Zillow Home Value Index data')\nlibrary(purrr)\n\nzillow_idea_county_state <- zillow_idea %>% \n  # create a list of grouped data.frames\n  {list(\n    group_by(., county_name, state), # the . is a  placeholder for the data.frame being piped in \n    group_by(., state)\n  )} %>% \n  map_df(., ~{\n    .x %>% # .x is a placeholder for each element of list above passed to map_df\n      # across allows us to apply a function to every column satisfying a condition\n      summarize(across(starts_with(\"x20\"), ~mean(.x, na.rm = TRUE)))\n  })\n#> `summarise()` has regrouped the output.\n#> ℹ Summaries were computed grouped by county_name and state.\n#> ℹ Output is grouped by county_name.\n#> ℹ Use `summarise(.groups = \"drop_last\")` to silence this\n#>   message.\n#> ℹ Use `summarise(.by = c(county_name, state))` for\n#>   per-operation grouping (`?dplyr::dplyr_by`) instead.\n  \n\nknitr::kable(zillow_idea_county_state)\nzillow_idea_county_state %>% \n  filter(is.na(county_name)) %>% \n  knitr::kable()\nzillow_idea_county_state <- zillow_idea %>% \n  # create a list of grouped data.frames\n  {list(\n    group_by(., county_name, state), # the . is a  placeholder for the data.frame being piped in \n    group_by(., state)\n  )} %>% \n  map_df(., ~{\n    .x %>% # .x is a placeholder for each element of list above passed to map_df\n      # across allows us to apply a function to every column satisfying a condition\n      summarize(across(starts_with(\"x20\"), ~mean(.x, na.rm = TRUE)))\n  }) %>% \n  replace_na(list(county_name = \"State Avg\"))\n#> `summarise()` has regrouped the output.\n#> ℹ Summaries were computed grouped by county_name and state.\n#> ℹ Output is grouped by county_name.\n#> ℹ Use `summarise(.groups = \"drop_last\")` to silence this\n#>   message.\n#> ℹ Use `summarise(.by = c(county_name, state))` for\n#>   per-operation grouping (`?dplyr::dplyr_by`) instead.\n\nzillow_idea_county_state %>% \n  filter(is.na(county_name))\n#> # A tibble: 0 × 19\n#> # Groups:   county_name [0]\n#> # ℹ 19 variables: county_name <chr>, state <chr>,\n#> #   x2020_01_31 <dbl>, x2020_02_29 <dbl>,\n#> #   x2020_03_31 <dbl>, x2020_04_30 <dbl>,\n#> #   x2020_05_31 <dbl>, x2020_06_30 <dbl>,\n#> #   x2020_07_31 <dbl>, x2020_08_31 <dbl>,\n#> #   x2020_09_30 <dbl>, x2020_10_31 <dbl>,\n#> #   x2020_11_30 <dbl>, x2020_12_31 <dbl>, …\n\nzillow_idea_county_state %>% \n  filter(county_name == \"State Avg\") %>% \n  knitr::kable()\nlibrary(ggrepel)\nlibrary(lubridate)\n\n\nzillow_idea_county_state %>% \n  # pivot to a long table by year\n  pivot_longer(cols = starts_with(\"x\"), names_to = \"month\", values_to = \"home_value\") %>% \n  # let's clean up the month column by removing the leading x and casting to a date\n  mutate(month = str_remove(month, \"x\"), \n         month = lubridate::ymd(month)) %>% \n  \n  ggplot(aes(x = month, home_value, color = county_name == \"State Avg\")) + \n  geom_line(aes(group=county_name)) +\n  # geom_dl(aes(color = county_name == \"State Avg\", label = county_name), \n  #         method = \"maxvar.qp\") +\n  geom_text_repel(data = . %>% \n                    filter(month == max(month)),\n                  aes(label = county_name), \n                  xlim = c(ymd(\"2022-05-31\"), Inf),\n                  size  = 1.5,\n                  force             = 0.05,\n                  nudge_x           = 5,\n                  direction         = \"y\",\n                  hjust             = 0, \n                  vjust = 0.5, \n                  max.overlaps = Inf, ) +\n  scale_y_continuous(labels = scales::dollar_format()) +\n  ideacolors::scale_color_idea(labels = c(\"County Avg\",\"State Avg\")) +\n  \n  coord_cartesian(clip = FALSE, expand = TRUE, xlim = c(ymd(\"2020-01-03\"), \n                                                        ymd(\"2023-12-31\"))) +\n  facet_wrap(~state) +\n  ideacolors::theme_idea_min() +\n  labs(y = \"Typical home values\", \n       x = \"Month\",\n       color = \"\") "},{"path":"tips-and-tricks.html","id":"saving-grouping-info","chapter":"14 Tips and Tricks","heading":"14.1.2.1 Saving grouping info","text":"Another trick save group_by info passing grouped data.frame column. ’s example:","code":"\n\nzillow_idea_neighborhood <- zillow_idea %>% \n  # create a list of grouped data.frames\n  {list(\n    group_by(., region_name, city, metro, county_name, state), \n    group_by(., city, metro, county_name, state), \n    group_by(., county_name, state),\n    group_by(., state)\n  )} %>% \n  map_df(., ~{\n    .x %>% # .x is a placeholder for each element of list above passed to map_df\n      # across allows us to apply a function to every column satisfying a condition\n      summarize(across(starts_with(\"x20\"), ~mean(.x, na.rm = TRUE))) %>% \n      mutate(groups = paste(group_vars(.x), collapse = \"|\"))\n  })\n#> `summarise()` has regrouped the output.\n#> `summarise()` has regrouped the output.\n#> `summarise()` has regrouped the output.\n#> ℹ Summaries were computed grouped by region_name, city,\n#>   metro, county_name, and state.\n#> ℹ Output is grouped by region_name, city, metro, and\n#>   county_name.\n#> ℹ Use `summarise(.groups = \"drop_last\")` to silence this\n#>   message.\n#> ℹ Use `summarise(.by = c(region_name, city, metro,\n#>   county_name, state))` for per-operation grouping\n#>   (`?dplyr::dplyr_by`) instead.\n\n\n\nzillow_idea_neighborhood %>% \n  filter(groups == \"city|metro|county_name|state\") %>% \n  top_n(20) %>% \n  knitr::kable()\n#> Selecting by groups"},{"path":"tips-and-tricks.html","id":"duplicating-rows","chapter":"14 Tips and Tricks","heading":"14.1.3 Duplicating rows","text":"Suppose aggregated data like table , instead, need duplicated rows create visualization instance region. example, might need 3 duplicate rows East Baton Rouge, 9 duplicate rows Austin, ., simply use tidyr::uncount() duplicate rows. first 10 rows printed example:data frame built information pertaining school, plotted easily ggplot call. Check documentation useful arguments.","code":"\ngrouped_data <- tribble(\n  ~ state, ~ region, ~ n_campuses,\n  \"FL\", \"Jacksonville\", 2,\n  \"FL\", \"Tampa\", 2,\n  \"LA\", \"East Baton Rouge\", 3,\n  \"OH\", \"Cincinnati\", 2,\n  \"TX\", \"Austin\", 9,\n  \"TX\", \"El Paso\", 5,\n  \"TX\", \"Greater Houston Area\", 3,\n  \"TX\", \"Permian Basin\", 2,\n  \"TX\", \"Rio Grande Valley\", 26,\n  \"TX\", \"San Antonio\", 15,\n  \"TX\", \"Tarrant County\", 4\n)\n\nknitr::kable(grouped_data)\ngrouped_data %>%\n  uncount(n_campuses) %>%\n  slice_head(n = 10) %>%\n  knitr::kable()"},{"path":"tips-and-tricks.html","id":"creating-scaffolds-when-joining-data","chapter":"14 Tips and Tricks","heading":"14.1.4 Creating “Scaffolds” when joining data","text":"Coming Soon. . .","code":""},{"path":"tips-and-tricks.html","id":"statistical-pitfalls","chapter":"14 Tips and Tricks","heading":"14.2 Statistical pitfalls","text":"","code":""},{"path":"tips-and-tricks.html","id":"simpsons-paradox","chapter":"14 Tips and Tricks","heading":"14.2.1 Simpson’s Paradox","text":"identifying trends distribution, careful interpreting trends, particularly hierarchy involved population. ranking, magnitude, direction trends can reverse conditioning certain level hierarchy. example, STAAR achievement levels function minutes individual learning program like Dreambox may significant district level, significant school classroom level.","code":""},{"path":"tips-and-tricks.html","id":"bias-variance-tradeoff","chapter":"14 Tips and Tricks","heading":"14.2.2 Bias-variance tradeoff","text":"","code":""},{"path":"tips-and-tricks.html","id":"troubleshooting-messages-and-errors","chapter":"14 Tips and Tricks","heading":"14.3 Troubleshooting messages and errors","text":"","code":""},{"path":"tips-and-tricks.html","id":"connection-to-the-dashboard","chapter":"14 Tips and Tricks","heading":"14.3.1 Connection to the dashboard","text":"working ideadata RStudio, issues connecting servers dashboards host ideadata may occur. example, warnings errors may include Resetting connection conn_Dashboard /environment server connections may show ptr “<pointer: (nil)>.resolve issue, consider following:Check VPN status, code accuracy, environment, connections, config settings using ProjectTemplate goes .VPN (aka Global Protect)\nVPN connection required server access.\nCheck make sure logged VPN.\nlogged , please enter IDEA login credentials.\nlogged connected VPN, please continue next steps.Code Accuracy:\nCheck code accuracy.\ntrying connect specific table, sure information table, database, schema, server names listed correctly based updated information.Environment Connections:\nReview environment connections.\nexample, check environment server connections. “null pointer” (<pointer: (nil)>), need reset connection try reloading project.Depending issue, select following commands enter console:\nrestart R session (CTRL + Shift + F10): clear objects libraries\nrm():remove one objects specified environment, examplerm(conn_Dashboard)\ndisconnect(): close connection, example disconnect(conn_PROD1)\nclear.cache(): clear cache, example: clear.cache(conn_PROD1)try reloading project running script.","code":""},{"path":"tips-and-tricks.html","id":"export-excel-workbook-with-multiple-worksheets-using-r","chapter":"14 Tips and Tricks","heading":"14.4 Export Excel Workbook with Multiple Worksheets Using R","text":"Assume request came provide list Core Value Award nominations return Excel workbook. requestor also asked entity presented separate worksheet. save manual process separating entities different worksheets within Excel, R can utilized. streamline workflow make reproducible event request made future. Note number ways accomplish task R though one demonstrated .begin, install (necessary) load {tidyverse} {openxlsx} create sample data frame:write.xlsx() {openxlsx} used create workbook \ntwo worksheets (one Texas nominations one IPS\nnominations). first argument function list \nworksheets. worksheet, name provided surrounded \n“quotes” followed equal sign included \nworksheet. case, first worksheet named “Texas” \nincludes entire core_value_award_nominations data frame \npart Texas entity. followed IPS\nworksheet includes nominations IPS.Note number unique worksheets longer (e.g., \nworksheet region), loop employed.","code":"\n# load packages ----\nlibrary(tidyverse)\nlibrary(openxlsx)\n\n# create the sample data frame ----\ncore_value_award_nominations <- data.frame(entity = c('TX', 'TX', 'IPS', 'TX', 'IPS'),\n                                           name = c('Simone Biles',\n                                                    'Laurie Hernandez',\n                                                    'Alexandra Raisman',\n                                                    'Madison Kocian',\n                                                    'Gabrielle Douglas'), \n                                           core_value = c('We Achieve Academic Excellence',\n                                                          'We Bring Joy',\n                                                          'We Deliver Results',\n                                                          'We Bring Joy',\n                                                          'We Achieve Academic Excellence'))\n# create Excel workbook ----\nwrite.xlsx(list(\"Texas\" = core_value_award_nominations %>% \n                 filter(entity == 'TX'),\n             \"IPS\" = core_value_award_nominations %>% \n                 filter(entity == 'IPS')),\n        file = \"C:/Users/fname.lname/Desktop/core_values_entity.xlsx\") # insert your path here"},{"path":"tips-and-tricks.html","id":"renviron","chapter":"14 Tips and Tricks","heading":"14.5 .Renviron","text":".Renviron file can used create environment variables R. One large benefit credentials API keys longer need included R scripts.open make changes .Renviron file, run following code:file open, changes can made. access IDEA data, following included:access Posit Connect, following included:additional example, may need Mapbox API token. , include following .Renviron file:included .Renviron file, key can called within R script ‘Sys.getenv(“MAPBOX_API_TOKEN”)’.changes made .Renviron file, don’t forget restart R changes take effect.","code":"\nlibrary(usethis)\nusethis::edit_r_environ()IDEA_RNA_DB_UID = ‘firstname.lastname’\nIDEA_RNA_DB_PWD = ‘password’ (your IDEA password)\nIDEA_RNA_ODC_DRIVER = ‘{ODBC Driver __ for SQL Server}’ (substitute blank with current number)\nCONNECT_API_KEY = 'your key here'\nCONNECT_SERVER = 'https://analytics.ideapublicschools.org/'\nMAPBOX_API_TOKEN = 'your key here'"},{"path":"tips-and-tricks.html","id":"idea-acronym-guide","chapter":"14 Tips and Tricks","heading":"14.6 IDEA Acronym Guide","text":"IDEA uses acronyms frequently. Several acronyms compiled resource.","code":""},{"path":"references-1.html","id":"references-1","chapter":"References","heading":"References","text":"","code":""}]
